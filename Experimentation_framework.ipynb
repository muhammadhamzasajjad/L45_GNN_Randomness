{"cells":[{"cell_type":"markdown","metadata":{"id":"qU87TNON39IV"},"source":["# **Preliminaries:** Install and import modules"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mpygj8TTZ-ur","outputId":"e2a548f0-d5fb-4ed1-af68-89e942088292","executionInfo":{"status":"ok","timestamp":1679310090819,"user_tz":0,"elapsed":51879,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mycolorpy\n","  Downloading mycolorpy-1.5.1.tar.gz (2.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mycolorpy) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mycolorpy) (3.7.1)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (5.12.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (8.4.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (4.39.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (0.11.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (23.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mycolorpy) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mycolorpy) (1.15.0)\n","Building wheels for collected packages: mycolorpy\n","  Building wheel for mycolorpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mycolorpy: filename=mycolorpy-1.5.1-py3-none-any.whl size=3874 sha256=e70cf7ca4a431bfdffb62d8bf0a26bc9b22abd749d3fe1670682dab80fcfefd8\n","  Stored in directory: /root/.cache/pip/wheels/b9/56/d6/a163bcbec3bb69f3f7797b1b542870b18d7e31ff5dbc0b87e3\n","Successfully built mycolorpy\n","Installing collected packages: mycolorpy\n","Successfully installed mycolorpy-1.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Installing collected packages: colorama\n","Successfully installed colorama-0.4.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ogb\n","  Downloading ogb-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.13.1+cu116)\n","Collecting outdated>=0.2.0\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.4.4)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.26.15)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.2.2)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.22.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.15.0)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (4.65.0)\n","Collecting littleutils\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (63.4.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (2.27.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n","Building wheels for collected packages: littleutils\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=40714e7e3fff41bd1fec59e36a383ff0d356805deef0952bb0e6b2d40690ca1e\n","  Stored in directory: /root/.cache/pip/wheels/04/bb/0d/2d02ec45f29c48d6192476bfb59c5a0e64b605e7212374dd15\n","Successfully built littleutils\n","Installing collected packages: littleutils, outdated, ogb\n","Successfully installed littleutils-0.2.2 ogb-1.3.5 outdated-0.2.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.17%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=378dc6bade3f98482552d3793ee5f08a19db9c0b01005f8b228c82ba1167a94b\n","  Stored in directory: /root/.cache/pip/wheels/31/b2/8c/9b4bb72a4384eabd1ffeab2b7ead692c9165e35711f8a9dc72\n","Successfully built torch-geometric\n","Installing collected packages: torch-scatter, torch-sparse, torch-cluster, torch-geometric\n","Successfully installed torch-cluster-1.6.1+pt113cu116 torch-geometric-2.2.0 torch-scatter-2.1.1+pt113cu116 torch-sparse-0.6.17+pt113cu116\n"]}],"source":["#@title [RUN] install\n","!pip install networkx\n","!pip install mycolorpy\n","!pip install colorama\n","!pip install ogb\n","\n","import torch\n","import os\n","!pip install torch-geometric torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ZLrrWpkk6xv-","executionInfo":{"status":"ok","timestamp":1679310359011,"user_tz":0,"elapsed":298,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["#@title [RUN] Import modules\n","import numpy as np\n","import seaborn as sns\n","import math\n","import itertools\n","import scipy as sp\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch_geometric\n","from torch_geometric.datasets import Planetoid, Coauthor\n","from torch_scatter import scatter_mean, scatter_max, scatter_sum\n","from torch_geometric.utils import to_dense_adj\n","from torch.nn import Embedding\n","from torch_geometric.typing import Adj\n","from ogb.nodeproppred import PygNodePropPredDataset\n","from torch_geometric.loader import NeighborLoader\n","from torch_geometric.utils import to_scipy_sparse_matrix\n","\n","#For FastRP\n","from scipy.sparse import coo_matrix, csr_matrix, csc_matrix, spdiags\n","from sklearn.preprocessing import normalize, scale, MultiLabelBinarizer\n","from sklearn import random_projection\n","\n","\n","import pdb\n","from datetime import datetime\n","\n","#for nice visualisations\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","from mycolorpy import colorlist as mcp\n","import matplotlib.cm as cm\n","\n","from typing import Mapping, Tuple, Sequence, List\n","import colorama\n","\n","import scipy.linalg\n","from scipy.linalg import block_diag"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"VLrKgQEuwgtb","executionInfo":{"status":"ok","timestamp":1679310106896,"user_tz":0,"elapsed":355,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["####### PLOTS #######\n","\n","def update_stats(training_stats, epoch_stats):\n","    \"\"\" Store metrics along the training\n","    Args:\n","      epoch_stats: dict containg metrics about one epoch\n","      training_stats: dict containing lists of metrics along training\n","    Returns:\n","      updated training_stats\n","    \"\"\"\n","    if training_stats is None:\n","        training_stats = {}\n","        for key in epoch_stats.keys():\n","            training_stats[key] = []\n","    for key,val in epoch_stats.items():\n","        training_stats[key].append(val)\n","    return training_stats\n","\n","def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n","    \"\"\" Create one plot for each metric stored in training_stats\n","    \"\"\"\n","    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n","    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n","    if len(stats_names)==1:\n","        ax = np.array([ax])\n","    for key, axx in zip(stats_names, ax.reshape(-1,)):\n","        axx.plot(\n","            training_stats['epoch'],\n","            training_stats[f'train_{key}'],\n","            label=f\"Training {key}\")\n","        axx.plot(\n","            training_stats['epoch'],\n","            training_stats[f'val_{key}'],\n","            label=f\"Validation {key}\")\n","        axx.set_xlabel(\"Training epoch\")\n","        axx.set_ylabel(key)\n","        axx.legend()\n","    plt.title(name)\n","\n","\n","def get_color_coded_str(i, color):\n","    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n","\n","def print_color_numpy(map, list_graphs):\n","    \"\"\" print matrix map in color according to list_graphs\n","    \"\"\"\n","    list_blocks = []\n","    for i,graph in enumerate(list_graphs):\n","        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n","        list_blocks += [block_i]\n","    block_color = block_diag(*list_blocks)\n","    \n","    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n","    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))"]},{"cell_type":"markdown","metadata":{"id":"82mrcZX0A3QR"},"source":["# Cora dataset\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBTnJEZWA-Iq","outputId":"04c85f2b-19cb-454b-ac70-11d9750846a7","executionInfo":{"status":"ok","timestamp":1679310113355,"user_tz":0,"elapsed":3640,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n","Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n","Processing...\n","Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"]},"metadata":{},"execution_count":4}],"source":["cora_dataset = Planetoid(\"/tmp/cora\", name=\"cora\", split=\"full\")\n","cora_data = cora_dataset[0]\n","cora_data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuZwDeBwJPZg","outputId":"013881ec-f785-412c-f807-8c0b906bc55d","executionInfo":{"status":"ok","timestamp":1679310115438,"user_tz":0,"elapsed":567,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training class sizes\n","tensor([160,  90, 196, 341, 196, 138,  87])\n","Validation class sizes\n","tensor([ 61,  36,  78, 158,  81,  57,  29])\n","Test class sizes\n","tensor([130,  91, 144, 319, 149, 103,  64])\n"]}],"source":["print(\"Training class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].train_mask]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].val_mask]))\n","print(\"Test class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].test_mask]))"]},{"cell_type":"markdown","metadata":{"id":"I9AoJuMmKQAO"},"source":["# OBGN-ARVIX dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jswepg0KKQAP","outputId":"b9ad4d34-ac36-478c-bf85-dd51cbf983f5","executionInfo":{"status":"ok","timestamp":1679310195818,"user_tz":0,"elapsed":78163,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"]},{"output_type":"stream","name":"stderr","text":["Downloaded 0.08 GB: 100%|██████████| 81/81 [00:07<00:00, 11.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/arxiv.zip\n"]},{"output_type":"stream","name":"stderr","text":["Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Loading necessary files...\n","This might take a while.\n","Processing graphs...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 1792.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Converting graphs into PyG objects...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 4275.54it/s]"]},{"output_type":"stream","name":"stdout","text":["Saving...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343], y=[169343])"]},"metadata":{},"execution_count":6}],"source":["d_name = \"ogbn-arxiv\"\n","\n","dataset = PygNodePropPredDataset(name = d_name)\n","\n","split_idx = dataset.get_idx_split()\n","train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n","arxiv_data = dataset[0]\n","arxiv_data.y = arxiv_data.y.squeeze()\n","arxiv_data.node_year = arxiv_data.node_year.squeeze()\n","arxiv_data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xj0Rb5CQKyLB","outputId":"0f1b3b56-1402-4f27-8e05-6513b0873b25","executionInfo":{"status":"ok","timestamp":1679310198809,"user_tz":0,"elapsed":290,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training class sizes\n","tensor([  437,   382,  3604,  1014,  2864,  2933,   703,   380,  4056,  2245,\n","         5182,   391,    21,  1290,   473,   248,  9998,   202,   402,  1873,\n","         1495,   304,  1268,  1539,  6989,   457,  2854,  1661, 16284,   239,\n","         4334,  1350,   270,   926,  5426,    75,  2506,  1615,  1100,  1551])\n","Validation class sizes\n","tensor([  74,  118,  502,  412, 1129,  779,  293,   75,  926,  230, 1232,  120,\n","           3,  440,   53,   68, 6846,  110,  138,  585,  268,   38,  249,  487,\n","        4458,  325,  710, 1074, 2273,   57, 2849,  586,   58,  125, 1027,   16,\n","         391,  273,  193,  209])\n","Test class sizes\n","tensor([   54,   187,   733,   654,  1869,  1246,   622,   134,  1250,   345,\n","         1455,   239,     5,   628,    71,    87, 10477,   203,   209,   419,\n","          313,    51,   386,   808, 10740,   475,  1041,  2066,  2849,   120,\n","         4631,   892,    83,   220,  1414,    36,   627,   481,   214,   269])\n"]}],"source":["print(\"Training class sizes\")\n","print(torch.bincount(arxiv_data.y[train_idx]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(arxiv_data.y[valid_idx]))\n","print(\"Test class sizes\")\n","print(torch.bincount(arxiv_data.y[test_idx]))"]},{"cell_type":"markdown","metadata":{"id":"xY5bb2rDEuqM"},"source":["#Coauthor dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9ZXzG7SE4oO","outputId":"cc663744-b60d-400e-b923-6c93bd238687","executionInfo":{"status":"ok","timestamp":1679310206789,"user_tz":0,"elapsed":4041,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/ms_academic_cs.npz\n","Processing...\n","Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["Data(x=[18333, 6805], edge_index=[2, 163788], y=[18333])"]},"metadata":{},"execution_count":8}],"source":["cs_dataset = Coauthor(\"/tmp/coauthor\", name=\"CS\")\n","cs_data = cs_dataset[0]\n","cs_data"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KO3BwlveIuNv","outputId":"14f69318-d8b0-4fcd-84ea-ff810b728b77","executionInfo":{"status":"ok","timestamp":1679310209268,"user_tz":0,"elapsed":293,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["10993 3668 3672\n"]}],"source":["# Create manual split, do 60:20:20 across classes\n","num_classes_cs = 15\n","train_mask_cs_indices = []\n","val_mask_cs_indices = []\n","test_mask_cs_indices = []\n","cs_labels = cs_data.y\n","for i in range(num_classes_cs):\n","\n","  class_i = np.where(cs_labels == i)[0]\n","  np.random.seed(0)\n","  np.random.shuffle(class_i)\n","\n","  num_samples = len(class_i)\n","  train_mask_cs_indices += (class_i[:int(num_samples*0.6)]).tolist() \n","  val_mask_cs_indices += (class_i[int(num_samples*0.6):int(num_samples*0.8)]).tolist() \n","  test_mask_cs_indices += (class_i[int(num_samples*0.8):]).tolist() \n","\n","print(len(train_mask_cs_indices), len(val_mask_cs_indices), len(test_mask_cs_indices))\n","# Create the masks for training\n","# Test mask \n","train_mask_cs = torch.full((len(cs_labels),), False)\n","train_mask_cs[train_mask_cs_indices] = True\n","# Val mask\n","val_mask_cs = torch.full((len(cs_labels),), False)\n","val_mask_cs[val_mask_cs_indices] = True\n","# Train mask\n","test_mask_cs = torch.full((len(cs_labels),), False)\n","test_mask_cs[test_mask_cs_indices] = True"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lO6lZz9SE6kK","outputId":"adbf639e-3a43-46ea-931c-f1f90cd056a8","executionInfo":{"status":"ok","timestamp":1679310214402,"user_tz":0,"elapsed":344,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training class sizes\n","tensor([ 424,  277, 1230,  257,  836, 1315,  222,  554,  465,   70,  866, 1219,\n","         252, 2481,  525])\n","Validation class sizes\n","tensor([142,  92, 410,  86, 279, 439,  74, 185, 155,  24, 289, 407,  84, 827,\n","        175])\n","Test class sizes\n","tensor([142,  93, 410,  86, 279, 439,  75, 185, 155,  24, 289, 407,  84, 828,\n","        176])\n"]}],"source":["print(\"Training class sizes\")\n","print(torch.bincount(cs_data.y[train_mask_cs]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(cs_data.y[val_mask_cs]))\n","print(\"Test class sizes\")\n","print(torch.bincount(cs_data.y[test_mask_cs]))"]},{"cell_type":"markdown","metadata":{"id":"KL8gKs07J9JP"},"source":["# Data saving / loading"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z80lU1V-Isky","outputId":"149fe655-c829-4def-9339-110ca748b524","executionInfo":{"status":"ok","timestamp":1679310236780,"user_tz":0,"elapsed":19517,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# use google drive for saving and loading information\n","from google.colab import drive\n","import pickle\n","import os\n","\n","drive.mount('/content/drive')\n","file_path = '/content/drive/MyDrive/L45_project/'\n","# create folder if it does not exist already\n","if not os.path.exists(file_path):\n","  os.mkdir(file_path) "]},{"cell_type":"code","execution_count":12,"metadata":{"id":"VhUfVQAZTWHu","executionInfo":{"status":"ok","timestamp":1679310239272,"user_tz":0,"elapsed":569,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["def save_training_info(training_stats: dict, node_embedding: torch.Tensor, filename: str):\n","  # write training data info to a file\n","  with open(file_path + filename + \".pkl\", 'wb') as fp:\n","    pickle.dump(training_stats, fp)\n","    print('Training stats saved successfully to file: ' + filename)\n","  # write node embedding to a file\n","  torch.save(node_embedding, file_path + filename + \"_emb.pt\")\n","  print('Node embedding saved successfully to file: ' + filename)\n","\n","\n","def load_training_info(filename: str):\n","  # load training stats dictionary \n","  with open(file_path + filename + \".pkl\", 'rb') as fp:\n","    train_stats = pickle.load(fp)\n","    print('Training stats successfully loaded from file: ' + filename)\n","  # load node embedding\n","  node_embedding = torch.load(file_path + filename + \"_emb.pt\")\n","  print('Node embedding successfully loaded from file: ' + filename)\n","  return train_stats, node_embedding\n","\n","# Final results is a list [seed, test result, [test per class accuracy], [training per class accuracy], [val per class accuracy]]\n","def save_final_results(final_results: List, filename: str):\n","  # write training data info to a file\n","  with open(file_path + filename + \".pkl\", 'ab') as fp:\n","    pickle.dump(final_results, fp)\n","    print('Final results saved successfully to file: ' + filename)\n","\n","# Returns an iterator which contains all the results from our various runs\n","def load_final_results(filename: str):\n","  with open(file_path + filename + \".pkl\", 'rb') as fp:\n","    print('Final results found in file: ' + filename)\n","    while True:\n","      try:\n","        # This notation creates a generator, which we can then iterate through\n","        yield pickle.load(fp)\n","      except EOFError:\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZECGPy9JTZrT","outputId":"ad72ff23-9243-4609-d4e7-6646392b8d11"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training stats saved successfully to file: testing\n","Node embedding saved successfully to file: testing\n","Training stats successfully loaded from file: testing\n","Node embedding successfully loaded from file: testing\n","{'c': [1, 2, 3], 'b': [4, 5, 6]} tensor([[ 1., -1.],\n","        [ 1., -1.]])\n"]}],"source":["test_dict = {'c':[1,2,3], 'b':[4,5,6]}\n","test_tensor = torch.tensor([[1., -1.], [1., -1.]])\n","save_training_info(test_dict, test_tensor, \"testing\")\n","recovered_val1, recovered_val2 = load_training_info(\"testing\")\n","print(recovered_val1, recovered_val2)"]},{"cell_type":"markdown","metadata":{"id":"yVyPiw_TBMj7"},"source":["# Model Wrappers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m_yBLcOs6V7v"},"outputs":[],"source":["from torch_geometric.nn import GCN\n","\n","class GCNModelWrapper(GCN):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # use one less layer as our final graph layer can downsize for us\n","    # super().__init__(in_channels, hidden_channels, num_layers-1)\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9xNcjhyBRmX"},"outputs":[],"source":["from torch_geometric.nn import GAT\n","\n","class GATModelWrapper(GAT):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int, v2: bool):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers, v2=v2)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3upq1VfKQAQ"},"outputs":[],"source":["from torch_geometric.nn import GraphSAGE\n","\n","class GraphSAGEModelWrapper(GraphSAGE):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7htrR7C1jc3a"},"outputs":[],"source":["from torch_geometric.nn import Node2Vec\n","from torch import Tensor\n","\n","class Node2VecWrapper(Node2Vec):\n","  def __init__(self, edge_index, embedding_size, walk_length, context_size, walks_per_node, num_negative_samples, p, q, sparse, out_channels):\n","    super().__init__(edge_index, embedding_dim=embedding_size, walk_length=walk_length,\n","                     context_size=context_size, walks_per_node=walks_per_node,\n","                     num_negative_samples=num_negative_samples, p=p, q=q, sparse=sparse)\n","    self.final_layer = nn.Linear(embedding_size, out_channels)\n","  def forward(self):\n","    x = super().forward()\n","    output = F.softmax(self.final_layer(x), dim=1)\n","    return output, x\n","  def test(\n","    self,\n","    train_z: Tensor,\n","    train_y: Tensor,\n","    test_z: Tensor,\n","    test_y: Tensor,\n","    solver: str = 'lbfgs',\n","    multi_class: str = 'auto',\n","    *args,\n","    **kwargs,\n","    ) -> float:\n","    r\"\"\"Evaluates latent space quality via a logistic regression downstream\n","    task.\"\"\"\n","    from sklearn.linear_model import LogisticRegression\n","\n","    clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n","                            **kwargs).fit(train_z.detach().cpu().numpy(),\n","                                          train_y.detach().cpu().numpy())\n","    y_pred = clf.predict(test_z.detach().cpu().numpy())\n","    return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIrBZ7ssNBzW"},"outputs":[],"source":["from torch_geometric.nn import GIN\n","\n","class GINWrapper(GIN):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"markdown","metadata":{"id":"5mLwBJNywK-9"},"source":["# Training code\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"cellView":"form","id":"-BLISzysQkdA","executionInfo":{"status":"ok","timestamp":1679310249042,"user_tz":0,"elapsed":292,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# @title [RUN] Hyperparameters GNN\n","\n","NUM_EPOCHS_CORA =  10 #@param {type:\"integer\"}\n","NUM_EPOCHS_ARVIX =  110 #@param {type:\"integer\"}\n","LR         = 0.01 #@param {type:\"number\"}\n","HIDDEN_DIM = 128  #@param {type:\"integer\"}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFTSH-Vuv4gk"},"outputs":[],"source":["# Code taken from L45 practical notebook\n","def train_gnn(X, edge_indices, y, mask, model, optimiser, device):\n","    model.train()\n","    # Put data on device\n","    X = X.to(device)\n","    edge_indices = edge_indices.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Train\n","    optimiser.zero_grad()\n","    y_out, _ = model(X, edge_indices)\n","    y_hat = y_out[mask]\n","    loss = F.cross_entropy(y_hat, y)\n","    loss.backward()\n","    optimiser.step()\n","    return loss.data\n","\n","# Training loop using subgraph batching from paper 'Inductive Representation Learning on Large Graphs' https://arxiv.org/pdf/1706.02216.pdf\n","def train_gnn_subgraph(data_batch, model, optimiser, device):\n","  total_loss = 0\n","  for batch in data_batch:\n","    # Put batch in device\n","    batch = batch.to(device)\n","    # Do training loop\n","    batch_size = batch.batch_size\n","    optimiser.zero_grad()\n","    y_out, _ = model(batch.x, batch.edge_index)\n","    y_out = y_out[:batch_size]\n","    batch_y = batch.y[:batch_size]\n","    batch_y = torch.reshape(batch_y, (-1,))\n","    loss = F.cross_entropy(y_out, batch_y)\n","    loss.backward()\n","    optimiser.step()\n","    # Keep a running total of the loss\n","    total_loss += float(loss)\n","\n","  # Get the average loss across all the batches\n","  loss = total_loss / len(data_batch)\n","  return loss\n","\n","def evaluate_gnn(X, edge_indices, y, mask, model, num_classes, device):\n","    model.eval()\n","    # Put data on device\n","    X = X.to(device)\n","    edge_indices = edge_indices.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Evaluate\n","    with torch.no_grad():\n","      y_out, node_embeddings = model(X, edge_indices)\n","    y_hat = y_out[mask]\n","    y_hat = y_hat.data.max(1)[1]\n","    num_correct = y_hat.eq(y.data).sum()\n","    num_total = len(y)\n","    accuracy = 100.0 * (num_correct/num_total)\n","\n","    # calculate per class accuracy\n","    values, counts = torch.unique(y_hat[y_hat == y.data], return_counts=True)\n","    per_class_counts = torch.zeros(num_classes)\n","    # make sure per_class_counts is on the correct device\n","    per_class_counts = per_class_counts.to(device)\n","    # allocate the number of counts per class\n","    for i, x in enumerate(values):\n","      per_class_counts[x] = counts[i]\n","    # find total number of data points per class in the split\n","    total_per_class = torch.bincount(y.data)\n","    per_class_accuracy = torch.div(per_class_counts, total_per_class)\n","\n","    return accuracy, per_class_accuracy, node_embeddings\n","    \n","# Training loop\n","def train_eval_loop_gnn(model, edge_indices, train_x, train_y, train_mask, valid_x, valid_y, valid_mask, \n","                             test_x, test_y, test_mask, num_classes, seed, filename, device, Cora, subgraph_batches=None):\n","    optimiser = optim.Adam(model.parameters(), lr=LR)\n","    training_stats = None\n","    # Choose number of epochs\n","    NUM_EPOCHS = NUM_EPOCHS_CORA if Cora else NUM_EPOCHS_ARVIX\n","    # Training loop\n","    for epoch in range(NUM_EPOCHS):\n","        # If subgraph batching is not provided, use the full graph for training. Otherwise use subgraph batch training regime\n","        if subgraph_batches is None:\n","          train_loss = train_gnn(train_x, edge_indices, train_y, train_mask, model, optimiser, device)\n","        else:\n","          train_loss = train_gnn_subgraph(subgraph_batches, model, optimiser, device)\n","        # Calculate accuracy on full graph  \n","        train_acc, train_class_acc, _ = evaluate_gnn(train_x, edge_indices, train_y, train_mask, model, num_classes, device)\n","        valid_acc, valid_class_acc, _ = evaluate_gnn(valid_x, edge_indices, valid_y, valid_mask, model, num_classes, device)\n","        if epoch % 10 == 0 or epoch == (NUM_EPOCHS-1):\n","            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n","            print(\"Per class train accuracy: \", train_class_acc)\n","            print(\"Per class val accuracy: \", valid_class_acc)\n","        # store the loss and the accuracy for the final plot\n","        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n","        training_stats = update_stats(training_stats, epoch_stats)\n","\n","    # Lets look at our final test performance\n","    # Only need to get the node embeddings once, take from the training evaluation call\n","    test_acc, test_class_acc, node_embeddings = evaluate_gnn(test_x, edge_indices, test_y, test_mask, model, num_classes, device)\n","    print(f\"Our final test accuracy for the GNN is: {test_acc:.3f}\")\n","    print(\"Final per class accuracy on test set: \", test_class_acc)\n","\n","    # Save training stats if on final iteration of the run\n","    save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","    # Save final results\n","    final_results_list = [seed, test_acc, test_class_acc, train_class_acc, valid_class_acc]\n","    save_final_results(final_results_list, filename)\n","    # Save final model weights incase we want to do further inference later\n","    torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","    return training_stats"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"A_O5m_YIaKY-","executionInfo":{"status":"ok","timestamp":1679310254447,"user_tz":0,"elapsed":357,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["def set_seeds(seed):\n","  print(\"SETTING SEEDS TO: \", str(seed))\n","  # seed the potential sources of randomness\n","  torch.manual_seed(seed)\n","  np.random.seed(seed)\n","  random.seed(seed)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"BDvu1pVpKQAR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679310483120,"user_tz":0,"elapsed":568,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"fbee638a-4a9b-4f67-ca14-e32468c6ed6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using Coauthor dataset\n"]}],"source":["# CHANGE: To name of model being tested\n","filename = \"FastRP-coauthor\"\n","dataset = \"Coauthor\"\n","# use 30 seeds which have been randomly generated using seed_list = [np.random.randint(4294967296 - 1) for i in range(30)]\n","seeds = [4193977854, 1863727779, 170173784, 2342954646, 116846604, 2105922959, 2739899259, 1024258131, 806299656, 880019963, 1818027900, 2135956485, 3710910636, 1517964140, 4083009686, 2455059856, 400225693, 89475662, 361232447, 3647665043, 1221215631, 2036056847, 1860537279, 516507873, 3692371949, 3300171104, 2794978777, 3303475786, 2952735006, 572297925]\n","\n","# create folder for saving all model info into if it does not exist already\n","if not os.path.exists(file_path+filename+\"/\"):\n","  os.mkdir(file_path+filename+\"/\")\n","\n","if dataset == \"Cora\":\n","  print(\"Using Cora dataset\")\n","  # Get the edge indices and node features for our model. General set up variables for running with all the models\n","  edge_indices = cora_data.edge_index\n","  node_features = cora_data.x\n","  neighbour_dataset = cora_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = cora_data.train_mask\n","  train_y = cora_data.y[train_mask]\n","  valid_mask = cora_data.val_mask\n","  valid_y = cora_data.y[valid_mask]\n","  test_mask = cora_data.test_mask\n","  test_y = cora_data.y[test_mask]\n","\n","  num_classes = 7\n","  is_cora=True\n","\n","elif dataset==\"Coauthor\":\n","  print(\"Using Coauthor dataset\")\n","  # Get the edge indices and node features for our model. General set up variables for running with all the models\n","  edge_indices = cs_data.edge_index\n","  node_features = cs_data.x\n","  neighbour_dataset = cs_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_mask_cs\n","  train_y = cs_data.y[train_mask]\n","  valid_mask = val_mask_cs\n","  valid_y = cs_data.y[valid_mask]\n","  test_mask = test_mask_cs\n","  test_y = cs_data.y[test_mask]\n","\n","  num_classes = 15\n","  is_cora=True\n","\n","# Otherwise we are using arvix dataset\n","else:\n","  print(\"Using Arvix dataset\")\n","  # Get the edge indices and node features for our model\n","  edge_indices = arxiv_data.edge_index\n","  node_features = arxiv_data.x\n","  neighbour_dataset = arxiv_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_idx\n","  train_y = arxiv_data.y[train_mask]\n","  valid_mask = valid_idx\n","  valid_y = arxiv_data.y[valid_mask]\n","  test_mask = test_idx\n","  test_y = arxiv_data.y[test_mask]\n","\n","  num_classes = 40\n","  is_cora = False\n"]},{"cell_type":"markdown","metadata":{"id":"fGgiIp_fKQAR"},"source":["# Training Loops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKAFIuc3YlIf"},"outputs":[],"source":["# Use to flush GPU memory if it gets too full\n","import gc\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rl6KVverQy7C"},"outputs":[],"source":["# General training loop for all models except GraphSAGE, using the whole graph in training instead of using subgraph batching\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Create the model\n","  model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes, v2=True)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVevwMOOKQAS"},"outputs":[],"source":["# Training loop for GraphSAGE which using subgraph batches instead of the entire graph\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Original paper uses neighbourhood sizes  S1 = 25 and S2 = 10 so this is what we use\n","  train_loader = NeighborLoader(neighbour_dataset, num_neighbors = [25, 10], batch_size=1024, input_nodes=train_mask)\n","\n","  # Create the model\n","  model = GraphSAGEModelWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora, subgraph_batches=train_loader)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLY-SWcPOjRa"},"outputs":[],"source":["# Training loop for GraphSAGE which using subgraph batches instead of the entire graph\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Original paper uses neighbourhood sizes  S1 = 25 and S2 = 10 so this is what we use\n","  train_loader = NeighborLoader(neighbour_dataset, num_neighbors = [25, 10], batch_size=1024, input_nodes=train_mask)\n","\n","  # Create the model\n","  model = GINWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora, subgraph_batches=train_loader)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"u4GMM4D5dLoB"},"source":["# TESTING LOADING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35RkMAgK8EHw"},"outputs":[],"source":["final_results = load_final_results(filename)\n","for r in final_results:\n","  print(r)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ3GQQld9b97"},"outputs":[],"source":["training_stats_1, embedding = load_training_info(filename+\"_1\")\n","plot_stats(training_stats_1, name=\"Testing\")\n","print(embedding)\n","print(node_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1nR7AjndQJn"},"outputs":[],"source":["# Loading stored model weights\n","model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n","model.load_state_dict(torch.load(file_path+filename+\"/\"+\"GATV2_1_model.pt\"))\n","model.eval()"]},{"cell_type":"markdown","metadata":{"id":"GubPzc9IQyP3"},"source":["- Plot graph with average training stats\n","- Save node embeddings for each run\n","- Save training stats for each run\n","- Save test accuracy for each run\n"]},{"cell_type":"markdown","metadata":{"id":"4tdBQvy4rVQq"},"source":["# FastRP"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"IHOX1AH0rVQq","executionInfo":{"status":"ok","timestamp":1679310282861,"user_tz":0,"elapsed":350,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["class FastRPEmbeddingWrapper(nn.Module):\n","  def __init__(self, input_dim, num_classes):\n","      super().__init__()\n","      self.linear = nn.Linear(input_dim, num_classes)\n","\n","  def forward(self, x):\n","      x = self.linear(x)\n","      return x"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"1Vv7X1p6rVQq","executionInfo":{"status":"ok","timestamp":1679310284927,"user_tz":0,"elapsed":286,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# Copied from https://github.com/GTmac/FastRP/blob/master/fastrp.py\n","# projection method: choose from Gaussian and Sparse\n","# input matrix: choose from adjacency and transition matrix\n","# alpha adjusts the weighting of nodes according to their degree\n","def fastrp_projection(A, q=3, dim=128, projection_method='gaussian', input_matrix='adj', alpha=None):\n","    assert input_matrix == 'adj' or input_matrix == 'trans'\n","    assert projection_method == 'gaussian' or projection_method == 'sparse'\n","    \n","    if input_matrix == 'adj':\n","        M = A\n","    else:\n","        N = A.shape[0]\n","        normalizer = spdiags(np.squeeze(1.0 / csc_matrix.sum(A, axis=1) ), 0, N, N)\n","        M = normalizer @ A\n","    # Gaussian projection matrix\n","    if projection_method == 'gaussian':\n","        transformer = random_projection.GaussianRandomProjection(n_components=dim, random_state=42)\n","    # Sparse projection matrix\n","    else:\n","        transformer = random_projection.SparseRandomProjection(n_components=dim, random_state=42)\n","    Y = transformer.fit(M)\n","    # Random projection for A\n","    if alpha is not None:\n","        Y.components_ = Y.components_ @ spdiags( \\\n","                        np.squeeze(np.power(csc_matrix.sum(A, axis=1), alpha)), 0, N, N)\n","    cur_U = transformer.transform(M)\n","    U_list = [cur_U]\n","    \n","    for i in range(2, q + 1):\n","        cur_U = M @ cur_U\n","        U_list.append(cur_U)\n","    return U_list\n","\n","# When weights is None, concatenate instead of linearly combines the embeddings from different powers of A\n","def fastrp_merge(U_list, weights, normalization=False):\n","    dense_U_list = [_U.todense() for _U in U_list] if type(U_list[0]) == csc_matrix else U_list\n","    _U_list = [normalize(_U, norm='l2', axis=1) for _U in dense_U_list] if normalization else dense_U_list\n","\n","    if weights is None:\n","        return np.concatenate(_U_list, axis=1)\n","    U = np.zeros_like(_U_list[0])\n","    for cur_U, weight in zip(_U_list, weights):\n","        U += cur_U * weight\n","    # U = scale(U.todense())\n","    # U = normalize(U.todense(), norm='l2', axis=1)\n","    return scale(np.asarray(U.todense())) if type(U) == csr_matrix else scale(np.asarray(U))\n","\n","# A is always the adjacency matrix\n","# the choice between adj matrix and trans matrix is decided in the conf\n","def fastrp_wrapper(A, conf):\n","    U_list = fastrp_projection(A,\n","                               q=len(conf['weights']),\n","                               dim=conf['dim'],\n","                               projection_method=conf['projection_method'],\n","                               input_matrix=conf['input_matrix'],\n","                               alpha=conf['alpha'],\n","    )\n","    U = fastrp_merge(U_list, conf['weights'], conf['normalization'])\n","    return U"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"l-Ch32qNrVQq","executionInfo":{"status":"ok","timestamp":1679310288849,"user_tz":0,"elapsed":402,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# Code adpated from L45 practical notebook\n","def train_embedding_classifier(X, y, mask, model, optimiser, device):\n","    model.train()\n","    # Put data on device\n","    X = X.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Train\n","    optimiser.zero_grad()\n","    y_out = model(X)\n","    y_hat = y_out[mask]\n","    loss = F.cross_entropy(y_hat, y)\n","    loss.backward()\n","    optimiser.step()\n","    return loss.data\n","\n","def evaluate_embedding_classifier(X, y, mask, model, num_classes, device):\n","    model.eval()\n","    # Put data on device\n","    X = X.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Evaluate\n","    with torch.no_grad():\n","      y_out = model(X)\n","    y_hat = y_out[mask]\n","    y_hat = y_hat.data.max(1)[1]\n","    num_correct = y_hat.eq(y.data).sum()\n","    num_total = len(y)\n","    accuracy = 100.0 * (num_correct/num_total)\n","\n","    # calculate per class accuracy\n","    values, counts = torch.unique(y_hat[y_hat == y.data], return_counts=True)\n","    per_class_counts = torch.zeros(num_classes)\n","    # make sure per_class_counts is on the correct device\n","    per_class_counts = per_class_counts.to(device)\n","    # allocate the number of counts per class\n","    for i, x in enumerate(values):\n","      per_class_counts[x] = counts[i]\n","    # find total number of data points per class in the split\n","    total_per_class = torch.bincount(y.data)\n","    per_class_accuracy = torch.div(per_class_counts, total_per_class)\n","\n","    return accuracy, per_class_accuracy\n","    \n","# Training loop\n","def train_eval_loop_embedding_classifier(model, embeddings, train_y, train_mask, \n","                                         valid_y, valid_mask, test_y, test_mask, num_classes, seed, filename, device, Cora):\n","    optimiser = optim.Adam(model.parameters(), lr=LR)\n","    training_stats = None\n","    # Choose number of epochs\n","    NUM_EPOCHS = NUM_EPOCHS_CORA if Cora else NUM_EPOCHS_ARVIX\n","    # Training loop\n","    for epoch in range(NUM_EPOCHS):\n","        train_loss = train_embedding_classifier(embeddings, train_y, train_mask, model, optimiser, device)\n","        # Calculate accuracy on full graph  \n","        train_acc, train_class_acc = evaluate_embedding_classifier(embeddings, train_y, train_mask, model, num_classes, device)\n","        valid_acc, valid_class_acc = evaluate_embedding_classifier(embeddings, valid_y, valid_mask, model, num_classes, device)\n","        if epoch % 10 == 0 or epoch == (NUM_EPOCHS-1):\n","            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n","            print(\"Per class train accuracy: \", train_class_acc)\n","            print(\"Per class val accuracy: \", valid_class_acc)\n","        # store the loss and the accuracy for the final plot\n","        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n","        training_stats = update_stats(training_stats, epoch_stats)\n","\n","    # Lets look at our final test performance\n","    # Only need to get the node embeddings once, take from the training evaluation call\n","    test_acc, test_class_acc = evaluate_embedding_classifier(embeddings, test_y, test_mask, model, num_classes, device)\n","    print(f\"Our final test accuracy for the GNN is: {test_acc:.3f}\")\n","    print(\"Final per class accuracy on test set: \", test_class_acc)\n","\n","    # Save training stats if on final iteration of the run, the node embeddings are actually passed in for training, where  \n","    node_embeddings = embeddings\n","    save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","    # Save final results\n","    final_results_list = [seed, test_acc, test_class_acc, train_class_acc, valid_class_acc]\n","    save_final_results(final_results_list, filename)\n","    # Save final model weights incase we want to do further inference later\n","    torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","    return training_stats"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"76Sx0lNcrVQq","executionInfo":{"status":"ok","timestamp":1679310515250,"user_tz":0,"elapsed":19900,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"1aa8c07c-876b-46f0-af10-acec53221af0"},"outputs":[{"output_type":"stream","name":"stdout","text":["SETTING SEEDS TO:  4193977854\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  4193977854\n","Epoch 0 with train loss: 2.932 train accuracy: 19.130 validation accuracy: 18.239\n","Per class train accuracy:  tensor([0.2005, 0.0794, 0.4341, 0.2257, 0.0395, 0.4129, 0.0676, 0.3249, 0.0860,\n","        0.0000, 0.3418, 0.0623, 0.2738, 0.0560, 0.0248], device='cuda:0')\n","Per class val accuracy:  tensor([0.2113, 0.0435, 0.4341, 0.1279, 0.0323, 0.4032, 0.0405, 0.3351, 0.0903,\n","        0.0000, 0.3149, 0.0565, 0.2619, 0.0484, 0.0286], device='cuda:0')\n","Epoch 9 with train loss: 1.015 train accuracy: 73.874 validation accuracy: 72.710\n","Per class train accuracy:  tensor([0.4363, 0.6462, 0.7553, 0.4786, 0.7823, 0.7194, 0.4414, 0.7960, 0.6430,\n","        0.3286, 0.8984, 0.7933, 0.8175, 0.7340, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.4648, 0.5543, 0.7341, 0.3488, 0.7455, 0.6948, 0.3919, 0.8000, 0.5806,\n","        0.1667, 0.9100, 0.7764, 0.8929, 0.7545, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.829\n","Final per class accuracy on test set:  tensor([0.5000, 0.5376, 0.7512, 0.3953, 0.8208, 0.6651, 0.4133, 0.8216, 0.6516,\n","        0.2500, 0.8927, 0.7813, 0.8095, 0.7609, 0.9261], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_4193977854\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_4193977854\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1863727779\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1863727779\n","Epoch 0 with train loss: 2.837 train accuracy: 24.115 validation accuracy: 23.882\n","Per class train accuracy:  tensor([0.0377, 0.3682, 0.1325, 0.1518, 0.3002, 0.1452, 0.0270, 0.1913, 0.2925,\n","        0.0571, 0.6028, 0.3585, 0.2183, 0.1395, 0.5276], device='cuda:0')\n","Per class val accuracy:  tensor([0.0352, 0.3478, 0.1293, 0.1395, 0.3118, 0.1344, 0.0135, 0.1514, 0.2194,\n","        0.0833, 0.6021, 0.3882, 0.2262, 0.1427, 0.5371], device='cuda:0')\n","Epoch 9 with train loss: 1.013 train accuracy: 74.839 validation accuracy: 73.582\n","Per class train accuracy:  tensor([0.3915, 0.6823, 0.7520, 0.5253, 0.8074, 0.7125, 0.4730, 0.8141, 0.6473,\n","        0.6000, 0.9030, 0.8179, 0.8452, 0.7412, 0.8952], device='cuda:0')\n","Per class val accuracy:  tensor([0.4014, 0.5217, 0.7268, 0.4651, 0.7742, 0.6697, 0.4054, 0.8162, 0.5935,\n","        0.4583, 0.9100, 0.8354, 0.8810, 0.7606, 0.8914], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.483\n","Final per class accuracy on test set:  tensor([0.3944, 0.5806, 0.7512, 0.3953, 0.8315, 0.6811, 0.4400, 0.8324, 0.6129,\n","        0.5833, 0.8858, 0.8133, 0.8214, 0.7717, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1863727779\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1863727779\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  170173784\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  170173784\n","Epoch 0 with train loss: 2.940 train accuracy: 17.793 validation accuracy: 17.475\n","Per class train accuracy:  tensor([0.1863, 0.1552, 0.0927, 0.0661, 0.1507, 0.2905, 0.1306, 0.0361, 0.3849,\n","        0.1000, 0.1559, 0.1936, 0.1270, 0.0947, 0.6133], device='cuda:0')\n","Per class val accuracy:  tensor([0.2394, 0.1630, 0.0878, 0.0814, 0.1290, 0.2802, 0.1081, 0.0432, 0.3484,\n","        0.1250, 0.1349, 0.1941, 0.1071, 0.1028, 0.6000], device='cuda:0')\n","Epoch 9 with train loss: 1.005 train accuracy: 74.829 validation accuracy: 73.964\n","Per class train accuracy:  tensor([0.4599, 0.6751, 0.7455, 0.4903, 0.8014, 0.7171, 0.4820, 0.8249, 0.6323,\n","        0.4857, 0.8961, 0.7990, 0.8294, 0.7537, 0.8895], device='cuda:0')\n","Per class val accuracy:  tensor([0.5000, 0.5543, 0.7268, 0.3721, 0.7634, 0.6765, 0.4189, 0.8162, 0.5290,\n","        0.2500, 0.8997, 0.8329, 0.9048, 0.7836, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.673\n","Final per class accuracy on test set:  tensor([0.5141, 0.5484, 0.7293, 0.3721, 0.8315, 0.6743, 0.4400, 0.8324, 0.6387,\n","        0.4583, 0.8893, 0.7813, 0.7976, 0.7923, 0.9318], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_170173784\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_170173784\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2342954646\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2342954646\n","Epoch 0 with train loss: 2.813 train accuracy: 25.780 validation accuracy: 25.654\n","Per class train accuracy:  tensor([0.0802, 0.2166, 0.1854, 0.2296, 0.6615, 0.0783, 0.1081, 0.8123, 0.1290,\n","        0.1429, 0.3025, 0.2223, 0.2778, 0.2418, 0.0952], device='cuda:0')\n","Per class val accuracy:  tensor([0.0915, 0.2283, 0.1659, 0.1395, 0.6523, 0.0661, 0.0946, 0.7946, 0.1161,\n","        0.2500, 0.3114, 0.2482, 0.2857, 0.2467, 0.1086], device='cuda:0')\n","Epoch 9 with train loss: 1.007 train accuracy: 74.684 validation accuracy: 72.492\n","Per class train accuracy:  tensor([0.4222, 0.6534, 0.7837, 0.4903, 0.8062, 0.6692, 0.4910, 0.8141, 0.6925,\n","        0.4429, 0.8845, 0.8138, 0.8413, 0.7461, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.4789, 0.5109, 0.7610, 0.3488, 0.7419, 0.5900, 0.4459, 0.8054, 0.6323,\n","        0.3750, 0.8962, 0.8133, 0.9048, 0.7570, 0.8857], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.529\n","Final per class accuracy on test set:  tensor([0.4859, 0.5376, 0.7659, 0.3605, 0.8351, 0.6128, 0.4267, 0.8270, 0.6645,\n","        0.3333, 0.8720, 0.7813, 0.8571, 0.7669, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2342954646\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2342954646\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  116846604\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  116846604\n","Epoch 0 with train loss: 2.693 train accuracy: 33.285 validation accuracy: 33.152\n","Per class train accuracy:  tensor([0.0566, 0.2996, 0.0390, 0.0856, 0.6483, 0.0776, 0.0405, 0.6444, 0.2323,\n","        0.3000, 0.7194, 0.5012, 0.4325, 0.3732, 0.1410], device='cuda:0')\n","Per class val accuracy:  tensor([0.0423, 0.2065, 0.0366, 0.0698, 0.6022, 0.0888, 0.0946, 0.6216, 0.2452,\n","        0.4583, 0.7197, 0.5012, 0.5000, 0.3833, 0.1200], device='cuda:0')\n","Epoch 9 with train loss: 0.990 train accuracy: 74.811 validation accuracy: 73.228\n","Per class train accuracy:  tensor([0.3986, 0.6823, 0.7374, 0.5019, 0.8182, 0.6890, 0.4820, 0.8213, 0.6774,\n","        0.4857, 0.8949, 0.7990, 0.8373, 0.7658, 0.8933], device='cuda:0')\n","Per class val accuracy:  tensor([0.3873, 0.5109, 0.7220, 0.3372, 0.7599, 0.6446, 0.4054, 0.8054, 0.6258,\n","        0.3750, 0.9031, 0.8133, 0.9048, 0.7884, 0.9086], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.210\n","Final per class accuracy on test set:  tensor([0.3732, 0.5699, 0.7341, 0.4070, 0.8351, 0.6446, 0.4133, 0.8378, 0.6968,\n","        0.5000, 0.8824, 0.7887, 0.8333, 0.7911, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_116846604\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_116846604\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2105922959\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2105922959\n","Epoch 0 with train loss: 2.902 train accuracy: 20.913 validation accuracy: 21.074\n","Per class train accuracy:  tensor([0.0755, 0.0903, 0.1106, 0.0545, 0.2620, 0.0555, 0.0541, 0.0921, 0.3462,\n","        0.4286, 0.2783, 0.5045, 0.0714, 0.1959, 0.3543], device='cuda:0')\n","Per class val accuracy:  tensor([0.0915, 0.1087, 0.0976, 0.1163, 0.2796, 0.0342, 0.0811, 0.0811, 0.2774,\n","        0.2500, 0.2664, 0.5135, 0.0952, 0.2116, 0.3886], device='cuda:0')\n","Epoch 9 with train loss: 1.007 train accuracy: 74.593 validation accuracy: 73.391\n","Per class train accuracy:  tensor([0.4222, 0.6859, 0.7537, 0.4669, 0.7907, 0.6479, 0.4955, 0.8141, 0.6731,\n","        0.5429, 0.8880, 0.8302, 0.8373, 0.7638, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.4648, 0.5761, 0.7171, 0.4070, 0.7491, 0.5923, 0.4459, 0.8162, 0.5935,\n","        0.2917, 0.9031, 0.8452, 0.9048, 0.7872, 0.9143], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.183\n","Final per class accuracy on test set:  tensor([0.4437, 0.5806, 0.7293, 0.4419, 0.8065, 0.5991, 0.4133, 0.8270, 0.6645,\n","        0.5000, 0.8858, 0.8305, 0.8452, 0.7935, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2105922959\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2105922959\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2739899259\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2739899259\n","Epoch 0 with train loss: 2.844 train accuracy: 25.480 validation accuracy: 24.291\n","Per class train accuracy:  tensor([0.0660, 0.4693, 0.2732, 0.0389, 0.1053, 0.1452, 0.1667, 0.6769, 0.0194,\n","        0.0857, 0.3430, 0.3134, 0.1270, 0.3035, 0.2419], device='cuda:0')\n","Per class val accuracy:  tensor([0.0423, 0.3913, 0.2512, 0.0698, 0.0681, 0.1367, 0.1622, 0.6162, 0.0387,\n","        0.0000, 0.3287, 0.3489, 0.1071, 0.2975, 0.2114], device='cuda:0')\n","Epoch 9 with train loss: 1.007 train accuracy: 74.093 validation accuracy: 73.201\n","Per class train accuracy:  tensor([0.4245, 0.6895, 0.7415, 0.4708, 0.8110, 0.6852, 0.5270, 0.7888, 0.6452,\n","        0.3000, 0.8857, 0.7867, 0.8452, 0.7549, 0.9048], device='cuda:0')\n","Per class val accuracy:  tensor([0.4577, 0.5435, 0.7049, 0.3837, 0.7634, 0.6788, 0.4459, 0.8000, 0.5806,\n","        0.1250, 0.8962, 0.7912, 0.9048, 0.7836, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.720\n","Final per class accuracy on test set:  tensor([0.4930, 0.5591, 0.7366, 0.3837, 0.8387, 0.6515, 0.4533, 0.8108, 0.6710,\n","        0.1667, 0.8789, 0.7690, 0.8452, 0.7729, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2739899259\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2739899259\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1024258131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1024258131\n","Epoch 0 with train loss: 3.000 train accuracy: 15.237 validation accuracy: 15.213\n","Per class train accuracy:  tensor([0.0755, 0.2202, 0.0732, 0.1362, 0.0849, 0.3840, 0.0495, 0.0632, 0.1935,\n","        0.0286, 0.0300, 0.0656, 0.2937, 0.2072, 0.0933], device='cuda:0')\n","Per class val accuracy:  tensor([0.0845, 0.2065, 0.0805, 0.1395, 0.0896, 0.3895, 0.0405, 0.0703, 0.1419,\n","        0.0000, 0.0415, 0.0565, 0.4405, 0.1947, 0.0857], device='cuda:0')\n","Epoch 9 with train loss: 1.003 train accuracy: 74.684 validation accuracy: 73.282\n","Per class train accuracy:  tensor([0.4269, 0.6643, 0.7545, 0.4864, 0.8026, 0.7247, 0.4820, 0.8014, 0.6581,\n","        0.3571, 0.8857, 0.8097, 0.8452, 0.7469, 0.8876], device='cuda:0')\n","Per class val accuracy:  tensor([0.4718, 0.5761, 0.7268, 0.3605, 0.7491, 0.6811, 0.4189, 0.7946, 0.5677,\n","        0.3750, 0.8927, 0.8133, 0.9167, 0.7690, 0.8800], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.292\n","Final per class accuracy on test set:  tensor([0.4577, 0.5914, 0.7415, 0.3721, 0.8423, 0.6993, 0.4400, 0.7892, 0.6452,\n","        0.2083, 0.8685, 0.8034, 0.8333, 0.7705, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1024258131\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1024258131\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  806299656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  806299656\n","Epoch 0 with train loss: 2.826 train accuracy: 25.989 validation accuracy: 27.181\n","Per class train accuracy:  tensor([0.0613, 0.3213, 0.0951, 0.0778, 0.4151, 0.0935, 0.1937, 0.3610, 0.4839,\n","        0.0143, 0.2067, 0.5160, 0.2817, 0.2459, 0.3371], device='cuda:0')\n","Per class val accuracy:  tensor([0.0563, 0.3587, 0.0683, 0.0698, 0.4337, 0.1298, 0.1216, 0.3784, 0.3613,\n","        0.0000, 0.2526, 0.5749, 0.2738, 0.2491, 0.4171], device='cuda:0')\n","Epoch 9 with train loss: 1.025 train accuracy: 73.765 validation accuracy: 72.383\n","Per class train accuracy:  tensor([0.4575, 0.6679, 0.7496, 0.4319, 0.7799, 0.6760, 0.4820, 0.8231, 0.6495,\n","        0.3714, 0.8995, 0.8072, 0.8413, 0.7344, 0.8914], device='cuda:0')\n","Per class val accuracy:  tensor([0.4718, 0.5435, 0.7293, 0.3256, 0.7419, 0.6241, 0.4324, 0.8216, 0.5613,\n","        0.2083, 0.9135, 0.8378, 0.8929, 0.7449, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.393\n","Final per class accuracy on test set:  tensor([0.4225, 0.5914, 0.7512, 0.3837, 0.8136, 0.6264, 0.4133, 0.8378, 0.6839,\n","        0.3750, 0.8824, 0.8084, 0.8333, 0.7500, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_806299656\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_806299656\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  880019963\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  880019963\n","Epoch 0 with train loss: 2.817 train accuracy: 24.597 validation accuracy: 23.746\n","Per class train accuracy:  tensor([0.2618, 0.1191, 0.3358, 0.0584, 0.2105, 0.1179, 0.2387, 0.1065, 0.1763,\n","        0.0286, 0.0693, 0.5012, 0.2262, 0.2072, 0.6914], device='cuda:0')\n","Per class val accuracy:  tensor([0.2817, 0.1304, 0.3366, 0.0349, 0.1685, 0.0957, 0.2432, 0.0703, 0.1419,\n","        0.0000, 0.0657, 0.5037, 0.2619, 0.2007, 0.7086], device='cuda:0')\n","Epoch 9 with train loss: 0.997 train accuracy: 74.857 validation accuracy: 72.955\n","Per class train accuracy:  tensor([0.4363, 0.6462, 0.7659, 0.4942, 0.8038, 0.6715, 0.5360, 0.8014, 0.6796,\n","        0.4286, 0.8903, 0.8244, 0.8611, 0.7537, 0.8933], device='cuda:0')\n","Per class val accuracy:  tensor([0.4718, 0.5109, 0.7293, 0.3837, 0.7419, 0.6059, 0.4730, 0.8108, 0.6065,\n","        0.2917, 0.9100, 0.8305, 0.9048, 0.7715, 0.8914], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.374\n","Final per class accuracy on test set:  tensor([0.4577, 0.5161, 0.7585, 0.3953, 0.8459, 0.6560, 0.4667, 0.8324, 0.6710,\n","        0.3750, 0.8789, 0.7936, 0.8571, 0.7693, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_880019963\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_880019963\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1818027900\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1818027900\n","Epoch 0 with train loss: 2.779 train accuracy: 27.399 validation accuracy: 27.535\n","Per class train accuracy:  tensor([0.1392, 0.2274, 0.2699, 0.0934, 0.1280, 0.1954, 0.1126, 0.5289, 0.1333,\n","        0.2571, 0.7448, 0.4200, 0.1270, 0.1237, 0.5257], device='cuda:0')\n","Per class val accuracy:  tensor([0.1056, 0.1630, 0.2463, 0.1163, 0.1613, 0.1526, 0.1216, 0.5243, 0.1290,\n","        0.1250, 0.7682, 0.4570, 0.1310, 0.1475, 0.4971], device='cuda:0')\n","Epoch 9 with train loss: 1.008 train accuracy: 73.847 validation accuracy: 72.764\n","Per class train accuracy:  tensor([0.4080, 0.6931, 0.7602, 0.4397, 0.7931, 0.6738, 0.4820, 0.8014, 0.6774,\n","        0.3143, 0.8972, 0.8097, 0.8532, 0.7364, 0.8800], device='cuda:0')\n","Per class val accuracy:  tensor([0.4437, 0.5543, 0.7366, 0.3488, 0.7384, 0.6310, 0.4189, 0.8108, 0.5935,\n","        0.2083, 0.9170, 0.8256, 0.9048, 0.7594, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.428\n","Final per class accuracy on test set:  tensor([0.4930, 0.5806, 0.7561, 0.3837, 0.8244, 0.6583, 0.4133, 0.8378, 0.7032,\n","        0.2500, 0.8893, 0.8010, 0.8333, 0.7657, 0.9034], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1818027900\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1818027900\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2135956485\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2135956485\n","Epoch 0 with train loss: 2.882 train accuracy: 21.423 validation accuracy: 20.311\n","Per class train accuracy:  tensor([0.1108, 0.3394, 0.1577, 0.0661, 0.1651, 0.2905, 0.0450, 0.4928, 0.1226,\n","        0.0857, 0.1501, 0.1222, 0.5238, 0.1552, 0.6495], device='cuda:0')\n","Per class val accuracy:  tensor([0.1127, 0.2174, 0.1683, 0.0698, 0.1685, 0.3189, 0.0676, 0.4757, 0.0903,\n","        0.0417, 0.1661, 0.0786, 0.5357, 0.1354, 0.5829], device='cuda:0')\n","Epoch 9 with train loss: 1.005 train accuracy: 74.575 validation accuracy: 73.364\n","Per class train accuracy:  tensor([0.4198, 0.6823, 0.7577, 0.5058, 0.7931, 0.6837, 0.5180, 0.7960, 0.6538,\n","        0.4714, 0.8961, 0.7916, 0.8373, 0.7610, 0.9029], device='cuda:0')\n","Per class val accuracy:  tensor([0.4437, 0.5652, 0.7488, 0.4302, 0.7348, 0.6697, 0.4054, 0.7946, 0.5871,\n","        0.2917, 0.9066, 0.7887, 0.9048, 0.7751, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.319\n","Final per class accuracy on test set:  tensor([0.5070, 0.6129, 0.7634, 0.4186, 0.8172, 0.6492, 0.4267, 0.8108, 0.6645,\n","        0.2917, 0.8789, 0.7789, 0.8452, 0.7778, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2135956485\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2135956485\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3710910636\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3710910636\n","Epoch 0 with train loss: 2.951 train accuracy: 19.039 validation accuracy: 18.484\n","Per class train accuracy:  tensor([0.0401, 0.0469, 0.1902, 0.0156, 0.1232, 0.0996, 0.0856, 0.0939, 0.1376,\n","        0.0429, 0.6570, 0.1715, 0.3730, 0.1387, 0.4514], device='cuda:0')\n","Per class val accuracy:  tensor([0.0352, 0.0326, 0.1683, 0.0349, 0.1147, 0.1002, 0.1081, 0.1027, 0.1290,\n","        0.0000, 0.6990, 0.1794, 0.3690, 0.1258, 0.3714], device='cuda:0')\n","Epoch 9 with train loss: 1.031 train accuracy: 73.811 validation accuracy: 73.037\n","Per class train accuracy:  tensor([0.3821, 0.6679, 0.7813, 0.4825, 0.8050, 0.6798, 0.5045, 0.7996, 0.6559,\n","        0.3429, 0.8938, 0.7966, 0.8373, 0.7295, 0.8857], device='cuda:0')\n","Per class val accuracy:  tensor([0.4296, 0.5217, 0.7634, 0.3721, 0.7599, 0.6697, 0.4324, 0.8054, 0.6000,\n","        0.2083, 0.9031, 0.8231, 0.8929, 0.7376, 0.9086], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.992\n","Final per class accuracy on test set:  tensor([0.4296, 0.5484, 0.7829, 0.4535, 0.8208, 0.6287, 0.4000, 0.8162, 0.6710,\n","        0.4583, 0.8997, 0.7912, 0.8333, 0.7633, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3710910636\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3710910636\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1517964140\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1517964140\n","Epoch 0 with train loss: 2.909 train accuracy: 24.015 validation accuracy: 22.574\n","Per class train accuracy:  tensor([0.0472, 0.0253, 0.3211, 0.0311, 0.4163, 0.1909, 0.0315, 0.5253, 0.3269,\n","        0.0143, 0.3268, 0.0263, 0.4167, 0.1419, 0.7390], device='cuda:0')\n","Per class val accuracy:  tensor([0.0282, 0.0000, 0.2854, 0.0233, 0.4194, 0.1777, 0.0405, 0.4919, 0.2194,\n","        0.0000, 0.3080, 0.0270, 0.4405, 0.1439, 0.7200], device='cuda:0')\n","Epoch 9 with train loss: 1.039 train accuracy: 73.592 validation accuracy: 72.056\n","Per class train accuracy:  tensor([0.4505, 0.6390, 0.7634, 0.4358, 0.8110, 0.6829, 0.5090, 0.8177, 0.6215,\n","        0.3571, 0.8926, 0.7621, 0.8333, 0.7400, 0.8895], device='cuda:0')\n","Per class val accuracy:  tensor([0.4789, 0.5000, 0.7317, 0.3837, 0.7634, 0.6287, 0.4459, 0.8270, 0.5355,\n","        0.2083, 0.9031, 0.7592, 0.9167, 0.7594, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.712\n","Final per class accuracy on test set:  tensor([0.4437, 0.5484, 0.7512, 0.3372, 0.8423, 0.6355, 0.4000, 0.8270, 0.6323,\n","        0.2500, 0.8720, 0.7568, 0.8571, 0.7560, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1517964140\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1517964140\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  4083009686\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  4083009686\n","Epoch 0 with train loss: 2.856 train accuracy: 26.326 validation accuracy: 26.581\n","Per class train accuracy:  tensor([0.2406, 0.4332, 0.1992, 0.0467, 0.4234, 0.0791, 0.1577, 0.1498, 0.3355,\n","        0.2714, 0.7171, 0.4832, 0.1032, 0.0967, 0.3581], device='cuda:0')\n","Per class val accuracy:  tensor([0.1831, 0.4022, 0.2366, 0.0349, 0.4516, 0.0797, 0.1486, 0.1189, 0.3355,\n","        0.3333, 0.6920, 0.4939, 0.0595, 0.1137, 0.3314], device='cuda:0')\n","Epoch 9 with train loss: 1.035 train accuracy: 74.011 validation accuracy: 71.919\n","Per class train accuracy:  tensor([0.4340, 0.6751, 0.7837, 0.4825, 0.8146, 0.6312, 0.5270, 0.8231, 0.6516,\n","        0.6286, 0.9053, 0.8056, 0.8532, 0.7227, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.4718, 0.5435, 0.7610, 0.3023, 0.7742, 0.5558, 0.4324, 0.8162, 0.6000,\n","        0.5833, 0.9170, 0.8010, 0.9048, 0.7364, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.066\n","Final per class accuracy on test set:  tensor([0.4577, 0.5161, 0.7561, 0.3837, 0.8495, 0.5695, 0.4400, 0.8000, 0.6839,\n","        0.7083, 0.8858, 0.7936, 0.8214, 0.7597, 0.9034], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_4083009686\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_4083009686\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2455059856\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2455059856\n","Epoch 0 with train loss: 2.848 train accuracy: 23.679 validation accuracy: 23.555\n","Per class train accuracy:  tensor([0.0401, 0.1372, 0.0886, 0.2802, 0.3935, 0.1939, 0.1982, 0.0162, 0.3140,\n","        0.0143, 0.5242, 0.1698, 0.3413, 0.2479, 0.4210], device='cuda:0')\n","Per class val accuracy:  tensor([0.0423, 0.0217, 0.0683, 0.4419, 0.4516, 0.1640, 0.1081, 0.0162, 0.2387,\n","        0.0000, 0.5052, 0.1720, 0.4048, 0.2745, 0.3829], device='cuda:0')\n","Epoch 9 with train loss: 1.000 train accuracy: 74.347 validation accuracy: 73.446\n","Per class train accuracy:  tensor([0.4175, 0.6751, 0.7472, 0.4630, 0.7859, 0.7042, 0.5360, 0.7960, 0.6667,\n","        0.2143, 0.9042, 0.7818, 0.8690, 0.7594, 0.8838], device='cuda:0')\n","Per class val accuracy:  tensor([0.4718, 0.5652, 0.7220, 0.4302, 0.7455, 0.6651, 0.4595, 0.8000, 0.5806,\n","        0.2500, 0.9135, 0.8084, 0.9048, 0.7727, 0.8914], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.965\n","Final per class accuracy on test set:  tensor([0.4718, 0.6022, 0.7537, 0.4186, 0.8208, 0.6469, 0.4533, 0.8270, 0.6903,\n","        0.2917, 0.8858, 0.7641, 0.8571, 0.7657, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2455059856\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2455059856\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  400225693\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  400225693\n","Epoch 0 with train loss: 2.828 train accuracy: 25.607 validation accuracy: 26.281\n","Per class train accuracy:  tensor([0.1321, 0.5090, 0.4122, 0.1284, 0.3708, 0.2076, 0.2613, 0.0162, 0.0624,\n","        0.0286, 0.1524, 0.4299, 0.2698, 0.2140, 0.2705], device='cuda:0')\n","Per class val accuracy:  tensor([0.1197, 0.4674, 0.4463, 0.0698, 0.3548, 0.2005, 0.2027, 0.0324, 0.1032,\n","        0.0417, 0.1592, 0.4644, 0.3690, 0.2092, 0.2914], device='cuda:0')\n","Epoch 9 with train loss: 1.000 train accuracy: 74.875 validation accuracy: 73.282\n","Per class train accuracy:  tensor([0.4127, 0.6643, 0.7740, 0.4825, 0.7943, 0.7224, 0.5135, 0.8014, 0.6258,\n","        0.5286, 0.8949, 0.7974, 0.8690, 0.7477, 0.9048], device='cuda:0')\n","Per class val accuracy:  tensor([0.4296, 0.5217, 0.7634, 0.3953, 0.7419, 0.6834, 0.4189, 0.7892, 0.5484,\n","        0.4167, 0.9031, 0.8059, 0.9048, 0.7594, 0.9143], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.129\n","Final per class accuracy on test set:  tensor([0.4507, 0.5484, 0.7732, 0.4070, 0.8172, 0.6765, 0.4533, 0.8000, 0.6452,\n","        0.6250, 0.8824, 0.7838, 0.8333, 0.7585, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_400225693\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_400225693\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  89475662\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  89475662\n","Epoch 0 with train loss: 2.801 train accuracy: 27.481 validation accuracy: 28.490\n","Per class train accuracy:  tensor([0.1792, 0.0397, 0.1472, 0.1323, 0.4414, 0.2304, 0.2973, 0.5235, 0.0409,\n","        0.0143, 0.1062, 0.5390, 0.2540, 0.1971, 0.7029], device='cuda:0')\n","Per class val accuracy:  tensor([0.1972, 0.0543, 0.1463, 0.0930, 0.4695, 0.2232, 0.2838, 0.5081, 0.0323,\n","        0.0000, 0.1142, 0.5700, 0.2619, 0.2273, 0.6857], device='cuda:0')\n","Epoch 9 with train loss: 1.005 train accuracy: 73.883 validation accuracy: 72.083\n","Per class train accuracy:  tensor([0.3892, 0.6570, 0.7528, 0.4981, 0.8110, 0.6753, 0.5315, 0.7960, 0.6538,\n","        0.1714, 0.8972, 0.8089, 0.8413, 0.7388, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.4296, 0.5217, 0.7268, 0.3953, 0.7491, 0.6128, 0.4459, 0.8162, 0.5742,\n","        0.1667, 0.9135, 0.8280, 0.9048, 0.7424, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.849\n","Final per class accuracy on test set:  tensor([0.4789, 0.5269, 0.7317, 0.3837, 0.8315, 0.6264, 0.4800, 0.8000, 0.6581,\n","        0.1250, 0.8720, 0.7912, 0.8214, 0.7548, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_89475662\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_89475662\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  361232447\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  361232447\n","Epoch 0 with train loss: 2.928 train accuracy: 21.186 validation accuracy: 19.466\n","Per class train accuracy:  tensor([0.0991, 0.3935, 0.1455, 0.0311, 0.2476, 0.3886, 0.0450, 0.1462, 0.0473,\n","        0.0429, 0.3129, 0.1715, 0.0079, 0.1862, 0.4057], device='cuda:0')\n","Per class val accuracy:  tensor([0.1197, 0.2826, 0.1171, 0.0233, 0.2437, 0.3280, 0.0135, 0.1243, 0.0645,\n","        0.0417, 0.3322, 0.1794, 0.0000, 0.1741, 0.3486], device='cuda:0')\n","Epoch 9 with train loss: 1.020 train accuracy: 74.138 validation accuracy: 72.546\n","Per class train accuracy:  tensor([0.4363, 0.6390, 0.7593, 0.4747, 0.8134, 0.7278, 0.4595, 0.7942, 0.6538,\n","        0.4000, 0.8880, 0.7842, 0.8413, 0.7304, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.4577, 0.4891, 0.7268, 0.3953, 0.7384, 0.6948, 0.4189, 0.8000, 0.5871,\n","        0.3333, 0.8893, 0.7985, 0.9048, 0.7388, 0.9200], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.992\n","Final per class accuracy on test set:  tensor([0.4507, 0.5376, 0.7634, 0.3953, 0.8280, 0.6993, 0.4400, 0.8054, 0.6710,\n","        0.2500, 0.9031, 0.7690, 0.8333, 0.7512, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_361232447\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_361232447\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3647665043\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3647665043\n","Epoch 0 with train loss: 2.861 train accuracy: 24.406 validation accuracy: 23.310\n","Per class train accuracy:  tensor([0.0401, 0.5596, 0.3098, 0.0311, 0.6196, 0.0555, 0.1171, 0.5325, 0.1161,\n","        0.0000, 0.3661, 0.3774, 0.1349, 0.1330, 0.0286], device='cuda:0')\n","Per class val accuracy:  tensor([0.0423, 0.5435, 0.2683, 0.0465, 0.5376, 0.0547, 0.1216, 0.4919, 0.0968,\n","        0.0417, 0.3806, 0.3956, 0.1667, 0.1221, 0.0514], device='cuda:0')\n","Epoch 9 with train loss: 1.010 train accuracy: 74.857 validation accuracy: 72.737\n","Per class train accuracy:  tensor([0.4151, 0.6895, 0.7764, 0.4981, 0.8062, 0.6791, 0.4910, 0.8087, 0.6430,\n","        0.4000, 0.8880, 0.8228, 0.8651, 0.7529, 0.8952], device='cuda:0')\n","Per class val accuracy:  tensor([0.4155, 0.5543, 0.7317, 0.3837, 0.7419, 0.6173, 0.3919, 0.8054, 0.5871,\n","        0.2083, 0.8927, 0.8305, 0.8929, 0.7775, 0.9086], device='cuda:0')\n","Our final test accuracy for the GNN is: 75.000\n","Final per class accuracy on test set:  tensor([0.4296, 0.6022, 0.7854, 0.4186, 0.8351, 0.6401, 0.4267, 0.8216, 0.6581,\n","        0.3333, 0.8824, 0.8182, 0.8452, 0.7874, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3647665043\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3647665043\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1221215631\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1221215631\n","Epoch 0 with train loss: 2.928 train accuracy: 19.522 validation accuracy: 19.520\n","Per class train accuracy:  tensor([0.2217, 0.1625, 0.0715, 0.1245, 0.3266, 0.0935, 0.0270, 0.1715, 0.4194,\n","        0.0429, 0.2760, 0.4553, 0.2540, 0.0726, 0.2933], device='cuda:0')\n","Per class val accuracy:  tensor([0.2958, 0.1630, 0.0659, 0.1395, 0.2975, 0.0979, 0.0541, 0.1838, 0.2452,\n","        0.0000, 0.2837, 0.5012, 0.3214, 0.0738, 0.2514], device='cuda:0')\n","Epoch 9 with train loss: 1.028 train accuracy: 73.974 validation accuracy: 72.465\n","Per class train accuracy:  tensor([0.4528, 0.6245, 0.7553, 0.5331, 0.7907, 0.6852, 0.4910, 0.8213, 0.6516,\n","        0.4571, 0.8984, 0.8187, 0.8413, 0.7158, 0.9067], device='cuda:0')\n","Per class val accuracy:  tensor([0.5282, 0.5109, 0.7341, 0.4302, 0.7491, 0.6219, 0.4459, 0.8054, 0.5677,\n","        0.3750, 0.8997, 0.8452, 0.9048, 0.7243, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.203\n","Final per class accuracy on test set:  tensor([0.4859, 0.4946, 0.7293, 0.3837, 0.8315, 0.6446, 0.4533, 0.8216, 0.6452,\n","        0.5000, 0.8789, 0.8133, 0.8214, 0.7415, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1221215631\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1221215631\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2036056847\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2036056847\n","Epoch 0 with train loss: 2.879 train accuracy: 23.697 validation accuracy: 22.301\n","Per class train accuracy:  tensor([0.1203, 0.2347, 0.0935, 0.0389, 0.0550, 0.0935, 0.1396, 0.4639, 0.3720,\n","        0.0000, 0.4180, 0.2166, 0.3770, 0.2709, 0.6495], device='cuda:0')\n","Per class val accuracy:  tensor([0.1338, 0.2283, 0.0805, 0.0349, 0.0394, 0.0797, 0.0811, 0.4703, 0.2968,\n","        0.0000, 0.3668, 0.2432, 0.4167, 0.2600, 0.5829], device='cuda:0')\n","Epoch 9 with train loss: 1.018 train accuracy: 73.847 validation accuracy: 72.383\n","Per class train accuracy:  tensor([0.4080, 0.6462, 0.7472, 0.4708, 0.7847, 0.6631, 0.5000, 0.8430, 0.6258,\n","        0.2714, 0.9065, 0.8089, 0.8413, 0.7465, 0.9048], device='cuda:0')\n","Per class val accuracy:  tensor([0.3944, 0.5326, 0.7317, 0.4070, 0.7348, 0.5900, 0.4459, 0.8324, 0.5484,\n","        0.1250, 0.9204, 0.8329, 0.9167, 0.7654, 0.9200], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.720\n","Final per class accuracy on test set:  tensor([0.5141, 0.5591, 0.7463, 0.4070, 0.8100, 0.6059, 0.4667, 0.8378, 0.6129,\n","        0.2917, 0.8824, 0.8133, 0.8452, 0.7693, 0.9261], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2036056847\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2036056847\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1860537279\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1860537279\n","Epoch 0 with train loss: 2.835 train accuracy: 23.733 validation accuracy: 23.528\n","Per class train accuracy:  tensor([0.1462, 0.0866, 0.4431, 0.0661, 0.0622, 0.1460, 0.2252, 0.3249, 0.1763,\n","        0.1286, 0.2864, 0.1148, 0.4206, 0.3624, 0.0057], device='cuda:0')\n","Per class val accuracy:  tensor([0.1338, 0.0543, 0.4098, 0.0233, 0.0502, 0.1526, 0.1622, 0.3189, 0.1548,\n","        0.0833, 0.2941, 0.1130, 0.4286, 0.3894, 0.0114], device='cuda:0')\n","Epoch 9 with train loss: 0.996 train accuracy: 74.902 validation accuracy: 73.391\n","Per class train accuracy:  tensor([0.4245, 0.6354, 0.7691, 0.4630, 0.8038, 0.6715, 0.5180, 0.7978, 0.6753,\n","        0.5286, 0.8972, 0.8113, 0.8413, 0.7650, 0.9029], device='cuda:0')\n","Per class val accuracy:  tensor([0.4507, 0.4674, 0.7415, 0.3837, 0.7384, 0.6173, 0.4189, 0.8054, 0.6194,\n","        0.6250, 0.9135, 0.8157, 0.9167, 0.7848, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.755\n","Final per class accuracy on test set:  tensor([0.4296, 0.5054, 0.7659, 0.3721, 0.8351, 0.6401, 0.4267, 0.8216, 0.6903,\n","        0.3333, 0.8962, 0.8206, 0.8452, 0.7923, 0.8977], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1860537279\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1860537279\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  516507873\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  516507873\n","Epoch 0 with train loss: 2.797 train accuracy: 27.818 validation accuracy: 27.454\n","Per class train accuracy:  tensor([0.1509, 0.2996, 0.5033, 0.2023, 0.4892, 0.3932, 0.0495, 0.0090, 0.2366,\n","        0.2571, 0.2252, 0.1706, 0.5714, 0.0842, 0.7886], device='cuda:0')\n","Per class val accuracy:  tensor([0.1972, 0.2717, 0.4683, 0.1977, 0.5090, 0.3964, 0.0541, 0.0000, 0.1677,\n","        0.2083, 0.2491, 0.1548, 0.6429, 0.0834, 0.7771], device='cuda:0')\n","Epoch 9 with train loss: 1.003 train accuracy: 74.366 validation accuracy: 73.119\n","Per class train accuracy:  tensor([0.4599, 0.6643, 0.7715, 0.4708, 0.7823, 0.7308, 0.4144, 0.8051, 0.6215,\n","        0.6000, 0.8961, 0.7834, 0.8770, 0.7352, 0.8876], device='cuda:0')\n","Per class val accuracy:  tensor([0.4577, 0.5435, 0.7585, 0.4302, 0.7312, 0.6856, 0.3649, 0.8000, 0.5484,\n","        0.5833, 0.8927, 0.8034, 0.9048, 0.7521, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.265\n","Final per class accuracy on test set:  tensor([0.4789, 0.5484, 0.7659, 0.3837, 0.8100, 0.6856, 0.3733, 0.8108, 0.6387,\n","        0.5833, 0.8858, 0.7961, 0.8452, 0.7609, 0.9205], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_516507873\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_516507873\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3692371949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3692371949\n","Epoch 0 with train loss: 2.900 train accuracy: 24.379 validation accuracy: 23.664\n","Per class train accuracy:  tensor([0.0590, 0.0108, 0.2894, 0.1245, 0.3206, 0.0281, 0.1036, 0.4585, 0.4366,\n","        0.0286, 0.3441, 0.0763, 0.0079, 0.2717, 0.7810], device='cuda:0')\n","Per class val accuracy:  tensor([0.0352, 0.0000, 0.2854, 0.1047, 0.2939, 0.0296, 0.0405, 0.4541, 0.4129,\n","        0.1667, 0.3391, 0.0835, 0.0238, 0.2709, 0.7371], device='cuda:0')\n","Epoch 9 with train loss: 1.033 train accuracy: 73.474 validation accuracy: 71.947\n","Per class train accuracy:  tensor([0.4175, 0.6354, 0.7756, 0.4942, 0.7823, 0.6373, 0.4640, 0.8285, 0.6645,\n","        0.4714, 0.8949, 0.7916, 0.8333, 0.7364, 0.8952], device='cuda:0')\n","Per class val accuracy:  tensor([0.4507, 0.5217, 0.7439, 0.4302, 0.7240, 0.5763, 0.3378, 0.8054, 0.5613,\n","        0.5833, 0.8997, 0.8059, 0.9048, 0.7654, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.557\n","Final per class accuracy on test set:  tensor([0.4648, 0.5269, 0.7683, 0.4419, 0.8136, 0.6014, 0.4000, 0.8324, 0.6516,\n","        0.5833, 0.8754, 0.7690, 0.8452, 0.7754, 0.9318], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3692371949\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3692371949\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3300171104\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3300171104\n","Epoch 0 with train loss: 2.817 train accuracy: 26.317 validation accuracy: 27.045\n","Per class train accuracy:  tensor([0.2642, 0.5704, 0.0220, 0.1167, 0.3589, 0.1901, 0.1261, 0.1534, 0.2559,\n","        0.0429, 0.1628, 0.4709, 0.1468, 0.3031, 0.5276], device='cuda:0')\n","Per class val accuracy:  tensor([0.2887, 0.5435, 0.0122, 0.1279, 0.3513, 0.2210, 0.1486, 0.1189, 0.2065,\n","        0.0000, 0.2076, 0.5233, 0.1429, 0.3047, 0.5029], device='cuda:0')\n","Epoch 9 with train loss: 0.996 train accuracy: 74.920 validation accuracy: 73.419\n","Per class train accuracy:  tensor([0.4552, 0.6859, 0.7350, 0.5409, 0.7907, 0.6989, 0.5225, 0.8141, 0.6774,\n","        0.6143, 0.8995, 0.7867, 0.8373, 0.7594, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.5000, 0.5652, 0.7049, 0.4419, 0.7384, 0.6538, 0.4324, 0.7946, 0.5742,\n","        0.6667, 0.8962, 0.8108, 0.8810, 0.7811, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.265\n","Final per class accuracy on test set:  tensor([0.4930, 0.5161, 0.7195, 0.4070, 0.8244, 0.6720, 0.4800, 0.8108, 0.6710,\n","        0.5417, 0.8893, 0.7813, 0.7976, 0.7814, 0.9205], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3300171104\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3300171104\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2794978777\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2794978777\n","Epoch 0 with train loss: 2.860 train accuracy: 22.696 validation accuracy: 22.383\n","Per class train accuracy:  tensor([0.1910, 0.0505, 0.3203, 0.0856, 0.5407, 0.2038, 0.1757, 0.6787, 0.0688,\n","        0.1000, 0.3834, 0.1370, 0.1746, 0.0963, 0.0533], device='cuda:0')\n","Per class val accuracy:  tensor([0.2042, 0.0543, 0.2854, 0.1163, 0.5269, 0.2050, 0.1081, 0.6324, 0.0387,\n","        0.0000, 0.3737, 0.1695, 0.1429, 0.1161, 0.0400], device='cuda:0')\n","Epoch 9 with train loss: 1.001 train accuracy: 74.820 validation accuracy: 73.610\n","Per class train accuracy:  tensor([0.3962, 0.6823, 0.7626, 0.4669, 0.8062, 0.6852, 0.5270, 0.8032, 0.6925,\n","        0.5286, 0.8926, 0.8179, 0.8373, 0.7501, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.4225, 0.5652, 0.7244, 0.3372, 0.7670, 0.6560, 0.4459, 0.8054, 0.5935,\n","        0.4583, 0.9031, 0.8477, 0.8929, 0.7703, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.537\n","Final per class accuracy on test set:  tensor([0.4648, 0.5591, 0.7634, 0.3605, 0.8423, 0.6538, 0.4667, 0.8162, 0.7032,\n","        0.5833, 0.8789, 0.7985, 0.8333, 0.7681, 0.9034], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2794978777\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2794978777\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3303475786\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3303475786\n","Epoch 0 with train loss: 2.812 train accuracy: 24.033 validation accuracy: 24.291\n","Per class train accuracy:  tensor([0.1085, 0.0289, 0.1138, 0.1556, 0.3517, 0.1643, 0.1532, 0.7798, 0.0860,\n","        0.1286, 0.4319, 0.3511, 0.2103, 0.1846, 0.1333], device='cuda:0')\n","Per class val accuracy:  tensor([0.0986, 0.0109, 0.1488, 0.1279, 0.3047, 0.1845, 0.0946, 0.7297, 0.0903,\n","        0.0417, 0.4429, 0.3538, 0.2262, 0.1911, 0.1829], device='cuda:0')\n","Epoch 9 with train loss: 0.999 train accuracy: 74.693 validation accuracy: 73.337\n","Per class train accuracy:  tensor([0.4575, 0.6787, 0.7569, 0.4747, 0.7919, 0.6806, 0.4955, 0.7996, 0.6731,\n","        0.5143, 0.8903, 0.8146, 0.8175, 0.7570, 0.8933], device='cuda:0')\n","Per class val accuracy:  tensor([0.4577, 0.5543, 0.7317, 0.4070, 0.7491, 0.6241, 0.4459, 0.8054, 0.6000,\n","        0.4167, 0.9135, 0.8231, 0.9048, 0.7715, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.564\n","Final per class accuracy on test set:  tensor([0.4859, 0.5591, 0.7585, 0.3837, 0.8387, 0.6446, 0.4400, 0.8108, 0.6839,\n","        0.6667, 0.8720, 0.7961, 0.7976, 0.7802, 0.9205], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3303475786\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3303475786\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2952735006\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2952735006\n","Epoch 0 with train loss: 2.871 train accuracy: 23.115 validation accuracy: 22.301\n","Per class train accuracy:  tensor([0.0613, 0.3791, 0.3756, 0.0389, 0.2799, 0.3445, 0.2297, 0.3195, 0.0452,\n","        0.0714, 0.1028, 0.1173, 0.0040, 0.3047, 0.0152], device='cuda:0')\n","Per class val accuracy:  tensor([0.0634, 0.4783, 0.3317, 0.0349, 0.2652, 0.3349, 0.2703, 0.3135, 0.0194,\n","        0.0417, 0.0934, 0.1327, 0.0119, 0.2866, 0.0229], device='cuda:0')\n","Epoch 9 with train loss: 1.012 train accuracy: 74.320 validation accuracy: 72.873\n","Per class train accuracy:  tensor([0.3915, 0.6823, 0.7561, 0.5058, 0.7978, 0.7300, 0.5045, 0.7870, 0.6581,\n","        0.2000, 0.8868, 0.7908, 0.8294, 0.7449, 0.8971], device='cuda:0')\n","Per class val accuracy:  tensor([0.4155, 0.5435, 0.7293, 0.3953, 0.7599, 0.6970, 0.4324, 0.8054, 0.5742,\n","        0.0417, 0.8962, 0.7912, 0.8929, 0.7606, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.455\n","Final per class accuracy on test set:  tensor([0.4225, 0.5914, 0.7732, 0.4419, 0.8208, 0.7062, 0.4400, 0.8108, 0.6452,\n","        0.2917, 0.8685, 0.7912, 0.8214, 0.7621, 0.9205], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2952735006\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2952735006\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  572297925\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  572297925\n","Epoch 0 with train loss: 2.865 train accuracy: 21.213 validation accuracy: 20.583\n","Per class train accuracy:  tensor([0.1651, 0.0253, 0.4976, 0.0389, 0.0455, 0.1468, 0.1216, 0.0271, 0.1204,\n","        0.0571, 0.0739, 0.2896, 0.3611, 0.1520, 0.7905], device='cuda:0')\n","Per class val accuracy:  tensor([0.1690, 0.0435, 0.4366, 0.0465, 0.0323, 0.1071, 0.1622, 0.0378, 0.0710,\n","        0.1250, 0.0761, 0.2899, 0.3929, 0.1826, 0.7486], device='cuda:0')\n","Epoch 9 with train loss: 1.007 train accuracy: 74.402 validation accuracy: 73.119\n","Per class train accuracy:  tensor([0.4458, 0.6318, 0.7642, 0.4397, 0.7955, 0.6890, 0.4730, 0.8105, 0.6387,\n","        0.4000, 0.8845, 0.8195, 0.8294, 0.7545, 0.8876], device='cuda:0')\n","Per class val accuracy:  tensor([0.4930, 0.5109, 0.7463, 0.3488, 0.7419, 0.6401, 0.3919, 0.8054, 0.5806,\n","        0.2083, 0.8927, 0.8354, 0.9048, 0.7666, 0.9143], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.646\n","Final per class accuracy on test set:  tensor([0.5211, 0.5376, 0.7439, 0.3721, 0.8351, 0.6446, 0.4933, 0.8270, 0.6581,\n","        0.4167, 0.8754, 0.8010, 0.8452, 0.7886, 0.9034], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_572297925\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_572297925\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n"]}],"source":["# Use parameters from example in https://github.com/GTmac/FastRP/blob/master/fast-random-projection-blogcatalog.ipynb\n","# Except our input matrix in an adjacency matrix and since we are not tuning alpha we just set this to None\n","conf = {\n","        'projection_method': 'sparse',\n","        'input_matrix': 'adj',\n","        'weights': [0.0, 0.0, 1.0, 6.67],\n","        'normalization': True,\n","        'dim': HIDDEN_DIM,\n","        'alpha': None,\n","        'C': 0.1\n","    }\n","\n","num_nodes = node_features.shape[0]\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Convert adjacency matrix to scipy matrix\n","  adj_matrix = to_scipy_sparse_matrix(edge_indices)\n","  embeddings = fastrp_wrapper(adj_matrix, conf)\n","  # convert to tensor \n","  embeddings = torch.from_numpy(embeddings)\n","\n","  # Create the model\n","  model = FastRPEmbeddingWrapper(HIDDEN_DIM, num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_embedding_classifier(model, embeddings, train_y, train_mask, \n","                                             valid_y, valid_mask, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"X5HLu-NNuJ88"},"source":["# Node2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LtiwsyJPxpt"},"outputs":[],"source":["from torch_geometric.nn import Node2Vec\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","data_name = \"Arxiv\"\n","\n","# Get masks and training labels for each split\n","if data_name == \"Cora\":\n","  num_classes = 7\n","  data = cora_data\n","  # Get the edge indices and node features for our model\n","  edge_indices = data.edge_index\n","  node_features = data.x\n","  # CHANGE: To name of model being tested\n","  filename =  \"Node2Vec_Cora\"\n","  train_mask = data.train_mask\n","  train_y = data.y[train_mask]\n","  valid_mask = data.val_mask\n","  valid_y = data.y[valid_mask]\n","  test_mask = data.test_mask\n","  test_y = data.y[test_mask]\n","elif data_name == \"Coauthor\":\n","  data = cs_data\n","  # Get the edge indices and node features for our model\n","  edge_indices = data.edge_index\n","  node_features = data.x\n","  num_classes = 15\n","  filename =  \"Node2Vec_Coauthor_CS\"\n","  train_mask = train_mask_cs\n","  train_y = data.y[train_mask]\n","  valid_mask = val_mask_cs\n","  valid_y = data.y[valid_mask]\n","  test_mask = test_mask_cs\n","  test_y = data.y[test_mask]\n","elif data_name == \"Arxiv\":\n","  data = arxiv_data\n","  edge_indices = arxiv_data.edge_index\n","  node_features = arxiv_data.x\n","  neighbour_dataset = arxiv_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_idx\n","  train_y = arxiv_data.y[train_mask]\n","  valid_mask = valid_idx\n","  valid_y = arxiv_data.y[valid_mask]\n","  test_mask = test_idx\n","  test_y = arxiv_data.y[test_mask]\n","\n","  num_classes = 40\n","  is_cora = False\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# use 30 seeds which have been randomly generated using seed_list = [np.random.randint(4294967296 - 1) for i in range(30)]\n","seeds = [4193977854, 1863727779, 170173784, 2342954646, 116846604, 2105922959, 2739899259, 1024258131, 806299656, 880019963, 1818027900, 2135956485, 3710910636, 1517964140, 4083009686, 2455059856, 400225693, 89475662, 361232447, 3647665043, 1221215631, 2036056847, 1860537279, 516507873, 3692371949, 3300171104, 2794978777, 3303475786, 2952735006, 572297925]\n","\n","# create folder for saving all model info into if it does not exist already\n","if not os.path.exists(file_path+filename+\"/\"):\n","  os.mkdir(file_path+filename+\"/\")\n","\n","filename = filename + \"/\" + filename\n","\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Create the model\n","  #model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n","  model = Node2VecWrapper(data.edge_index.to(device), embedding_size=128, walk_length=20,\n","                     context_size=10, walks_per_node=10,\n","                     num_negative_samples=1, p=1, q=1, sparse=True, out_channels=num_classes).to(device)\n","  loader = model.loader(batch_size=128, shuffle=True,\n","                      num_workers=0)\n","  optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n","\n","  def train():\n","    model.train()\n","    total_loss = 0\n","    for pos_rw, neg_rw in loader:\n","      optimizer.zero_grad()\n","      loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n","      loss.backward()\n","      optimizer.step()\n","      total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","  @torch.no_grad()\n","  def find_model_acc(model, train_z, train_y, test_z, test_y, solver: str = 'lbfgs', multi_class: str = 'auto', *args, **kwargs):\n","    pred_y = model.test(train_z, train_y, test_z, test_y, solver=solver, multi_class=multi_class, *args, **kwargs)\n","    acc = accuracy_score(test_y.detach().cpu().numpy(), pred_y)\n","    matrix = confusion_matrix(test_y.detach().cpu().numpy(), pred_y)\n","    per_class_acc = matrix.diagonal()/matrix.sum(axis=1)\n","    #print(m)\n","    #report = classification_report(test_y.detach().cpu().numpy(), pred_y)\n","    #print(report)\n","    return acc, per_class_acc\n","\n","  @torch.no_grad()\n","  def test():\n","    model.eval()\n","    \n","    pred, z = model()\n","    acc_train, per_class_train_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[train_mask], data.y[train_mask])\n","  \n","    acc_val, per_class_val_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[valid_mask], data.y[valid_mask])\n","\n","    acc_test, per_class_test_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[test_mask], data.y[test_mask])\n","\n","    return z, acc_train, per_class_train_acc, acc_val, per_class_val_acc, acc_test, per_class_test_acc\n","\n","  training_stats = None\n","  for epoch in range(0, 10):\n","    loss = train()\n","    node_embeddings, acc_train, per_class_train_acc, acc_val, per_class_val_acc, acc_test, per_class_test_acc = test()\n","    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Acc_train: {acc_train:.4f}, Acc_val: {acc_val:.4f}, Acc_test: {acc_test:.4f}')\n","    print(f'Per class train accuracy: ', per_class_train_acc)\n","    epoch_stats = {'train_acc': acc_train, 'val_acc': acc_val, 'test_acc': acc_test, 'epoch':epoch}\n","    training_stats = update_stats(training_stats, epoch_stats)\n","  \n","  # Save training stats if on final iteration of the run\n","  save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","  # Save final results\n","  final_results_list = [seed, acc_test, per_class_test_acc, per_class_train_acc, per_class_val_acc]\n","  save_final_results(final_results_list, filename)\n","  # Save final model weights incase we want to do further inference later\n","  torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","\n","  plot_stats(training_stats, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"NGtX2ycNQa-H"},"source":["# Similarity tests"]},{"cell_type":"markdown","metadata":{"id":"-eesbQaUQfd4"},"source":["https://github.com/SGDE2020/embedding_stability/blob/master/similarity_tests/similarity_tests.py"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["NGtX2ycNQa-H"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}