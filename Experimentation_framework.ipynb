{"cells":[{"cell_type":"markdown","metadata":{"id":"qU87TNON39IV"},"source":["# **Preliminaries:** Install and import modules"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Mpygj8TTZ-ur","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679411336910,"user_tz":0,"elapsed":29074,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"1b770f9c-8823-4ca0-8b4f-bec1972bebc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mycolorpy\n","  Downloading mycolorpy-1.5.1.tar.gz (2.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mycolorpy) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mycolorpy) (3.7.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (23.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (4.39.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (2.8.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (1.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (1.4.4)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (5.12.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mycolorpy) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mycolorpy) (1.15.0)\n","Building wheels for collected packages: mycolorpy\n","  Building wheel for mycolorpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mycolorpy: filename=mycolorpy-1.5.1-py3-none-any.whl size=3874 sha256=2f37185cea27e2c1ba02055efabf2b3a00689aaf3d63b87ca844fc8f95cf7047\n","  Stored in directory: /root/.cache/pip/wheels/b9/56/d6/a163bcbec3bb69f3f7797b1b542870b18d7e31ff5dbc0b87e3\n","Successfully built mycolorpy\n","Installing collected packages: mycolorpy\n","Successfully installed mycolorpy-1.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Installing collected packages: colorama\n","Successfully installed colorama-0.4.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ogb\n","  Downloading ogb-1.3.5-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.13.1+cu116)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.4.4)\n","Collecting outdated>=0.2.0\n","  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.26.15)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.22.4)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (4.65.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.15.0)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (2.27.1)\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (63.4.3)\n","Collecting littleutils\n","  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.1)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2.0.12)\n","Building wheels for collected packages: littleutils\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=9213c1c9d65fc7fd112eb94e04c9ff47b1117cd087c23bae7d1d9be58e42eebe\n","  Stored in directory: /root/.cache/pip/wheels/04/bb/0d/2d02ec45f29c48d6192476bfb59c5a0e64b605e7212374dd15\n","Successfully built littleutils\n","Installing collected packages: littleutils, outdated, ogb\n","Successfully installed littleutils-0.2.2 ogb-1.3.5 outdated-0.2.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.17%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=bd99308a3e469bab3b1c03abade2de7fcfd974a66b015dbd4393448eda2fd59a\n","  Stored in directory: /root/.cache/pip/wheels/31/b2/8c/9b4bb72a4384eabd1ffeab2b7ead692c9165e35711f8a9dc72\n","Successfully built torch-geometric\n","Installing collected packages: torch-scatter, torch-sparse, torch-cluster, torch-geometric\n","Successfully installed torch-cluster-1.6.1+pt113cu116 torch-geometric-2.2.0 torch-scatter-2.1.1+pt113cu116 torch-sparse-0.6.17+pt113cu116\n"]}],"source":["#@title [RUN] install\n","!pip install networkx\n","!pip install mycolorpy\n","!pip install colorama\n","!pip install ogb\n","\n","import torch\n","import os\n","!pip install torch-geometric torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZLrrWpkk6xv-","executionInfo":{"status":"ok","timestamp":1679411342966,"user_tz":0,"elapsed":2713,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["#@title [RUN] Import modules\n","import numpy as np\n","import seaborn as sns\n","import math\n","import itertools\n","import scipy as sp\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch_geometric\n","from torch_geometric.datasets import Planetoid, Coauthor\n","from torch_scatter import scatter_mean, scatter_max, scatter_sum\n","from torch_geometric.utils import to_dense_adj\n","from torch.nn import Embedding\n","from torch_geometric.typing import Adj\n","from ogb.nodeproppred import PygNodePropPredDataset\n","from torch_geometric.loader import NeighborLoader\n","from torch_geometric.utils import to_scipy_sparse_matrix, degree\n","\n","#For FastRP\n","from scipy.sparse import coo_matrix, csr_matrix, csc_matrix, spdiags\n","from sklearn.preprocessing import normalize, scale, MultiLabelBinarizer\n","from sklearn import random_projection\n","\n","\n","import pdb\n","from datetime import datetime\n","\n","#for nice visualisations\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","from mycolorpy import colorlist as mcp\n","import matplotlib.cm as cm\n","\n","from typing import Mapping, Tuple, Sequence, List\n","import colorama\n","\n","import scipy.linalg\n","from scipy.linalg import block_diag"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"VLrKgQEuwgtb","executionInfo":{"status":"ok","timestamp":1679411345633,"user_tz":0,"elapsed":189,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["####### PLOTS #######\n","\n","def update_stats(training_stats, epoch_stats):\n","    \"\"\" Store metrics along the training\n","    Args:\n","      epoch_stats: dict containg metrics about one epoch\n","      training_stats: dict containing lists of metrics along training\n","    Returns:\n","      updated training_stats\n","    \"\"\"\n","    if training_stats is None:\n","        training_stats = {}\n","        for key in epoch_stats.keys():\n","            training_stats[key] = []\n","    for key,val in epoch_stats.items():\n","        training_stats[key].append(val)\n","    return training_stats\n","\n","def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n","    \"\"\" Create one plot for each metric stored in training_stats\n","    \"\"\"\n","    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n","    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n","    if len(stats_names)==1:\n","        ax = np.array([ax])\n","    for key, axx in zip(stats_names, ax.reshape(-1,)):\n","        axx.plot(\n","            training_stats['epoch'],\n","            training_stats[f'train_{key}'],\n","            label=f\"Training {key}\")\n","        axx.plot(\n","            training_stats['epoch'],\n","            training_stats[f'val_{key}'],\n","            label=f\"Validation {key}\")\n","        axx.set_xlabel(\"Training epoch\")\n","        axx.set_ylabel(key)\n","        axx.legend()\n","    plt.title(name)\n","\n","\n","def get_color_coded_str(i, color):\n","    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n","\n","def print_color_numpy(map, list_graphs):\n","    \"\"\" print matrix map in color according to list_graphs\n","    \"\"\"\n","    list_blocks = []\n","    for i,graph in enumerate(list_graphs):\n","        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n","        list_blocks += [block_i]\n","    block_color = block_diag(*list_blocks)\n","    \n","    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n","    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))"]},{"cell_type":"markdown","metadata":{"id":"82mrcZX0A3QR"},"source":["# Cora dataset\n","\n"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"bBTnJEZWA-Iq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394822530,"user_tz":0,"elapsed":2,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"b8a25a25-1860-4708-85e5-19224369f813"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"]},"metadata":{},"execution_count":65}],"source":["cora_dataset = Planetoid(\"/tmp/cora\", name=\"cora\", split=\"full\")\n","cora_data = cora_dataset[0]\n","cora_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UuZwDeBwJPZg"},"outputs":[],"source":["print(\"Training class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].train_mask]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].val_mask]))\n","print(\"Test class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].test_mask]))"]},{"cell_type":"markdown","metadata":{"id":"I9AoJuMmKQAO"},"source":["# OBGN-ARVIX dataset"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"Jswepg0KKQAP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679411619667,"user_tz":0,"elapsed":418,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"21c242f9-3ca0-4a41-fd9b-50cff3132c95"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343], y=[169343])"]},"metadata":{},"execution_count":15}],"source":["d_name = \"ogbn-arxiv\"\n","\n","dataset = PygNodePropPredDataset(name = d_name)\n","\n","split_idx = dataset.get_idx_split()\n","train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n","arxiv_data = dataset[0]\n","arxiv_data.y = arxiv_data.y.squeeze()\n","arxiv_data.node_year = arxiv_data.node_year.squeeze()\n","arxiv_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xj0Rb5CQKyLB"},"outputs":[],"source":["print(\"Training class sizes\")\n","print(torch.bincount(arxiv_data.y[train_idx]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(arxiv_data.y[valid_idx]))\n","print(\"Test class sizes\")\n","print(torch.bincount(arxiv_data.y[test_idx]))"]},{"cell_type":"markdown","metadata":{"id":"xY5bb2rDEuqM"},"source":["#Coauthor dataset"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"g9ZXzG7SE4oO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394856690,"user_tz":0,"elapsed":4360,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"ad7b2e79-1a52-476f-d4a3-90f71f49586b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/ms_academic_cs.npz\n","Processing...\n","Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["Data(x=[18333, 6805], edge_index=[2, 163788], y=[18333])"]},"metadata":{},"execution_count":67}],"source":["cs_dataset = Coauthor(\"/tmp/coauthor\", name=\"CS\")\n","cs_data = cs_dataset[0]\n","cs_data"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"KO3BwlveIuNv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394859724,"user_tz":0,"elapsed":575,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"fa9da774-4bfc-4dc0-8e59-5432fd6592fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["10993 3668 3672\n"]}],"source":["# Create manual split, do 60:20:20 across classes\n","num_classes_cs = 15\n","train_mask_cs_indices = []\n","val_mask_cs_indices = []\n","test_mask_cs_indices = []\n","cs_labels = cs_data.y\n","for i in range(num_classes_cs):\n","\n","  class_i = np.where(cs_labels == i)[0]\n","  np.random.seed(0)\n","  np.random.shuffle(class_i)\n","\n","  num_samples = len(class_i)\n","  train_mask_cs_indices += (class_i[:int(num_samples*0.6)]).tolist() \n","  val_mask_cs_indices += (class_i[int(num_samples*0.6):int(num_samples*0.8)]).tolist() \n","  test_mask_cs_indices += (class_i[int(num_samples*0.8):]).tolist() \n","\n","print(len(train_mask_cs_indices), len(val_mask_cs_indices), len(test_mask_cs_indices))\n","# Create the masks for training\n","# Test mask \n","train_mask_cs = torch.full((len(cs_labels),), False)\n","train_mask_cs[train_mask_cs_indices] = True\n","# Val mask\n","val_mask_cs = torch.full((len(cs_labels),), False)\n","val_mask_cs[val_mask_cs_indices] = True\n","# Train mask\n","test_mask_cs = torch.full((len(cs_labels),), False)\n","test_mask_cs[test_mask_cs_indices] = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lO6lZz9SE6kK"},"outputs":[],"source":["print(\"Training class sizes\")\n","print(torch.bincount(cs_data.y[train_mask_cs]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(cs_data.y[val_mask_cs]))\n","print(\"Test class sizes\")\n","print(torch.bincount(cs_data.y[test_mask_cs]))"]},{"cell_type":"markdown","metadata":{"id":"KL8gKs07J9JP"},"source":["# Data saving / loading"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z80lU1V-Isky","outputId":"b208fc02-8395-4db1-f218-b26cba7fe7f7","executionInfo":{"status":"ok","timestamp":1679411442225,"user_tz":0,"elapsed":15130,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# use google drive for saving and loading information\n","from google.colab import drive\n","import pickle\n","import os\n","\n","drive.mount('/content/drive')\n","file_path = '/content/drive/MyDrive/L45_project/'\n","# create folder if it does not exist already\n","if not os.path.exists(file_path):\n","  os.mkdir(file_path) "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"VhUfVQAZTWHu","executionInfo":{"status":"ok","timestamp":1679411517514,"user_tz":0,"elapsed":162,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["def save_training_info(training_stats: dict, node_embedding: torch.Tensor, filename: str):\n","  # write training data info to a file\n","  with open(file_path + filename + \".pkl\", 'wb') as fp:\n","    pickle.dump(training_stats, fp)\n","    print('Training stats saved successfully to file: ' + filename)\n","  # write node embedding to a file\n","  torch.save(node_embedding, file_path + filename + \"_emb.pt\")\n","  print('Node embedding saved successfully to file: ' + filename)\n","\n","\n","def load_training_info(filename: str):\n","  # load training stats dictionary \n","  with open(file_path + filename + \".pkl\", 'rb') as fp:\n","    train_stats = pickle.load(fp)\n","    print('Training stats successfully loaded from file: ' + filename)\n","  # load node embedding\n","  node_embedding = torch.load(file_path + filename + \"_emb.pt\")\n","  print('Node embedding successfully loaded from file: ' + filename)\n","  return train_stats, node_embedding\n","\n","# Final results is a list [seed, test result, [test per class accuracy], [training per class accuracy], [val per class accuracy]]\n","def save_final_results(final_results: List, filename: str):\n","  # write training data info to a file\n","  with open(file_path + filename + \".pkl\", 'ab') as fp:\n","    pickle.dump(final_results, fp)\n","    print('Final results saved successfully to file: ' + filename)\n","\n","# Returns an iterator which contains all the results from our various runs\n","def load_final_results(filename: str):\n","  with open(file_path + filename + \".pkl\", 'rb') as fp:\n","    print('Final results found in file: ' + filename)\n","    while True:\n","      try:\n","        # This notation creates a generator, which we can then iterate through\n","        yield pickle.load(fp)\n","      except EOFError:\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZECGPy9JTZrT"},"outputs":[],"source":["test_dict = {'c':[1,2,3], 'b':[4,5,6]}\n","test_tensor = torch.tensor([[1., -1.], [1., -1.]])\n","save_training_info(test_dict, test_tensor, \"testing\")\n","recovered_val1, recovered_val2 = load_training_info(\"testing\")\n","print(recovered_val1, recovered_val2)"]},{"cell_type":"markdown","metadata":{"id":"yVyPiw_TBMj7"},"source":["# Model Wrappers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m_yBLcOs6V7v"},"outputs":[],"source":["from torch_geometric.nn import GCN\n","\n","class GCNModelWrapper(GCN):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # use one less layer as our final graph layer can downsize for us\n","    # super().__init__(in_channels, hidden_channels, num_layers-1)\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9xNcjhyBRmX"},"outputs":[],"source":["from torch_geometric.nn import GAT\n","\n","class GATModelWrapper(GAT):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int, v2: bool):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers, v2=v2)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3upq1VfKQAQ"},"outputs":[],"source":["from torch_geometric.nn import GraphSAGE\n","\n","class GraphSAGEModelWrapper(GraphSAGE):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7htrR7C1jc3a"},"outputs":[],"source":["from torch_geometric.nn import Node2Vec\n","from torch import Tensor\n","\n","class Node2VecWrapper(Node2Vec):\n","  def __init__(self, edge_index, embedding_size, walk_length, context_size, walks_per_node, num_negative_samples, p, q, sparse, out_channels):\n","    super().__init__(edge_index, embedding_dim=embedding_size, walk_length=walk_length,\n","                     context_size=context_size, walks_per_node=walks_per_node,\n","                     num_negative_samples=num_negative_samples, p=p, q=q, sparse=sparse)\n","    self.final_layer = nn.Linear(embedding_size, out_channels)\n","  def forward(self):\n","    x = super().forward()\n","    output = F.softmax(self.final_layer(x), dim=1)\n","    return output, x\n","  def test(\n","    self,\n","    train_z: Tensor,\n","    train_y: Tensor,\n","    test_z: Tensor,\n","    test_y: Tensor,\n","    solver: str = 'lbfgs',\n","    multi_class: str = 'auto',\n","    *args,\n","    **kwargs,\n","    ) -> float:\n","    r\"\"\"Evaluates latent space quality via a logistic regression downstream\n","    task.\"\"\"\n","    from sklearn.linear_model import LogisticRegression\n","\n","    clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n","                            **kwargs).fit(train_z.detach().cpu().numpy(),\n","                                          train_y.detach().cpu().numpy())\n","    y_pred = clf.predict(test_z.detach().cpu().numpy())\n","    return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIrBZ7ssNBzW"},"outputs":[],"source":["from torch_geometric.nn import GIN\n","\n","class GINWrapper(GIN):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"markdown","metadata":{"id":"5mLwBJNywK-9"},"source":["# Training code\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","id":"-BLISzysQkdA","executionInfo":{"status":"ok","timestamp":1679411381788,"user_tz":0,"elapsed":206,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# @title [RUN] Hyperparameters GNN\n","\n","NUM_EPOCHS_CORA =  10 #@param {type:\"integer\"}\n","NUM_EPOCHS_ARVIX =  110 #@param {type:\"integer\"}\n","LR         = 0.01 #@param {type:\"number\"}\n","HIDDEN_DIM = 128  #@param {type:\"integer\"}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFTSH-Vuv4gk"},"outputs":[],"source":["# Code taken from L45 practical notebook\n","def train_gnn(X, edge_indices, y, mask, model, optimiser, device):\n","    model.train()\n","    # Put data on device\n","    X = X.to(device)\n","    edge_indices = edge_indices.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Train\n","    optimiser.zero_grad()\n","    y_out, _ = model(X, edge_indices)\n","    y_hat = y_out[mask]\n","    loss = F.cross_entropy(y_hat, y)\n","    loss.backward()\n","    optimiser.step()\n","    return loss.data\n","\n","# Training loop using subgraph batching from paper 'Inductive Representation Learning on Large Graphs' https://arxiv.org/pdf/1706.02216.pdf\n","def train_gnn_subgraph(data_batch, model, optimiser, device):\n","  total_loss = 0\n","  for batch in data_batch:\n","    # Put batch in device\n","    batch = batch.to(device)\n","    # Do training loop\n","    batch_size = batch.batch_size\n","    optimiser.zero_grad()\n","    y_out, _ = model(batch.x, batch.edge_index)\n","    y_out = y_out[:batch_size]\n","    batch_y = batch.y[:batch_size]\n","    batch_y = torch.reshape(batch_y, (-1,))\n","    loss = F.cross_entropy(y_out, batch_y)\n","    loss.backward()\n","    optimiser.step()\n","    # Keep a running total of the loss\n","    total_loss += float(loss)\n","\n","  # Get the average loss across all the batches\n","  loss = total_loss / len(data_batch)\n","  return loss\n","\n","def evaluate_gnn(X, edge_indices, y, mask, model, num_classes, device):\n","    model.eval()\n","    # Put data on device\n","    X = X.to(device)\n","    edge_indices = edge_indices.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Evaluate\n","    with torch.no_grad():\n","      y_out, node_embeddings = model(X, edge_indices)\n","    y_hat = y_out[mask]\n","    y_hat = y_hat.data.max(1)[1]\n","    num_correct = y_hat.eq(y.data).sum()\n","    num_total = len(y)\n","    accuracy = 100.0 * (num_correct/num_total)\n","\n","    # calculate per class accuracy\n","    values, counts = torch.unique(y_hat[y_hat == y.data], return_counts=True)\n","    per_class_counts = torch.zeros(num_classes)\n","    # make sure per_class_counts is on the correct device\n","    per_class_counts = per_class_counts.to(device)\n","    # allocate the number of counts per class\n","    for i, x in enumerate(values):\n","      per_class_counts[x] = counts[i]\n","    # find total number of data points per class in the split\n","    total_per_class = torch.bincount(y.data)\n","    per_class_accuracy = torch.div(per_class_counts, total_per_class)\n","\n","    return accuracy, per_class_accuracy, node_embeddings\n","    \n","# Training loop\n","def train_eval_loop_gnn(model, edge_indices, train_x, train_y, train_mask, valid_x, valid_y, valid_mask, \n","                             test_x, test_y, test_mask, num_classes, seed, filename, device, Cora, subgraph_batches=None):\n","    optimiser = optim.Adam(model.parameters(), lr=LR)\n","    training_stats = None\n","    # Choose number of epochs\n","    NUM_EPOCHS = NUM_EPOCHS_CORA if Cora else NUM_EPOCHS_ARVIX\n","    # Training loop\n","    for epoch in range(NUM_EPOCHS):\n","        # If subgraph batching is not provided, use the full graph for training. Otherwise use subgraph batch training regime\n","        if subgraph_batches is None:\n","          train_loss = train_gnn(train_x, edge_indices, train_y, train_mask, model, optimiser, device)\n","        else:\n","          train_loss = train_gnn_subgraph(subgraph_batches, model, optimiser, device)\n","        # Calculate accuracy on full graph  \n","        train_acc, train_class_acc, _ = evaluate_gnn(train_x, edge_indices, train_y, train_mask, model, num_classes, device)\n","        valid_acc, valid_class_acc, _ = evaluate_gnn(valid_x, edge_indices, valid_y, valid_mask, model, num_classes, device)\n","        if epoch % 10 == 0 or epoch == (NUM_EPOCHS-1):\n","            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n","            print(\"Per class train accuracy: \", train_class_acc)\n","            print(\"Per class val accuracy: \", valid_class_acc)\n","        # store the loss and the accuracy for the final plot\n","        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n","        training_stats = update_stats(training_stats, epoch_stats)\n","\n","    # Lets look at our final test performance\n","    # Only need to get the node embeddings once, take from the training evaluation call\n","    test_acc, test_class_acc, node_embeddings = evaluate_gnn(test_x, edge_indices, test_y, test_mask, model, num_classes, device)\n","    print(f\"Our final test accuracy for the GNN is: {test_acc:.3f}\")\n","    print(\"Final per class accuracy on test set: \", test_class_acc)\n","\n","    # Save training stats if on final iteration of the run\n","    save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","    # Save final results\n","    final_results_list = [seed, test_acc, test_class_acc, train_class_acc, valid_class_acc]\n","    save_final_results(final_results_list, filename)\n","    # Save final model weights incase we want to do further inference later\n","    torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","    return training_stats"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"A_O5m_YIaKY-","executionInfo":{"status":"ok","timestamp":1679411386753,"user_tz":0,"elapsed":222,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["def set_seeds(seed):\n","  print(\"SETTING SEEDS TO: \", str(seed))\n","  # seed the potential sources of randomness\n","  torch.manual_seed(seed)\n","  np.random.seed(seed)\n","  random.seed(seed)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"BDvu1pVpKQAR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679411633861,"user_tz":0,"elapsed":455,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"724937a9-988d-48bb-c967-f1521b6e7be2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using Arvix dataset\n"]}],"source":["# CHANGE: To name of model being tested\n","filename = \"FastRP-arvix\"\n","dataset = \"Arvix\"\n","# use 30 seeds which have been randomly generated using seed_list = [np.random.randint(4294967296 - 1) for i in range(30)]\n","seeds = [4193977854, 1863727779, 170173784, 2342954646, 116846604, 2105922959, 2739899259, 1024258131, 806299656, 880019963, 1818027900, 2135956485, 3710910636, 1517964140, 4083009686, 2455059856, 400225693, 89475662, 361232447, 3647665043, 1221215631, 2036056847, 1860537279, 516507873, 3692371949, 3300171104, 2794978777, 3303475786, 2952735006, 572297925]\n","\n","# create folder for saving all model info into if it does not exist already\n","if not os.path.exists(file_path+filename+\"/\"):\n","  os.mkdir(file_path+filename+\"/\")\n","\n","if dataset == \"Cora\":\n","  print(\"Using Cora dataset\")\n","  # Get the edge indices and node features for our model. General set up variables for running with all the models\n","  edge_indices = cora_data.edge_index\n","  node_features = cora_data.x\n","  neighbour_dataset = cora_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = cora_data.train_mask\n","  train_y = cora_data.y[train_mask]\n","  valid_mask = cora_data.val_mask\n","  valid_y = cora_data.y[valid_mask]\n","  test_mask = cora_data.test_mask\n","  test_y = cora_data.y[test_mask]\n","\n","  num_classes = 7\n","  is_cora=True\n","\n","elif dataset==\"Coauthor\":\n","  print(\"Using Coauthor dataset\")\n","  # Get the edge indices and node features for our model. General set up variables for running with all the models\n","  edge_indices = cs_data.edge_index\n","  node_features = cs_data.x\n","  neighbour_dataset = cs_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_mask_cs\n","  train_y = cs_data.y[train_mask]\n","  valid_mask = val_mask_cs\n","  valid_y = cs_data.y[valid_mask]\n","  test_mask = test_mask_cs\n","  test_y = cs_data.y[test_mask]\n","\n","  num_classes = 15\n","  is_cora=True\n","\n","# Otherwise we are using arvix dataset\n","else:\n","  print(\"Using Arvix dataset\")\n","  # Get the edge indices and node features for our model\n","  edge_indices = arxiv_data.edge_index\n","  node_features = arxiv_data.x\n","  neighbour_dataset = arxiv_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_idx\n","  train_y = arxiv_data.y[train_mask]\n","  valid_mask = valid_idx\n","  valid_y = arxiv_data.y[valid_mask]\n","  test_mask = test_idx\n","  test_y = arxiv_data.y[test_mask]\n","\n","  num_classes = 40\n","  is_cora = False\n"]},{"cell_type":"markdown","metadata":{"id":"fGgiIp_fKQAR"},"source":["# Training Loops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKAFIuc3YlIf"},"outputs":[],"source":["# Use to flush GPU memory if it gets too full\n","import gc\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rl6KVverQy7C"},"outputs":[],"source":["# General training loop for all models except GraphSAGE, using the whole graph in training instead of using subgraph batching\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Create the model\n","  model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes, v2=True)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVevwMOOKQAS"},"outputs":[],"source":["# Training loop for GraphSAGE which using subgraph batches instead of the entire graph\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Original paper uses neighbourhood sizes  S1 = 25 and S2 = 10 so this is what we use\n","  train_loader = NeighborLoader(neighbour_dataset, num_neighbors = [25, 10], batch_size=1024, input_nodes=train_mask)\n","\n","  # Create the model\n","  model = GraphSAGEModelWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora, subgraph_batches=train_loader)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLY-SWcPOjRa"},"outputs":[],"source":["# Training loop for GraphSAGE which using subgraph batches instead of the entire graph\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Original paper uses neighbourhood sizes  S1 = 25 and S2 = 10 so this is what we use\n","  train_loader = NeighborLoader(neighbour_dataset, num_neighbors = [25, 10], batch_size=1024, input_nodes=train_mask)\n","\n","  # Create the model\n","  model = GINWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora, subgraph_batches=train_loader)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"u4GMM4D5dLoB"},"source":["# TESTING LOADING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35RkMAgK8EHw"},"outputs":[],"source":["final_results = load_final_results(filename)\n","for r in final_results:\n","  print(r)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ3GQQld9b97"},"outputs":[],"source":["training_stats_1, embedding = load_training_info(filename+\"_1\")\n","plot_stats(training_stats_1, name=\"Testing\")\n","print(embedding)\n","print(node_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1nR7AjndQJn"},"outputs":[],"source":["# Loading stored model weights\n","model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n","model.load_state_dict(torch.load(file_path+filename+\"/\"+\"GATV2_1_model.pt\"))\n","model.eval()"]},{"cell_type":"markdown","metadata":{"id":"GubPzc9IQyP3"},"source":["- Plot graph with average training stats\n","- Save node embeddings for each run\n","- Save training stats for each run\n","- Save test accuracy for each run\n"]},{"cell_type":"markdown","metadata":{"id":"dneCfd9SkayN"},"source":["# FastRP"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"K69XCQpzkayN","executionInfo":{"status":"ok","timestamp":1679411536324,"user_tz":0,"elapsed":182,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["class FastRPEmbeddingWrapper(nn.Module):\n","  def __init__(self, input_dim, num_classes):\n","      super().__init__()\n","      self.linear = nn.Linear(input_dim, num_classes)\n","\n","  def forward(self, x):\n","      x = self.linear(x)\n","      return x"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"c7mdOE9EkayN","executionInfo":{"status":"ok","timestamp":1679411538208,"user_tz":0,"elapsed":4,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# Copied from https://github.com/GTmac/FastRP/blob/master/fastrp.py\n","# projection method: choose from Gaussian and Sparse\n","# input matrix: choose from adjacency and transition matrix\n","# alpha adjusts the weighting of nodes according to their degree\n","def fastrp_projection(A, seed, q=3, dim=128, projection_method='gaussian', input_matrix='adj', alpha=None):\n","    assert input_matrix == 'adj' or input_matrix == 'trans'\n","    assert projection_method == 'gaussian' or projection_method == 'sparse'\n","    \n","    N = A.shape[0]\n","    if input_matrix == 'adj':\n","        M = A\n","    else:\n","        # Change csc_matrix.sum(A) to A.sum as this caused bugs\n","        normalizer = spdiags(np.squeeze(1.0 / A.sum(axis=1) ), 0, N, N)\n","        M = normalizer @ A\n","    # Gaussian projection matrix\n","    if projection_method == 'gaussian':\n","        transformer = random_projection.GaussianRandomProjection(n_components=dim, random_state=seed)\n","    # Sparse projection matrix\n","    else:\n","        transformer = random_projection.SparseRandomProjection(n_components=dim, random_state=seed)\n","    Y = transformer.fit(M)\n","    # Random projection for A\n","    if alpha is not None:\n","      # Change csc_matrix.sum(A) to A.sum as this caused bugs\n","        Y.components_ = Y.components_ @ spdiags( \\\n","                        np.squeeze(np.power(A.sum(axis=1), alpha)), 0, N, N)\n","    cur_U = transformer.transform(M)\n","    U_list = [cur_U]\n","    \n","    for i in range(2, q + 1):\n","        cur_U = M @ cur_U\n","        U_list.append(cur_U)\n","    return U_list\n","\n","# When weights is None, concatenate instead of linearly combines the embeddings from different powers of A\n","def fastrp_merge(U_list, weights, normalization=False):\n","    dense_U_list = [_U.todense() for _U in U_list] if type(U_list[0]) == csc_matrix else U_list\n","    _U_list = [normalize(_U, norm='l2', axis=1) for _U in dense_U_list] if normalization else dense_U_list\n","\n","    if weights is None:\n","        return np.concatenate(_U_list, axis=1)\n","    U = np.zeros_like(_U_list[0])\n","    for cur_U, weight in zip(_U_list, weights):\n","        U += cur_U * weight\n","    # U = scale(U.todense())\n","    # U = normalize(U.todense(), norm='l2', axis=1)\n","    return scale(np.asarray(U.todense())) if type(U) == csr_matrix else scale(np.asarray(U))\n","\n","# A is always the adjacency matrix\n","# the choice between adj matrix and trans matrix is decided in the conf\n","def fastrp_wrapper(A, conf, seed):\n","    U_list = fastrp_projection(A,\n","                               seed,\n","                               q=len(conf['weights']),\n","                               dim=conf['dim'],\n","                               projection_method=conf['projection_method'],\n","                               input_matrix=conf['input_matrix'],\n","                               alpha=conf['alpha'],\n","    )\n","    U = fastrp_merge(U_list, conf['weights'], conf['normalization'])\n","    return U"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"7wPmS2Q3kayN","executionInfo":{"status":"ok","timestamp":1679411547041,"user_tz":0,"elapsed":201,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# Code adpated from L45 practical notebook\n","def train_embedding_classifier(X, y, mask, model, optimiser, device):\n","    model.train()\n","    # Put data on device\n","    X = X.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Train\n","    optimiser.zero_grad()\n","    y_out = model(X)\n","    y_hat = y_out[mask]\n","    loss = F.cross_entropy(y_hat, y)\n","    loss.backward()\n","    optimiser.step()\n","    return loss.data\n","\n","def evaluate_embedding_classifier(X, y, mask, model, num_classes, device):\n","    model.eval()\n","    # Put data on device\n","    X = X.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Evaluate\n","    with torch.no_grad():\n","      y_out = model(X)\n","    y_hat = y_out[mask]\n","    y_hat = y_hat.data.max(1)[1]\n","    num_correct = y_hat.eq(y.data).sum()\n","    num_total = len(y)\n","    accuracy = 100.0 * (num_correct/num_total)\n","\n","    # calculate per class accuracy\n","    values, counts = torch.unique(y_hat[y_hat == y.data], return_counts=True)\n","    per_class_counts = torch.zeros(num_classes)\n","    # make sure per_class_counts is on the correct device\n","    per_class_counts = per_class_counts.to(device)\n","    # allocate the number of counts per class\n","    for i, x in enumerate(values):\n","      per_class_counts[x] = counts[i]\n","    # find total number of data points per class in the split\n","    total_per_class = torch.bincount(y.data)\n","    per_class_accuracy = torch.div(per_class_counts, total_per_class)\n","\n","    return accuracy, per_class_accuracy\n","    \n","# Training loop\n","def train_eval_loop_embedding_classifier(model, embeddings, train_y, train_mask, \n","                                         valid_y, valid_mask, test_y, test_mask, num_classes, seed, filename, device, Cora):\n","    optimiser = optim.Adam(model.parameters(), lr=LR)\n","    training_stats = None\n","    # Choose number of epochs\n","    NUM_EPOCHS = NUM_EPOCHS_CORA if Cora else NUM_EPOCHS_ARVIX\n","    # Training loop\n","    for epoch in range(NUM_EPOCHS):\n","        train_loss = train_embedding_classifier(embeddings, train_y, train_mask, model, optimiser, device)\n","        # Calculate accuracy on full graph  \n","        train_acc, train_class_acc = evaluate_embedding_classifier(embeddings, train_y, train_mask, model, num_classes, device)\n","        valid_acc, valid_class_acc = evaluate_embedding_classifier(embeddings, valid_y, valid_mask, model, num_classes, device)\n","        if epoch % 10 == 0 or epoch == (NUM_EPOCHS-1):\n","            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n","            print(\"Per class train accuracy: \", train_class_acc)\n","            print(\"Per class val accuracy: \", valid_class_acc)\n","        # store the loss and the accuracy for the final plot\n","        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n","        training_stats = update_stats(training_stats, epoch_stats)\n","\n","    # Lets look at our final test performance\n","    # Only need to get the node embeddings once, take from the training evaluation call\n","    test_acc, test_class_acc = evaluate_embedding_classifier(embeddings, test_y, test_mask, model, num_classes, device)\n","    print(f\"Our final test accuracy for the GNN is: {test_acc:.3f}\")\n","    print(\"Final per class accuracy on test set: \", test_class_acc)\n","\n","    # Save training stats if on final iteration of the run, the node embeddings are actually passed in for training, where  \n","    node_embeddings = embeddings\n","    save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","    # Save final results\n","    final_results_list = [seed, test_acc, test_class_acc, train_class_acc, valid_class_acc]\n","    save_final_results(final_results_list, filename)\n","    # Save final model weights incase we want to do further inference later\n","    torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","    return training_stats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GOvJm2pnkayN"},"outputs":[],"source":["# Use parameters from example in https://github.com/GTmac/FastRP/blob/master/fast-random-projection-blogcatalog.ipynb\n","# Except our input matrix in an adjacency matrix and since we are not tuning alpha we just set this to None\n","input_matrix = 'adj'\n","alpha = -0.67\n","conf = {\n","        'projection_method': 'sparse',\n","        'input_matrix': input_matrix,\n","        'weights': [0.0, 0.0, 1.0, 6.67],\n","        'normalization': True,\n","        'dim': HIDDEN_DIM,\n","        'alpha': alpha,\n","        'C': 0.1\n","    }\n","\n","num_nodes = node_features.shape[0]\n","\n","# Convert adjacency matrix to scipy matrix\n","adj_matrix = to_scipy_sparse_matrix(edge_indices)\n","# Whether we are using the adjacency or transition matrix\n","if input_matrix == 'trans':\n","  # Create the degree matrix for the graph\n","  degrees = degree(edge_indices[0])\n","  diagonal_degree = sp.sparse.spdiags(degrees, 0, degrees.size()[0], degrees.size()[0])\n","  # Create the transition matrix for the graph = D-1(A)\n","  transition_matrix = scipy.sparse.linalg.inv(diagonal_degree).multiply(adj_matrix)\n","  print(\"Using transition matrix\")\n","else:\n","  transition_matrix = adj_matrix\n","  print(\"Using adjacency matrix\")\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  \n","  embeddings = fastrp_wrapper(transition_matrix, conf, seed)\n","  # convert to tensor \n","  embeddings = torch.from_numpy(embeddings)\n","\n","  # Create the model\n","  model = FastRPEmbeddingWrapper(HIDDEN_DIM, num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_embedding_classifier(model, embeddings, train_y, train_mask, \n","                                             valid_y, valid_mask, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"X5HLu-NNuJ88"},"source":["# Node2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LtiwsyJPxpt"},"outputs":[],"source":["from torch_geometric.nn import Node2Vec\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","data_name = \"Arxiv\"\n","\n","# Get masks and training labels for each split\n","if data_name == \"Cora\":\n","  num_classes = 7\n","  data = cora_data\n","  # Get the edge indices and node features for our model\n","  edge_indices = data.edge_index\n","  node_features = data.x\n","  # CHANGE: To name of model being tested\n","  filename =  \"Node2Vec_Cora\"\n","  train_mask = data.train_mask\n","  train_y = data.y[train_mask]\n","  valid_mask = data.val_mask\n","  valid_y = data.y[valid_mask]\n","  test_mask = data.test_mask\n","  test_y = data.y[test_mask]\n","elif data_name == \"Coauthor\":\n","  data = cs_data\n","  # Get the edge indices and node features for our model\n","  edge_indices = data.edge_index\n","  node_features = data.x\n","  num_classes = 15\n","  filename =  \"Node2Vec_Coauthor_CS\"\n","  train_mask = train_mask_cs\n","  train_y = data.y[train_mask]\n","  valid_mask = val_mask_cs\n","  valid_y = data.y[valid_mask]\n","  test_mask = test_mask_cs\n","  test_y = data.y[test_mask]\n","elif data_name == \"Arxiv\":\n","  data = arxiv_data\n","  edge_indices = arxiv_data.edge_index\n","  node_features = arxiv_data.x\n","  neighbour_dataset = arxiv_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_idx\n","  train_y = arxiv_data.y[train_mask]\n","  valid_mask = valid_idx\n","  valid_y = arxiv_data.y[valid_mask]\n","  test_mask = test_idx\n","  test_y = arxiv_data.y[test_mask]\n","\n","  num_classes = 40\n","  is_cora = False\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# use 30 seeds which have been randomly generated using seed_list = [np.random.randint(4294967296 - 1) for i in range(30)]\n","seeds = [4193977854, 1863727779, 170173784, 2342954646, 116846604, 2105922959, 2739899259, 1024258131, 806299656, 880019963, 1818027900, 2135956485, 3710910636, 1517964140, 4083009686, 2455059856, 400225693, 89475662, 361232447, 3647665043, 1221215631, 2036056847, 1860537279, 516507873, 3692371949, 3300171104, 2794978777, 3303475786, 2952735006, 572297925]\n","\n","# create folder for saving all model info into if it does not exist already\n","if not os.path.exists(file_path+filename+\"/\"):\n","  os.mkdir(file_path+filename+\"/\")\n","\n","filename = filename + \"/\" + filename\n","\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Create the model\n","  #model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n","  model = Node2VecWrapper(data.edge_index.to(device), embedding_size=128, walk_length=20,\n","                     context_size=10, walks_per_node=10,\n","                     num_negative_samples=1, p=1, q=1, sparse=True, out_channels=num_classes).to(device)\n","  loader = model.loader(batch_size=128, shuffle=True,\n","                      num_workers=0)\n","  optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n","\n","  def train():\n","    model.train()\n","    total_loss = 0\n","    for pos_rw, neg_rw in loader:\n","      optimizer.zero_grad()\n","      loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n","      loss.backward()\n","      optimizer.step()\n","      total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","  @torch.no_grad()\n","  def find_model_acc(model, train_z, train_y, test_z, test_y, solver: str = 'lbfgs', multi_class: str = 'auto', *args, **kwargs):\n","    pred_y = model.test(train_z, train_y, test_z, test_y, solver=solver, multi_class=multi_class, *args, **kwargs)\n","    acc = accuracy_score(test_y.detach().cpu().numpy(), pred_y)\n","    matrix = confusion_matrix(test_y.detach().cpu().numpy(), pred_y)\n","    per_class_acc = matrix.diagonal()/matrix.sum(axis=1)\n","    #print(m)\n","    #report = classification_report(test_y.detach().cpu().numpy(), pred_y)\n","    #print(report)\n","    return acc, per_class_acc\n","\n","  @torch.no_grad()\n","  def test():\n","    model.eval()\n","    \n","    pred, z = model()\n","    acc_train, per_class_train_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[train_mask], data.y[train_mask])\n","  \n","    acc_val, per_class_val_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[valid_mask], data.y[valid_mask])\n","\n","    acc_test, per_class_test_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[test_mask], data.y[test_mask])\n","\n","    return z, acc_train, per_class_train_acc, acc_val, per_class_val_acc, acc_test, per_class_test_acc\n","\n","  training_stats = None\n","  for epoch in range(0, 10):\n","    loss = train()\n","    node_embeddings, acc_train, per_class_train_acc, acc_val, per_class_val_acc, acc_test, per_class_test_acc = test()\n","    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Acc_train: {acc_train:.4f}, Acc_val: {acc_val:.4f}, Acc_test: {acc_test:.4f}')\n","    print(f'Per class train accuracy: ', per_class_train_acc)\n","    epoch_stats = {'train_acc': acc_train, 'val_acc': acc_val, 'test_acc': acc_test, 'epoch':epoch}\n","    training_stats = update_stats(training_stats, epoch_stats)\n","  \n","  # Save training stats if on final iteration of the run\n","  save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","  # Save final results\n","  final_results_list = [seed, acc_test, per_class_test_acc, per_class_train_acc, per_class_val_acc]\n","  save_final_results(final_results_list, filename)\n","  # Save final model weights incase we want to do further inference later\n","  torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","\n","  plot_stats(training_stats, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"NGtX2ycNQa-H"},"source":["# Similarity tests"]},{"cell_type":"markdown","metadata":{"id":"-eesbQaUQfd4"},"source":["https://github.com/SGDE2020/embedding_stability/blob/master/similarity_tests/similarity_tests.py"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["NGtX2ycNQa-H"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}