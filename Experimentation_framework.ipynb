{"cells":[{"cell_type":"markdown","metadata":{"id":"qU87TNON39IV"},"source":["# **Preliminaries:** Install and import modules"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"Mpygj8TTZ-ur","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394810477,"user_tz":0,"elapsed":20244,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"5339df34-45a2-4e27-bfc6-8b732a423d95"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: mycolorpy in /usr/local/lib/python3.9/dist-packages (1.5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from mycolorpy) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mycolorpy) (3.7.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (4.39.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (23.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (1.0.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (8.4.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mycolorpy) (5.12.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mycolorpy) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mycolorpy) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: colorama in /usr/local/lib/python3.9/dist-packages (0.4.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ogb in /usr/local/lib/python3.9/dist-packages (1.3.5)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.22.4)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.4.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.15.0)\n","Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (0.2.2)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.13.1+cu116)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.26.15)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (1.2.2)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.9/dist-packages (from ogb) (4.65.0)\n","Requirement already satisfied: littleutils in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n","Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (63.4.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from outdated>=0.2.0->ogb) (2.27.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.1.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.9/dist-packages (2.2.0)\n","Requirement already satisfied: torch-scatter in /usr/local/lib/python3.9/dist-packages (2.1.1+pt113cu116)\n","Requirement already satisfied: torch-sparse in /usr/local/lib/python3.9/dist-packages (0.6.17+pt113cu116)\n","Requirement already satisfied: torch-cluster in /usr/local/lib/python3.9/dist-packages (1.6.1+pt113cu116)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n"]}],"source":["#@title [RUN] install\n","!pip install networkx\n","!pip install mycolorpy\n","!pip install colorama\n","!pip install ogb\n","\n","import torch\n","import os\n","!pip install torch-geometric torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"ZLrrWpkk6xv-","executionInfo":{"status":"ok","timestamp":1679394814090,"user_tz":0,"elapsed":2,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["#@title [RUN] Import modules\n","import numpy as np\n","import seaborn as sns\n","import math\n","import itertools\n","import scipy as sp\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch_geometric\n","from torch_geometric.datasets import Planetoid, Coauthor\n","from torch_scatter import scatter_mean, scatter_max, scatter_sum\n","from torch_geometric.utils import to_dense_adj\n","from torch.nn import Embedding\n","from torch_geometric.typing import Adj\n","from ogb.nodeproppred import PygNodePropPredDataset\n","from torch_geometric.loader import NeighborLoader\n","from torch_geometric.utils import to_scipy_sparse_matrix, degree\n","\n","#For FastRP\n","from scipy.sparse import coo_matrix, csr_matrix, csc_matrix, spdiags\n","from sklearn.preprocessing import normalize, scale, MultiLabelBinarizer\n","from sklearn import random_projection\n","\n","\n","import pdb\n","from datetime import datetime\n","\n","#for nice visualisations\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","from mycolorpy import colorlist as mcp\n","import matplotlib.cm as cm\n","\n","from typing import Mapping, Tuple, Sequence, List\n","import colorama\n","\n","import scipy.linalg\n","from scipy.linalg import block_diag"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"VLrKgQEuwgtb","executionInfo":{"status":"ok","timestamp":1679394817934,"user_tz":0,"elapsed":2,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["####### PLOTS #######\n","\n","def update_stats(training_stats, epoch_stats):\n","    \"\"\" Store metrics along the training\n","    Args:\n","      epoch_stats: dict containg metrics about one epoch\n","      training_stats: dict containing lists of metrics along training\n","    Returns:\n","      updated training_stats\n","    \"\"\"\n","    if training_stats is None:\n","        training_stats = {}\n","        for key in epoch_stats.keys():\n","            training_stats[key] = []\n","    for key,val in epoch_stats.items():\n","        training_stats[key].append(val)\n","    return training_stats\n","\n","def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n","    \"\"\" Create one plot for each metric stored in training_stats\n","    \"\"\"\n","    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n","    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n","    if len(stats_names)==1:\n","        ax = np.array([ax])\n","    for key, axx in zip(stats_names, ax.reshape(-1,)):\n","        axx.plot(\n","            training_stats['epoch'],\n","            training_stats[f'train_{key}'],\n","            label=f\"Training {key}\")\n","        axx.plot(\n","            training_stats['epoch'],\n","            training_stats[f'val_{key}'],\n","            label=f\"Validation {key}\")\n","        axx.set_xlabel(\"Training epoch\")\n","        axx.set_ylabel(key)\n","        axx.legend()\n","    plt.title(name)\n","\n","\n","def get_color_coded_str(i, color):\n","    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n","\n","def print_color_numpy(map, list_graphs):\n","    \"\"\" print matrix map in color according to list_graphs\n","    \"\"\"\n","    list_blocks = []\n","    for i,graph in enumerate(list_graphs):\n","        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n","        list_blocks += [block_i]\n","    block_color = block_diag(*list_blocks)\n","    \n","    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n","    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))"]},{"cell_type":"markdown","metadata":{"id":"82mrcZX0A3QR"},"source":["# Cora dataset\n","\n"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"bBTnJEZWA-Iq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394822530,"user_tz":0,"elapsed":2,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"b8a25a25-1860-4708-85e5-19224369f813"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"]},"metadata":{},"execution_count":65}],"source":["cora_dataset = Planetoid(\"/tmp/cora\", name=\"cora\", split=\"full\")\n","cora_data = cora_dataset[0]\n","cora_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UuZwDeBwJPZg"},"outputs":[],"source":["print(\"Training class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].train_mask]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].val_mask]))\n","print(\"Test class sizes\")\n","print(torch.bincount(cora_dataset[0].y[cora_dataset[0].test_mask]))"]},{"cell_type":"markdown","metadata":{"id":"I9AoJuMmKQAO"},"source":["# OBGN-ARVIX dataset"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"Jswepg0KKQAP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394845289,"user_tz":0,"elapsed":16286,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"70ab8af2-45ae-40ff-e05d-7248cddbc6aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"]},{"output_type":"stream","name":"stderr","text":["Downloaded 0.08 GB: 100%|██████████| 81/81 [00:09<00:00,  8.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/arxiv.zip\n"]},{"output_type":"stream","name":"stderr","text":["Processing...\n"]},{"output_type":"stream","name":"stdout","text":["Loading necessary files...\n","This might take a while.\n","Processing graphs...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 1988.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Converting graphs into PyG objects...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 4917.12it/s]"]},{"output_type":"stream","name":"stdout","text":["Saving...\n"]},{"output_type":"stream","name":"stderr","text":["\n","Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343], y=[169343])"]},"metadata":{},"execution_count":66}],"source":["d_name = \"ogbn-arxiv\"\n","\n","dataset = PygNodePropPredDataset(name = d_name)\n","\n","split_idx = dataset.get_idx_split()\n","train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n","arxiv_data = dataset[0]\n","arxiv_data.y = arxiv_data.y.squeeze()\n","arxiv_data.node_year = arxiv_data.node_year.squeeze()\n","arxiv_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xj0Rb5CQKyLB"},"outputs":[],"source":["print(\"Training class sizes\")\n","print(torch.bincount(arxiv_data.y[train_idx]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(arxiv_data.y[valid_idx]))\n","print(\"Test class sizes\")\n","print(torch.bincount(arxiv_data.y[test_idx]))"]},{"cell_type":"markdown","metadata":{"id":"xY5bb2rDEuqM"},"source":["#Coauthor dataset"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"g9ZXzG7SE4oO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394856690,"user_tz":0,"elapsed":4360,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"ad7b2e79-1a52-476f-d4a3-90f71f49586b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/ms_academic_cs.npz\n","Processing...\n","Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["Data(x=[18333, 6805], edge_index=[2, 163788], y=[18333])"]},"metadata":{},"execution_count":67}],"source":["cs_dataset = Coauthor(\"/tmp/coauthor\", name=\"CS\")\n","cs_data = cs_dataset[0]\n","cs_data"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"KO3BwlveIuNv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394859724,"user_tz":0,"elapsed":575,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"fa9da774-4bfc-4dc0-8e59-5432fd6592fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["10993 3668 3672\n"]}],"source":["# Create manual split, do 60:20:20 across classes\n","num_classes_cs = 15\n","train_mask_cs_indices = []\n","val_mask_cs_indices = []\n","test_mask_cs_indices = []\n","cs_labels = cs_data.y\n","for i in range(num_classes_cs):\n","\n","  class_i = np.where(cs_labels == i)[0]\n","  np.random.seed(0)\n","  np.random.shuffle(class_i)\n","\n","  num_samples = len(class_i)\n","  train_mask_cs_indices += (class_i[:int(num_samples*0.6)]).tolist() \n","  val_mask_cs_indices += (class_i[int(num_samples*0.6):int(num_samples*0.8)]).tolist() \n","  test_mask_cs_indices += (class_i[int(num_samples*0.8):]).tolist() \n","\n","print(len(train_mask_cs_indices), len(val_mask_cs_indices), len(test_mask_cs_indices))\n","# Create the masks for training\n","# Test mask \n","train_mask_cs = torch.full((len(cs_labels),), False)\n","train_mask_cs[train_mask_cs_indices] = True\n","# Val mask\n","val_mask_cs = torch.full((len(cs_labels),), False)\n","val_mask_cs[val_mask_cs_indices] = True\n","# Train mask\n","test_mask_cs = torch.full((len(cs_labels),), False)\n","test_mask_cs[test_mask_cs_indices] = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lO6lZz9SE6kK"},"outputs":[],"source":["print(\"Training class sizes\")\n","print(torch.bincount(cs_data.y[train_mask_cs]))\n","print(\"Validation class sizes\")\n","print(torch.bincount(cs_data.y[val_mask_cs]))\n","print(\"Test class sizes\")\n","print(torch.bincount(cs_data.y[test_mask_cs]))"]},{"cell_type":"markdown","metadata":{"id":"KL8gKs07J9JP"},"source":["# Data saving / loading"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z80lU1V-Isky","outputId":"7f98ec88-40d6-45ad-de9e-c8004ca78213","executionInfo":{"status":"ok","timestamp":1679394866946,"user_tz":0,"elapsed":3423,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# use google drive for saving and loading information\n","from google.colab import drive\n","import pickle\n","import os\n","\n","drive.mount('/content/drive')\n","file_path = '/content/drive/MyDrive/L45_project/'\n","# create folder if it does not exist already\n","if not os.path.exists(file_path):\n","  os.mkdir(file_path) "]},{"cell_type":"code","execution_count":70,"metadata":{"id":"VhUfVQAZTWHu","executionInfo":{"status":"ok","timestamp":1679394870693,"user_tz":0,"elapsed":489,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["def save_training_info(training_stats: dict, node_embedding: torch.Tensor, filename: str):\n","  # write training data info to a file\n","  with open(file_path + filename + \".pkl\", 'wb') as fp:\n","    pickle.dump(training_stats, fp)\n","    print('Training stats saved successfully to file: ' + filename)\n","  # write node embedding to a file\n","  torch.save(node_embedding, file_path + filename + \"_emb.pt\")\n","  print('Node embedding saved successfully to file: ' + filename)\n","\n","\n","def load_training_info(filename: str):\n","  # load training stats dictionary \n","  with open(file_path + filename + \".pkl\", 'rb') as fp:\n","    train_stats = pickle.load(fp)\n","    print('Training stats successfully loaded from file: ' + filename)\n","  # load node embedding\n","  node_embedding = torch.load(file_path + filename + \"_emb.pt\")\n","  print('Node embedding successfully loaded from file: ' + filename)\n","  return train_stats, node_embedding\n","\n","# Final results is a list [seed, test result, [test per class accuracy], [training per class accuracy], [val per class accuracy]]\n","def save_final_results(final_results: List, filename: str):\n","  # write training data info to a file\n","  with open(file_path + filename + \".pkl\", 'ab') as fp:\n","    pickle.dump(final_results, fp)\n","    print('Final results saved successfully to file: ' + filename)\n","\n","# Returns an iterator which contains all the results from our various runs\n","def load_final_results(filename: str):\n","  with open(file_path + filename + \".pkl\", 'rb') as fp:\n","    print('Final results found in file: ' + filename)\n","    while True:\n","      try:\n","        # This notation creates a generator, which we can then iterate through\n","        yield pickle.load(fp)\n","      except EOFError:\n","        break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZECGPy9JTZrT","outputId":"ad72ff23-9243-4609-d4e7-6646392b8d11"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training stats saved successfully to file: testing\n","Node embedding saved successfully to file: testing\n","Training stats successfully loaded from file: testing\n","Node embedding successfully loaded from file: testing\n","{'c': [1, 2, 3], 'b': [4, 5, 6]} tensor([[ 1., -1.],\n","        [ 1., -1.]])\n"]}],"source":["test_dict = {'c':[1,2,3], 'b':[4,5,6]}\n","test_tensor = torch.tensor([[1., -1.], [1., -1.]])\n","save_training_info(test_dict, test_tensor, \"testing\")\n","recovered_val1, recovered_val2 = load_training_info(\"testing\")\n","print(recovered_val1, recovered_val2)"]},{"cell_type":"markdown","metadata":{"id":"yVyPiw_TBMj7"},"source":["# Model Wrappers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m_yBLcOs6V7v"},"outputs":[],"source":["from torch_geometric.nn import GCN\n","\n","class GCNModelWrapper(GCN):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # use one less layer as our final graph layer can downsize for us\n","    # super().__init__(in_channels, hidden_channels, num_layers-1)\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9xNcjhyBRmX"},"outputs":[],"source":["from torch_geometric.nn import GAT\n","\n","class GATModelWrapper(GAT):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int, v2: bool):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers, v2=v2)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3upq1VfKQAQ"},"outputs":[],"source":["from torch_geometric.nn import GraphSAGE\n","\n","class GraphSAGEModelWrapper(GraphSAGE):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7htrR7C1jc3a"},"outputs":[],"source":["from torch_geometric.nn import Node2Vec\n","from torch import Tensor\n","\n","class Node2VecWrapper(Node2Vec):\n","  def __init__(self, edge_index, embedding_size, walk_length, context_size, walks_per_node, num_negative_samples, p, q, sparse, out_channels):\n","    super().__init__(edge_index, embedding_dim=embedding_size, walk_length=walk_length,\n","                     context_size=context_size, walks_per_node=walks_per_node,\n","                     num_negative_samples=num_negative_samples, p=p, q=q, sparse=sparse)\n","    self.final_layer = nn.Linear(embedding_size, out_channels)\n","  def forward(self):\n","    x = super().forward()\n","    output = F.softmax(self.final_layer(x), dim=1)\n","    return output, x\n","  def test(\n","    self,\n","    train_z: Tensor,\n","    train_y: Tensor,\n","    test_z: Tensor,\n","    test_y: Tensor,\n","    solver: str = 'lbfgs',\n","    multi_class: str = 'auto',\n","    *args,\n","    **kwargs,\n","    ) -> float:\n","    r\"\"\"Evaluates latent space quality via a logistic regression downstream\n","    task.\"\"\"\n","    from sklearn.linear_model import LogisticRegression\n","\n","    clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n","                            **kwargs).fit(train_z.detach().cpu().numpy(),\n","                                          train_y.detach().cpu().numpy())\n","    y_pred = clf.predict(test_z.detach().cpu().numpy())\n","    return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIrBZ7ssNBzW"},"outputs":[],"source":["from torch_geometric.nn import GIN\n","\n","class GINWrapper(GIN):\n","\n","  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n","    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n","    super().__init__(in_channels, hidden_channels, num_layers)\n","    self.out_channels = out_channels\n","    self.final_layer = nn.Linear(hidden_channels, out_channels)\n","\n","  def forward(self, x: torch.Tensor, edge_index: Adj):\n","    x = super().forward(x, edge_index)\n","    output = self.final_layer(x)\n","    return output, x"]},{"cell_type":"markdown","metadata":{"id":"5mLwBJNywK-9"},"source":["# Training code\n","\n"]},{"cell_type":"code","execution_count":71,"metadata":{"cellView":"form","id":"-BLISzysQkdA","executionInfo":{"status":"ok","timestamp":1679394877613,"user_tz":0,"elapsed":415,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# @title [RUN] Hyperparameters GNN\n","\n","NUM_EPOCHS_CORA =  10 #@param {type:\"integer\"}\n","NUM_EPOCHS_ARVIX =  110 #@param {type:\"integer\"}\n","LR         = 0.01 #@param {type:\"number\"}\n","HIDDEN_DIM = 128  #@param {type:\"integer\"}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFTSH-Vuv4gk"},"outputs":[],"source":["# Code taken from L45 practical notebook\n","def train_gnn(X, edge_indices, y, mask, model, optimiser, device):\n","    model.train()\n","    # Put data on device\n","    X = X.to(device)\n","    edge_indices = edge_indices.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Train\n","    optimiser.zero_grad()\n","    y_out, _ = model(X, edge_indices)\n","    y_hat = y_out[mask]\n","    loss = F.cross_entropy(y_hat, y)\n","    loss.backward()\n","    optimiser.step()\n","    return loss.data\n","\n","# Training loop using subgraph batching from paper 'Inductive Representation Learning on Large Graphs' https://arxiv.org/pdf/1706.02216.pdf\n","def train_gnn_subgraph(data_batch, model, optimiser, device):\n","  total_loss = 0\n","  for batch in data_batch:\n","    # Put batch in device\n","    batch = batch.to(device)\n","    # Do training loop\n","    batch_size = batch.batch_size\n","    optimiser.zero_grad()\n","    y_out, _ = model(batch.x, batch.edge_index)\n","    y_out = y_out[:batch_size]\n","    batch_y = batch.y[:batch_size]\n","    batch_y = torch.reshape(batch_y, (-1,))\n","    loss = F.cross_entropy(y_out, batch_y)\n","    loss.backward()\n","    optimiser.step()\n","    # Keep a running total of the loss\n","    total_loss += float(loss)\n","\n","  # Get the average loss across all the batches\n","  loss = total_loss / len(data_batch)\n","  return loss\n","\n","def evaluate_gnn(X, edge_indices, y, mask, model, num_classes, device):\n","    model.eval()\n","    # Put data on device\n","    X = X.to(device)\n","    edge_indices = edge_indices.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Evaluate\n","    with torch.no_grad():\n","      y_out, node_embeddings = model(X, edge_indices)\n","    y_hat = y_out[mask]\n","    y_hat = y_hat.data.max(1)[1]\n","    num_correct = y_hat.eq(y.data).sum()\n","    num_total = len(y)\n","    accuracy = 100.0 * (num_correct/num_total)\n","\n","    # calculate per class accuracy\n","    values, counts = torch.unique(y_hat[y_hat == y.data], return_counts=True)\n","    per_class_counts = torch.zeros(num_classes)\n","    # make sure per_class_counts is on the correct device\n","    per_class_counts = per_class_counts.to(device)\n","    # allocate the number of counts per class\n","    for i, x in enumerate(values):\n","      per_class_counts[x] = counts[i]\n","    # find total number of data points per class in the split\n","    total_per_class = torch.bincount(y.data)\n","    per_class_accuracy = torch.div(per_class_counts, total_per_class)\n","\n","    return accuracy, per_class_accuracy, node_embeddings\n","    \n","# Training loop\n","def train_eval_loop_gnn(model, edge_indices, train_x, train_y, train_mask, valid_x, valid_y, valid_mask, \n","                             test_x, test_y, test_mask, num_classes, seed, filename, device, Cora, subgraph_batches=None):\n","    optimiser = optim.Adam(model.parameters(), lr=LR)\n","    training_stats = None\n","    # Choose number of epochs\n","    NUM_EPOCHS = NUM_EPOCHS_CORA if Cora else NUM_EPOCHS_ARVIX\n","    # Training loop\n","    for epoch in range(NUM_EPOCHS):\n","        # If subgraph batching is not provided, use the full graph for training. Otherwise use subgraph batch training regime\n","        if subgraph_batches is None:\n","          train_loss = train_gnn(train_x, edge_indices, train_y, train_mask, model, optimiser, device)\n","        else:\n","          train_loss = train_gnn_subgraph(subgraph_batches, model, optimiser, device)\n","        # Calculate accuracy on full graph  \n","        train_acc, train_class_acc, _ = evaluate_gnn(train_x, edge_indices, train_y, train_mask, model, num_classes, device)\n","        valid_acc, valid_class_acc, _ = evaluate_gnn(valid_x, edge_indices, valid_y, valid_mask, model, num_classes, device)\n","        if epoch % 10 == 0 or epoch == (NUM_EPOCHS-1):\n","            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n","            print(\"Per class train accuracy: \", train_class_acc)\n","            print(\"Per class val accuracy: \", valid_class_acc)\n","        # store the loss and the accuracy for the final plot\n","        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n","        training_stats = update_stats(training_stats, epoch_stats)\n","\n","    # Lets look at our final test performance\n","    # Only need to get the node embeddings once, take from the training evaluation call\n","    test_acc, test_class_acc, node_embeddings = evaluate_gnn(test_x, edge_indices, test_y, test_mask, model, num_classes, device)\n","    print(f\"Our final test accuracy for the GNN is: {test_acc:.3f}\")\n","    print(\"Final per class accuracy on test set: \", test_class_acc)\n","\n","    # Save training stats if on final iteration of the run\n","    save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","    # Save final results\n","    final_results_list = [seed, test_acc, test_class_acc, train_class_acc, valid_class_acc]\n","    save_final_results(final_results_list, filename)\n","    # Save final model weights incase we want to do further inference later\n","    torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","    return training_stats"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"A_O5m_YIaKY-","executionInfo":{"status":"ok","timestamp":1679394881880,"user_tz":0,"elapsed":2,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["def set_seeds(seed):\n","  print(\"SETTING SEEDS TO: \", str(seed))\n","  # seed the potential sources of randomness\n","  torch.manual_seed(seed)\n","  np.random.seed(seed)\n","  random.seed(seed)"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"BDvu1pVpKQAR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679394968517,"user_tz":0,"elapsed":374,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"e1ae5075-4ae6-4948-9fb1-95f5371b3486"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using Coauthor dataset\n"]}],"source":["# CHANGE: To name of model being tested\n","filename = \"FastRP-coauthor\"\n","dataset = \"Coauthor\"\n","# use 30 seeds which have been randomly generated using seed_list = [np.random.randint(4294967296 - 1) for i in range(30)]\n","seeds = [4193977854, 1863727779, 170173784, 2342954646, 116846604, 2105922959, 2739899259, 1024258131, 806299656, 880019963, 1818027900, 2135956485, 3710910636, 1517964140, 4083009686, 2455059856, 400225693, 89475662, 361232447, 3647665043, 1221215631, 2036056847, 1860537279, 516507873, 3692371949, 3300171104, 2794978777, 3303475786, 2952735006, 572297925]\n","\n","# create folder for saving all model info into if it does not exist already\n","if not os.path.exists(file_path+filename+\"/\"):\n","  os.mkdir(file_path+filename+\"/\")\n","\n","if dataset == \"Cora\":\n","  print(\"Using Cora dataset\")\n","  # Get the edge indices and node features for our model. General set up variables for running with all the models\n","  edge_indices = cora_data.edge_index\n","  node_features = cora_data.x\n","  neighbour_dataset = cora_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = cora_data.train_mask\n","  train_y = cora_data.y[train_mask]\n","  valid_mask = cora_data.val_mask\n","  valid_y = cora_data.y[valid_mask]\n","  test_mask = cora_data.test_mask\n","  test_y = cora_data.y[test_mask]\n","\n","  num_classes = 7\n","  is_cora=True\n","\n","elif dataset==\"Coauthor\":\n","  print(\"Using Coauthor dataset\")\n","  # Get the edge indices and node features for our model. General set up variables for running with all the models\n","  edge_indices = cs_data.edge_index\n","  node_features = cs_data.x\n","  neighbour_dataset = cs_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_mask_cs\n","  train_y = cs_data.y[train_mask]\n","  valid_mask = val_mask_cs\n","  valid_y = cs_data.y[valid_mask]\n","  test_mask = test_mask_cs\n","  test_y = cs_data.y[test_mask]\n","\n","  num_classes = 15\n","  is_cora=True\n","\n","# Otherwise we are using arvix dataset\n","else:\n","  print(\"Using Arvix dataset\")\n","  # Get the edge indices and node features for our model\n","  edge_indices = arxiv_data.edge_index\n","  node_features = arxiv_data.x\n","  neighbour_dataset = arxiv_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_idx\n","  train_y = arxiv_data.y[train_mask]\n","  valid_mask = valid_idx\n","  valid_y = arxiv_data.y[valid_mask]\n","  test_mask = test_idx\n","  test_y = arxiv_data.y[test_mask]\n","\n","  num_classes = 40\n","  is_cora = False\n"]},{"cell_type":"markdown","metadata":{"id":"fGgiIp_fKQAR"},"source":["# Training Loops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKAFIuc3YlIf"},"outputs":[],"source":["# Use to flush GPU memory if it gets too full\n","import gc\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rl6KVverQy7C"},"outputs":[],"source":["# General training loop for all models except GraphSAGE, using the whole graph in training instead of using subgraph batching\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Create the model\n","  model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes, v2=True)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVevwMOOKQAS"},"outputs":[],"source":["# Training loop for GraphSAGE which using subgraph batches instead of the entire graph\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Original paper uses neighbourhood sizes  S1 = 25 and S2 = 10 so this is what we use\n","  train_loader = NeighborLoader(neighbour_dataset, num_neighbors = [25, 10], batch_size=1024, input_nodes=train_mask)\n","\n","  # Create the model\n","  model = GraphSAGEModelWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora, subgraph_batches=train_loader)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLY-SWcPOjRa"},"outputs":[],"source":["# Training loop for GraphSAGE which using subgraph batches instead of the entire graph\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Original paper uses neighbourhood sizes  S1 = 25 and S2 = 10 so this is what we use\n","  train_loader = NeighborLoader(neighbour_dataset, num_neighbors = [25, 10], batch_size=1024, input_nodes=train_mask)\n","\n","  # Create the model\n","  model = GINWrapper(in_channels = node_features.shape[-1], hidden_channels = HIDDEN_DIM, num_layers=1, out_channels=num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_gnn(model, edge_indices, node_features, train_y, train_mask, \n","                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora, subgraph_batches=train_loader)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"u4GMM4D5dLoB"},"source":["# TESTING LOADING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35RkMAgK8EHw"},"outputs":[],"source":["final_results = load_final_results(filename)\n","for r in final_results:\n","  print(r)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bZ3GQQld9b97"},"outputs":[],"source":["training_stats_1, embedding = load_training_info(filename+\"_1\")\n","plot_stats(training_stats_1, name=\"Testing\")\n","print(embedding)\n","print(node_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s1nR7AjndQJn"},"outputs":[],"source":["# Loading stored model weights\n","model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n","model.load_state_dict(torch.load(file_path+filename+\"/\"+\"GATV2_1_model.pt\"))\n","model.eval()"]},{"cell_type":"markdown","metadata":{"id":"GubPzc9IQyP3"},"source":["- Plot graph with average training stats\n","- Save node embeddings for each run\n","- Save training stats for each run\n","- Save test accuracy for each run\n"]},{"cell_type":"markdown","metadata":{"id":"dneCfd9SkayN"},"source":["# FastRP"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"K69XCQpzkayN","executionInfo":{"status":"ok","timestamp":1679394974640,"user_tz":0,"elapsed":396,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["class FastRPEmbeddingWrapper(nn.Module):\n","  def __init__(self, input_dim, num_classes):\n","      super().__init__()\n","      self.linear = nn.Linear(input_dim, num_classes)\n","\n","  def forward(self, x):\n","      x = self.linear(x)\n","      return x"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"c7mdOE9EkayN","executionInfo":{"status":"ok","timestamp":1679394904272,"user_tz":0,"elapsed":5,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# Copied from https://github.com/GTmac/FastRP/blob/master/fastrp.py\n","# projection method: choose from Gaussian and Sparse\n","# input matrix: choose from adjacency and transition matrix\n","# alpha adjusts the weighting of nodes according to their degree\n","def fastrp_projection(A, seed, q=3, dim=128, projection_method='gaussian', input_matrix='adj', alpha=None):\n","    assert input_matrix == 'adj' or input_matrix == 'trans'\n","    assert projection_method == 'gaussian' or projection_method == 'sparse'\n","    \n","    N = A.shape[0]\n","    if input_matrix == 'adj':\n","        M = A\n","    else:\n","        # Change csc_matrix.sum(A) to A.sum as this caused bugs\n","        normalizer = spdiags(np.squeeze(1.0 / A.sum(axis=1) ), 0, N, N)\n","        M = normalizer @ A\n","    # Gaussian projection matrix\n","    if projection_method == 'gaussian':\n","        transformer = random_projection.GaussianRandomProjection(n_components=dim, random_state=seed)\n","    # Sparse projection matrix\n","    else:\n","        transformer = random_projection.SparseRandomProjection(n_components=dim, random_state=seed)\n","    Y = transformer.fit(M)\n","    # Random projection for A\n","    if alpha is not None:\n","      # Change csc_matrix.sum(A) to A.sum as this caused bugs\n","        Y.components_ = Y.components_ @ spdiags( \\\n","                        np.squeeze(np.power(A.sum(axis=1), alpha)), 0, N, N)\n","    cur_U = transformer.transform(M)\n","    U_list = [cur_U]\n","    \n","    for i in range(2, q + 1):\n","        cur_U = M @ cur_U\n","        U_list.append(cur_U)\n","    return U_list\n","\n","# When weights is None, concatenate instead of linearly combines the embeddings from different powers of A\n","def fastrp_merge(U_list, weights, normalization=False):\n","    dense_U_list = [_U.todense() for _U in U_list] if type(U_list[0]) == csc_matrix else U_list\n","    _U_list = [normalize(_U, norm='l2', axis=1) for _U in dense_U_list] if normalization else dense_U_list\n","\n","    if weights is None:\n","        return np.concatenate(_U_list, axis=1)\n","    U = np.zeros_like(_U_list[0])\n","    for cur_U, weight in zip(_U_list, weights):\n","        U += cur_U * weight\n","    # U = scale(U.todense())\n","    # U = normalize(U.todense(), norm='l2', axis=1)\n","    return scale(np.asarray(U.todense())) if type(U) == csr_matrix else scale(np.asarray(U))\n","\n","# A is always the adjacency matrix\n","# the choice between adj matrix and trans matrix is decided in the conf\n","def fastrp_wrapper(A, conf, seed):\n","    U_list = fastrp_projection(A,\n","                               seed,\n","                               q=len(conf['weights']),\n","                               dim=conf['dim'],\n","                               projection_method=conf['projection_method'],\n","                               input_matrix=conf['input_matrix'],\n","                               alpha=conf['alpha'],\n","    )\n","    U = fastrp_merge(U_list, conf['weights'], conf['normalization'])\n","    return U"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"7wPmS2Q3kayN","executionInfo":{"status":"ok","timestamp":1679394909216,"user_tz":0,"elapsed":409,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}}},"outputs":[],"source":["# Code adpated from L45 practical notebook\n","def train_embedding_classifier(X, y, mask, model, optimiser, device):\n","    model.train()\n","    # Put data on device\n","    X = X.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Train\n","    optimiser.zero_grad()\n","    y_out = model(X)\n","    y_hat = y_out[mask]\n","    loss = F.cross_entropy(y_hat, y)\n","    loss.backward()\n","    optimiser.step()\n","    return loss.data\n","\n","def evaluate_embedding_classifier(X, y, mask, model, num_classes, device):\n","    model.eval()\n","    # Put data on device\n","    X = X.to(device)\n","    y = y.to(device)\n","    mask = mask.to(device)\n","    # Evaluate\n","    with torch.no_grad():\n","      y_out = model(X)\n","    y_hat = y_out[mask]\n","    y_hat = y_hat.data.max(1)[1]\n","    num_correct = y_hat.eq(y.data).sum()\n","    num_total = len(y)\n","    accuracy = 100.0 * (num_correct/num_total)\n","\n","    # calculate per class accuracy\n","    values, counts = torch.unique(y_hat[y_hat == y.data], return_counts=True)\n","    per_class_counts = torch.zeros(num_classes)\n","    # make sure per_class_counts is on the correct device\n","    per_class_counts = per_class_counts.to(device)\n","    # allocate the number of counts per class\n","    for i, x in enumerate(values):\n","      per_class_counts[x] = counts[i]\n","    # find total number of data points per class in the split\n","    total_per_class = torch.bincount(y.data)\n","    per_class_accuracy = torch.div(per_class_counts, total_per_class)\n","\n","    return accuracy, per_class_accuracy\n","    \n","# Training loop\n","def train_eval_loop_embedding_classifier(model, embeddings, train_y, train_mask, \n","                                         valid_y, valid_mask, test_y, test_mask, num_classes, seed, filename, device, Cora):\n","    optimiser = optim.Adam(model.parameters(), lr=LR)\n","    training_stats = None\n","    # Choose number of epochs\n","    NUM_EPOCHS = NUM_EPOCHS_CORA if Cora else NUM_EPOCHS_ARVIX\n","    # Training loop\n","    for epoch in range(NUM_EPOCHS):\n","        train_loss = train_embedding_classifier(embeddings, train_y, train_mask, model, optimiser, device)\n","        # Calculate accuracy on full graph  \n","        train_acc, train_class_acc = evaluate_embedding_classifier(embeddings, train_y, train_mask, model, num_classes, device)\n","        valid_acc, valid_class_acc = evaluate_embedding_classifier(embeddings, valid_y, valid_mask, model, num_classes, device)\n","        if epoch % 10 == 0 or epoch == (NUM_EPOCHS-1):\n","            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n","            print(\"Per class train accuracy: \", train_class_acc)\n","            print(\"Per class val accuracy: \", valid_class_acc)\n","        # store the loss and the accuracy for the final plot\n","        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n","        training_stats = update_stats(training_stats, epoch_stats)\n","\n","    # Lets look at our final test performance\n","    # Only need to get the node embeddings once, take from the training evaluation call\n","    test_acc, test_class_acc = evaluate_embedding_classifier(embeddings, test_y, test_mask, model, num_classes, device)\n","    print(f\"Our final test accuracy for the GNN is: {test_acc:.3f}\")\n","    print(\"Final per class accuracy on test set: \", test_class_acc)\n","\n","    # Save training stats if on final iteration of the run, the node embeddings are actually passed in for training, where  \n","    node_embeddings = embeddings\n","    save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","    # Save final results\n","    final_results_list = [seed, test_acc, test_class_acc, train_class_acc, valid_class_acc]\n","    save_final_results(final_results_list, filename)\n","    # Save final model weights incase we want to do further inference later\n","    torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","    return training_stats"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"GOvJm2pnkayN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679395001615,"user_tz":0,"elapsed":21128,"user":{"displayName":"Emily Morris","userId":"08202831375881547702"}},"outputId":"3c2b1bab-ee61-4324-c815-38eb575973f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using adjacency matrix\n","SETTING SEEDS TO:  4193977854\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  4193977854\n","Epoch 0 with train loss: 2.867 train accuracy: 21.586 validation accuracy: 21.020\n","Per class train accuracy:  tensor([0.0778, 0.0830, 0.1024, 0.0856, 0.2584, 0.1186, 0.1441, 0.6841, 0.2860,\n","        0.0000, 0.0139, 0.1665, 0.6508, 0.2334, 0.5619], device='cuda:0')\n","Per class val accuracy:  tensor([0.1338, 0.0761, 0.0805, 0.0465, 0.2796, 0.0888, 0.1622, 0.6919, 0.1935,\n","        0.0417, 0.0035, 0.1376, 0.6429, 0.2382, 0.6400], device='cuda:0')\n","Epoch 9 with train loss: 1.087 train accuracy: 72.628 validation accuracy: 71.129\n","Per class train accuracy:  tensor([0.4245, 0.6751, 0.7537, 0.5525, 0.8062, 0.5970, 0.4685, 0.7852, 0.5269,\n","        0.3714, 0.8811, 0.7998, 0.8214, 0.7465, 0.9181], device='cuda:0')\n","Per class val accuracy:  tensor([0.4789, 0.5326, 0.7073, 0.4302, 0.7742, 0.5535, 0.4189, 0.7946, 0.4645,\n","        0.4167, 0.8789, 0.7862, 0.8571, 0.7751, 0.9086], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.549\n","Final per class accuracy on test set:  tensor([0.4577, 0.5806, 0.7317, 0.4651, 0.8638, 0.5581, 0.4400, 0.8378, 0.5613,\n","        0.4167, 0.8789, 0.8034, 0.8095, 0.7572, 0.8977], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_4193977854\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_4193977854\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1863727779\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1863727779\n","Epoch 0 with train loss: 2.839 train accuracy: 22.341 validation accuracy: 21.619\n","Per class train accuracy:  tensor([0.1627, 0.2491, 0.4358, 0.0389, 0.2560, 0.0913, 0.2748, 0.0343, 0.2602,\n","        0.0143, 0.1663, 0.3060, 0.0119, 0.1350, 0.7257], device='cuda:0')\n","Per class val accuracy:  tensor([0.2254, 0.2609, 0.4220, 0.0116, 0.2545, 0.0752, 0.2027, 0.0162, 0.2194,\n","        0.0833, 0.1661, 0.3194, 0.0000, 0.1427, 0.6229], device='cuda:0')\n","Epoch 9 with train loss: 1.054 train accuracy: 73.137 validation accuracy: 71.238\n","Per class train accuracy:  tensor([0.4693, 0.6029, 0.7203, 0.4903, 0.7943, 0.6388, 0.6171, 0.7798, 0.5419,\n","        0.5429, 0.8718, 0.7801, 0.8135, 0.7694, 0.9124], device='cuda:0')\n","Per class val accuracy:  tensor([0.4577, 0.5000, 0.6878, 0.3721, 0.7706, 0.5763, 0.5811, 0.8054, 0.4774,\n","        0.5833, 0.8616, 0.7813, 0.8452, 0.7799, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.039\n","Final per class accuracy on test set:  tensor([0.4577, 0.5914, 0.7024, 0.4070, 0.8315, 0.6219, 0.5733, 0.8162, 0.5419,\n","        0.3333, 0.8927, 0.7690, 0.8214, 0.7790, 0.9261], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1863727779\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1863727779\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  170173784\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  170173784\n","Epoch 0 with train loss: 2.802 train accuracy: 27.117 validation accuracy: 25.164\n","Per class train accuracy:  tensor([0.2241, 0.4332, 0.3862, 0.1556, 0.2500, 0.1498, 0.1216, 0.2004, 0.3075,\n","        0.0714, 0.6189, 0.2141, 0.1349, 0.2056, 0.4152], device='cuda:0')\n","Per class val accuracy:  tensor([0.2394, 0.4348, 0.3683, 0.1279, 0.2222, 0.1207, 0.1757, 0.2270, 0.2516,\n","        0.0417, 0.5952, 0.1990, 0.1071, 0.1778, 0.3886], device='cuda:0')\n","Epoch 9 with train loss: 1.109 train accuracy: 71.909 validation accuracy: 71.483\n","Per class train accuracy:  tensor([0.4929, 0.6065, 0.7366, 0.5914, 0.7560, 0.5954, 0.5811, 0.8267, 0.6344,\n","        0.5571, 0.8753, 0.7703, 0.8333, 0.7066, 0.9029], device='cuda:0')\n","Per class val accuracy:  tensor([0.5493, 0.5000, 0.7146, 0.5116, 0.7491, 0.5718, 0.5135, 0.8541, 0.5935,\n","        0.5000, 0.9100, 0.7961, 0.8690, 0.7050, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.331\n","Final per class accuracy on test set:  tensor([0.5211, 0.5269, 0.7366, 0.5349, 0.8172, 0.5877, 0.5333, 0.8324, 0.6452,\n","        0.5000, 0.8824, 0.7420, 0.7857, 0.7403, 0.8920], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_170173784\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_170173784\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2342954646\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2342954646\n","Epoch 0 with train loss: 2.885 train accuracy: 19.276 validation accuracy: 19.329\n","Per class train accuracy:  tensor([0.0283, 0.1083, 0.1797, 0.1245, 0.1627, 0.1688, 0.2297, 0.0054, 0.1204,\n","        0.1857, 0.3776, 0.2568, 0.3690, 0.2056, 0.1905], device='cuda:0')\n","Per class val accuracy:  tensor([0.0352, 0.0761, 0.1780, 0.0814, 0.1720, 0.2118, 0.1892, 0.0054, 0.1419,\n","        0.2083, 0.3910, 0.2359, 0.3810, 0.1983, 0.1657], device='cuda:0')\n","Epoch 9 with train loss: 1.091 train accuracy: 72.555 validation accuracy: 70.311\n","Per class train accuracy:  tensor([0.4458, 0.6282, 0.7138, 0.5564, 0.8002, 0.5901, 0.5360, 0.7852, 0.6172,\n","        0.4857, 0.8938, 0.7687, 0.8333, 0.7549, 0.9105], device='cuda:0')\n","Per class val accuracy:  tensor([0.4718, 0.5109, 0.6951, 0.4767, 0.7814, 0.5421, 0.4189, 0.8054, 0.5355,\n","        0.3333, 0.8997, 0.7740, 0.8571, 0.7340, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 71.078\n","Final per class accuracy on test set:  tensor([0.4155, 0.5699, 0.7073, 0.5349, 0.8315, 0.5513, 0.4533, 0.8162, 0.5613,\n","        0.3750, 0.8927, 0.7641, 0.8095, 0.7355, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2342954646\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2342954646\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  116846604\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  116846604\n","Epoch 0 with train loss: 2.858 train accuracy: 21.086 validation accuracy: 21.374\n","Per class train accuracy:  tensor([0.1014, 0.2274, 0.3472, 0.0584, 0.0945, 0.2008, 0.0811, 0.0469, 0.3742,\n","        0.0286, 0.1628, 0.3421, 0.0873, 0.1689, 0.3962], device='cuda:0')\n","Per class val accuracy:  tensor([0.0915, 0.1957, 0.3512, 0.0698, 0.1075, 0.2050, 0.0541, 0.0649, 0.3032,\n","        0.0417, 0.1349, 0.3538, 0.0714, 0.1983, 0.3771], device='cuda:0')\n","Epoch 9 with train loss: 1.079 train accuracy: 73.156 validation accuracy: 71.401\n","Per class train accuracy:  tensor([0.3892, 0.6137, 0.7593, 0.5603, 0.7608, 0.6441, 0.5045, 0.8195, 0.5978,\n","        0.3857, 0.8741, 0.8056, 0.8571, 0.7416, 0.9143], device='cuda:0')\n","Per class val accuracy:  tensor([0.4507, 0.4457, 0.7463, 0.4419, 0.7204, 0.6128, 0.5000, 0.8216, 0.4839,\n","        0.2500, 0.8754, 0.8084, 0.8929, 0.7437, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.849\n","Final per class accuracy on test set:  tensor([0.3944, 0.5054, 0.7561, 0.4767, 0.8100, 0.6082, 0.4800, 0.8216, 0.5742,\n","        0.4167, 0.8685, 0.7936, 0.8333, 0.7621, 0.9432], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_116846604\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_116846604\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2105922959\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2105922959\n","Epoch 0 with train loss: 2.825 train accuracy: 22.269 validation accuracy: 21.129\n","Per class train accuracy:  tensor([0.0660, 0.3682, 0.1366, 0.2101, 0.1938, 0.3209, 0.0901, 0.6083, 0.0323,\n","        0.3000, 0.2910, 0.3700, 0.0833, 0.1495, 0.0457], device='cuda:0')\n","Per class val accuracy:  tensor([0.0563, 0.3587, 0.1073, 0.2674, 0.1935, 0.2802, 0.0946, 0.5351, 0.0581,\n","        0.2500, 0.2837, 0.3661, 0.0476, 0.1511, 0.0514], device='cuda:0')\n","Epoch 9 with train loss: 1.086 train accuracy: 72.928 validation accuracy: 72.165\n","Per class train accuracy:  tensor([0.4434, 0.6390, 0.7463, 0.6070, 0.7907, 0.6433, 0.4369, 0.7906, 0.6387,\n","        0.5857, 0.8741, 0.8056, 0.8333, 0.7122, 0.9181], device='cuda:0')\n","Per class val accuracy:  tensor([0.5563, 0.5652, 0.7122, 0.5233, 0.7599, 0.5968, 0.3919, 0.7838, 0.5419,\n","        0.5000, 0.8997, 0.8206, 0.8810, 0.7376, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.576\n","Final per class accuracy on test set:  tensor([0.4859, 0.5699, 0.7268, 0.5349, 0.8172, 0.6401, 0.4533, 0.7946, 0.6452,\n","        0.4583, 0.8754, 0.8010, 0.7976, 0.7138, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2105922959\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2105922959\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2739899259\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2739899259\n","Epoch 0 with train loss: 2.829 train accuracy: 21.923 validation accuracy: 19.193\n","Per class train accuracy:  tensor([0.1675, 0.3574, 0.2293, 0.0973, 0.4701, 0.2342, 0.1216, 0.3249, 0.4065,\n","        0.0714, 0.1998, 0.1854, 0.2341, 0.1060, 0.2095], device='cuda:0')\n","Per class val accuracy:  tensor([0.1127, 0.3152, 0.1951, 0.0581, 0.4444, 0.2164, 0.0946, 0.2595, 0.3032,\n","        0.0000, 0.1869, 0.1351, 0.2262, 0.1112, 0.1886], device='cuda:0')\n","Epoch 9 with train loss: 1.072 train accuracy: 72.437 validation accuracy: 69.847\n","Per class train accuracy:  tensor([0.4670, 0.6534, 0.7634, 0.5409, 0.7859, 0.6213, 0.4820, 0.8105, 0.5720,\n","        0.4000, 0.8591, 0.7941, 0.8175, 0.7158, 0.9295], device='cuda:0')\n","Per class val accuracy:  tensor([0.4577, 0.5435, 0.7561, 0.3953, 0.7455, 0.5558, 0.4054, 0.7892, 0.4645,\n","        0.3333, 0.8927, 0.7961, 0.8690, 0.7062, 0.8914], device='cuda:0')\n","Our final test accuracy for the GNN is: 71.786\n","Final per class accuracy on test set:  tensor([0.4225, 0.5914, 0.7610, 0.4767, 0.8172, 0.5854, 0.4667, 0.8216, 0.5935,\n","        0.3333, 0.8685, 0.7764, 0.8333, 0.7186, 0.9318], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2739899259\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2739899259\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1024258131\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1024258131\n","Epoch 0 with train loss: 2.849 train accuracy: 21.477 validation accuracy: 21.619\n","Per class train accuracy:  tensor([0.0778, 0.1372, 0.4049, 0.1051, 0.3804, 0.0791, 0.1036, 0.2780, 0.0968,\n","        0.0000, 0.5658, 0.0509, 0.3294, 0.1471, 0.2305], device='cuda:0')\n","Per class val accuracy:  tensor([0.1268, 0.0870, 0.3902, 0.1047, 0.3226, 0.0729, 0.0541, 0.2649, 0.1032,\n","        0.0833, 0.5848, 0.0614, 0.3929, 0.1572, 0.2743], device='cuda:0')\n","Epoch 9 with train loss: 1.069 train accuracy: 71.991 validation accuracy: 70.802\n","Per class train accuracy:  tensor([0.3726, 0.5993, 0.7650, 0.5681, 0.7919, 0.6023, 0.4910, 0.7690, 0.6258,\n","        0.1429, 0.8972, 0.7572, 0.8135, 0.7364, 0.9162], device='cuda:0')\n","Per class val accuracy:  tensor([0.4366, 0.4891, 0.7317, 0.5465, 0.7348, 0.5353, 0.4730, 0.7892, 0.5935,\n","        0.1250, 0.9066, 0.7912, 0.8571, 0.7388, 0.9143], device='cuda:0')\n","Our final test accuracy for the GNN is: 71.841\n","Final per class accuracy on test set:  tensor([0.4648, 0.5054, 0.7488, 0.5349, 0.8136, 0.5809, 0.4667, 0.8270, 0.6258,\n","        0.2083, 0.8893, 0.7174, 0.7500, 0.7548, 0.9261], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1024258131\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1024258131\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  806299656\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  806299656\n","Epoch 0 with train loss: 2.892 train accuracy: 19.995 validation accuracy: 20.883\n","Per class train accuracy:  tensor([0.1132, 0.1913, 0.0642, 0.0895, 0.4545, 0.2053, 0.2658, 0.3357, 0.2925,\n","        0.0143, 0.1085, 0.3470, 0.2659, 0.1362, 0.0781], device='cuda:0')\n","Per class val accuracy:  tensor([0.1197, 0.1630, 0.0854, 0.0930, 0.4695, 0.2164, 0.2432, 0.3514, 0.2903,\n","        0.0833, 0.0830, 0.3784, 0.2857, 0.1403, 0.0971], device='cuda:0')\n","Epoch 9 with train loss: 1.085 train accuracy: 72.364 validation accuracy: 71.919\n","Per class train accuracy:  tensor([0.4410, 0.6065, 0.7049, 0.6070, 0.7584, 0.6365, 0.4910, 0.7924, 0.6043,\n","        0.5000, 0.8799, 0.7949, 0.8333, 0.7328, 0.9200], device='cuda:0')\n","Per class val accuracy:  tensor([0.5070, 0.5217, 0.7146, 0.5349, 0.7204, 0.6196, 0.4459, 0.7730, 0.5226,\n","        0.2917, 0.9135, 0.8108, 0.8333, 0.7473, 0.9143], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.712\n","Final per class accuracy on test set:  tensor([0.4718, 0.5054, 0.6951, 0.5581, 0.8172, 0.6424, 0.5200, 0.8054, 0.6129,\n","        0.3333, 0.8858, 0.7912, 0.7857, 0.7452, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_806299656\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_806299656\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  880019963\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  880019963\n","Epoch 0 with train loss: 2.969 train accuracy: 16.010 validation accuracy: 15.840\n","Per class train accuracy:  tensor([0.0637, 0.0686, 0.0789, 0.1984, 0.3373, 0.1711, 0.1081, 0.3646, 0.0495,\n","        0.0857, 0.0358, 0.1091, 0.1151, 0.0919, 0.7295], device='cuda:0')\n","Per class val accuracy:  tensor([0.1127, 0.0652, 0.0756, 0.1860, 0.3226, 0.1777, 0.0811, 0.3135, 0.0645,\n","        0.0417, 0.0450, 0.0934, 0.0833, 0.1064, 0.7029], device='cuda:0')\n","Epoch 9 with train loss: 1.135 train accuracy: 70.563 validation accuracy: 69.466\n","Per class train accuracy:  tensor([0.4764, 0.6065, 0.7447, 0.5370, 0.7835, 0.6198, 0.4505, 0.7960, 0.6215,\n","        0.2143, 0.8684, 0.7219, 0.8214, 0.6860, 0.9086], device='cuda:0')\n","Per class val accuracy:  tensor([0.4789, 0.4891, 0.7195, 0.4651, 0.7527, 0.5786, 0.4324, 0.7784, 0.5355,\n","        0.3333, 0.8789, 0.7248, 0.8810, 0.7110, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 70.724\n","Final per class accuracy on test set:  tensor([0.5211, 0.4946, 0.7341, 0.4767, 0.8495, 0.6036, 0.4267, 0.8270, 0.6323,\n","        0.0417, 0.8581, 0.7150, 0.7976, 0.6993, 0.9318], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_880019963\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_880019963\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1818027900\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1818027900\n","Epoch 0 with train loss: 2.839 train accuracy: 21.286 validation accuracy: 21.947\n","Per class train accuracy:  tensor([0.0943, 0.0866, 0.2024, 0.0700, 0.4856, 0.1452, 0.1351, 0.2708, 0.1699,\n","        0.3000, 0.2286, 0.2240, 0.1429, 0.1310, 0.5714], device='cuda:0')\n","Per class val accuracy:  tensor([0.1127, 0.1304, 0.1927, 0.1047, 0.4373, 0.1754, 0.0676, 0.2811, 0.1613,\n","        0.2083, 0.2284, 0.2310, 0.1429, 0.1439, 0.6400], device='cuda:0')\n","Epoch 9 with train loss: 1.079 train accuracy: 72.110 validation accuracy: 70.256\n","Per class train accuracy:  tensor([0.3892, 0.6173, 0.7553, 0.5603, 0.7835, 0.6221, 0.4640, 0.7690, 0.6151,\n","        0.4857, 0.8764, 0.7957, 0.8095, 0.7179, 0.9181], device='cuda:0')\n","Per class val accuracy:  tensor([0.3803, 0.5217, 0.7146, 0.4302, 0.7276, 0.5558, 0.4459, 0.7892, 0.5677,\n","        0.5417, 0.8962, 0.8133, 0.8571, 0.7267, 0.8857], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.576\n","Final per class accuracy on test set:  tensor([0.3873, 0.6022, 0.7537, 0.5116, 0.8172, 0.6082, 0.4400, 0.8000, 0.5935,\n","        0.3750, 0.8893, 0.8157, 0.7976, 0.7319, 0.9205], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1818027900\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1818027900\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2135956485\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2135956485\n","Epoch 0 with train loss: 2.914 train accuracy: 19.967 validation accuracy: 19.438\n","Per class train accuracy:  tensor([0.0991, 0.2924, 0.2707, 0.1089, 0.1292, 0.1939, 0.1622, 0.3682, 0.3161,\n","        0.1429, 0.3684, 0.1001, 0.0714, 0.0556, 0.6743], device='cuda:0')\n","Per class val accuracy:  tensor([0.1408, 0.2826, 0.2463, 0.0930, 0.1111, 0.2050, 0.1351, 0.3838, 0.2839,\n","        0.0000, 0.3702, 0.0983, 0.1667, 0.0472, 0.6400], device='cuda:0')\n","Epoch 9 with train loss: 1.105 train accuracy: 72.601 validation accuracy: 71.047\n","Per class train accuracy:  tensor([0.4670, 0.6426, 0.7756, 0.5447, 0.7584, 0.6814, 0.5090, 0.7960, 0.6409,\n","        0.5571, 0.8753, 0.8113, 0.8532, 0.6634, 0.9181], device='cuda:0')\n","Per class val accuracy:  tensor([0.4930, 0.5543, 0.7561, 0.4070, 0.7276, 0.6492, 0.5676, 0.8000, 0.5419,\n","        0.3750, 0.8893, 0.7936, 0.8810, 0.6723, 0.9086], device='cuda:0')\n","Our final test accuracy for the GNN is: 71.514\n","Final per class accuracy on test set:  tensor([0.4718, 0.5806, 0.7293, 0.4884, 0.8172, 0.6629, 0.4667, 0.7838, 0.6710,\n","        0.2917, 0.8651, 0.7838, 0.7976, 0.6727, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2135956485\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2135956485\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3710910636\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3710910636\n","Epoch 0 with train loss: 2.872 train accuracy: 19.967 validation accuracy: 18.839\n","Per class train accuracy:  tensor([0.0448, 0.1877, 0.0163, 0.1946, 0.1794, 0.2281, 0.0450, 0.6570, 0.1656,\n","        0.1000, 0.3637, 0.3363, 0.2381, 0.1197, 0.1219], device='cuda:0')\n","Per class val accuracy:  tensor([0.0493, 0.1739, 0.0195, 0.1395, 0.1505, 0.1913, 0.0946, 0.5838, 0.0968,\n","        0.0417, 0.3875, 0.3538, 0.2738, 0.1197, 0.0743], device='cuda:0')\n","Epoch 9 with train loss: 1.077 train accuracy: 73.447 validation accuracy: 72.519\n","Per class train accuracy:  tensor([0.4599, 0.5993, 0.7016, 0.5447, 0.7644, 0.6350, 0.4730, 0.7870, 0.6473,\n","        0.5143, 0.8741, 0.8056, 0.8254, 0.7759, 0.9257], device='cuda:0')\n","Per class val accuracy:  tensor([0.4930, 0.5326, 0.7073, 0.4186, 0.7491, 0.5718, 0.4865, 0.8108, 0.5677,\n","        0.5417, 0.9031, 0.8206, 0.8571, 0.7787, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.312\n","Final per class accuracy on test set:  tensor([0.4648, 0.5269, 0.6976, 0.4419, 0.8172, 0.5923, 0.4933, 0.8000, 0.6516,\n","        0.4167, 0.8754, 0.8034, 0.7738, 0.7983, 0.9261], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3710910636\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3710910636\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1517964140\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1517964140\n","Epoch 0 with train loss: 2.844 train accuracy: 22.996 validation accuracy: 22.710\n","Per class train accuracy:  tensor([0.2217, 0.0542, 0.2797, 0.0078, 0.0837, 0.3163, 0.1081, 0.2112, 0.2409,\n","        0.1857, 0.5012, 0.1838, 0.3968, 0.0988, 0.6057], device='cuda:0')\n","Per class val accuracy:  tensor([0.2113, 0.0217, 0.2561, 0.0233, 0.1111, 0.3030, 0.0811, 0.2216, 0.2903,\n","        0.2917, 0.4913, 0.2064, 0.3333, 0.0907, 0.5829], device='cuda:0')\n","Epoch 9 with train loss: 1.090 train accuracy: 73.001 validation accuracy: 70.911\n","Per class train accuracy:  tensor([0.5094, 0.6606, 0.7626, 0.3930, 0.7464, 0.6882, 0.5180, 0.8087, 0.6172,\n","        0.5000, 0.8845, 0.7564, 0.8770, 0.7207, 0.9067], device='cuda:0')\n","Per class val accuracy:  tensor([0.5352, 0.5435, 0.6976, 0.3140, 0.7168, 0.6355, 0.5270, 0.7946, 0.5677,\n","        0.4583, 0.8927, 0.7813, 0.8929, 0.7122, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.883\n","Final per class accuracy on test set:  tensor([0.5704, 0.5914, 0.7659, 0.3837, 0.8172, 0.6902, 0.5067, 0.8108, 0.6323,\n","        0.4583, 0.8893, 0.7641, 0.8929, 0.7222, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1517964140\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1517964140\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  4083009686\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  4083009686\n","Epoch 0 with train loss: 2.916 train accuracy: 20.176 validation accuracy: 19.984\n","Per class train accuracy:  tensor([0.1486, 0.0758, 0.0992, 0.0428, 0.2093, 0.1635, 0.1982, 0.5614, 0.0043,\n","        0.0143, 0.2217, 0.3560, 0.0000, 0.1520, 0.4762], device='cuda:0')\n","Per class val accuracy:  tensor([0.1831, 0.0652, 0.1024, 0.1163, 0.2330, 0.1162, 0.2027, 0.5514, 0.0065,\n","        0.0000, 0.2422, 0.3268, 0.0000, 0.1536, 0.4857], device='cuda:0')\n","Epoch 9 with train loss: 1.059 train accuracy: 73.410 validation accuracy: 72.274\n","Per class train accuracy:  tensor([0.5165, 0.6209, 0.7626, 0.5175, 0.7835, 0.6760, 0.5631, 0.7852, 0.5376,\n","        0.4429, 0.8776, 0.7966, 0.8214, 0.7291, 0.9067], device='cuda:0')\n","Per class val accuracy:  tensor([0.5775, 0.5543, 0.7317, 0.4070, 0.7276, 0.6287, 0.5000, 0.8000, 0.4645,\n","        0.2500, 0.9135, 0.8182, 0.8810, 0.7473, 0.8686], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.230\n","Final per class accuracy on test set:  tensor([0.5352, 0.5269, 0.7317, 0.5349, 0.8172, 0.6629, 0.5467, 0.8054, 0.5742,\n","        0.1667, 0.8754, 0.7715, 0.7857, 0.7512, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_4083009686\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_4083009686\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2455059856\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2455059856\n","Epoch 0 with train loss: 2.914 train accuracy: 20.504 validation accuracy: 20.802\n","Per class train accuracy:  tensor([0.1156, 0.2202, 0.1585, 0.1440, 0.2727, 0.1506, 0.0766, 0.0578, 0.1806,\n","        0.0000, 0.4804, 0.0697, 0.0913, 0.1721, 0.7657], device='cuda:0')\n","Per class val accuracy:  tensor([0.0986, 0.2065, 0.1488, 0.1744, 0.2652, 0.1526, 0.1081, 0.0865, 0.1419,\n","        0.0417, 0.5190, 0.0688, 0.0714, 0.1935, 0.6971], device='cuda:0')\n","Epoch 9 with train loss: 1.064 train accuracy: 73.610 validation accuracy: 71.701\n","Per class train accuracy:  tensor([0.3373, 0.5704, 0.7577, 0.5564, 0.8361, 0.6738, 0.4640, 0.8159, 0.5957,\n","        0.4857, 0.8868, 0.8072, 0.8651, 0.7316, 0.9143], device='cuda:0')\n","Per class val accuracy:  tensor([0.3451, 0.4891, 0.7195, 0.4535, 0.7814, 0.6059, 0.3919, 0.8378, 0.5290,\n","        0.3333, 0.8997, 0.8034, 0.8929, 0.7533, 0.9086], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.039\n","Final per class accuracy on test set:  tensor([0.3662, 0.4839, 0.7537, 0.5116, 0.8638, 0.6241, 0.4533, 0.8595, 0.5548,\n","        0.2917, 0.8893, 0.7715, 0.8690, 0.7536, 0.9261], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2455059856\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2455059856\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  400225693\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  400225693\n","Epoch 0 with train loss: 2.908 train accuracy: 18.821 validation accuracy: 18.593\n","Per class train accuracy:  tensor([0.0495, 0.1264, 0.2610, 0.2646, 0.0502, 0.2395, 0.0360, 0.1859, 0.1763,\n","        0.0000, 0.5624, 0.1378, 0.0714, 0.1403, 0.1010], device='cuda:0')\n","Per class val accuracy:  tensor([0.0563, 0.1739, 0.2341, 0.3256, 0.0394, 0.1891, 0.0405, 0.2162, 0.2000,\n","        0.0417, 0.5606, 0.1130, 0.0357, 0.1632, 0.1086], device='cuda:0')\n","Epoch 9 with train loss: 1.071 train accuracy: 73.228 validation accuracy: 71.838\n","Per class train accuracy:  tensor([0.4198, 0.5776, 0.7049, 0.5564, 0.7787, 0.6601, 0.5045, 0.7996, 0.6409,\n","        0.3286, 0.8949, 0.7957, 0.8770, 0.7525, 0.9029], device='cuda:0')\n","Per class val accuracy:  tensor([0.4507, 0.5000, 0.7000, 0.5581, 0.7348, 0.6150, 0.4865, 0.8324, 0.5355,\n","        0.2917, 0.9100, 0.7715, 0.9048, 0.7545, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.747\n","Final per class accuracy on test set:  tensor([0.4930, 0.4731, 0.7122, 0.5116, 0.8351, 0.6401, 0.4667, 0.8541, 0.6258,\n","        0.2500, 0.9066, 0.7568, 0.8929, 0.7754, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_400225693\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_400225693\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  89475662\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  89475662\n","Epoch 0 with train loss: 2.810 train accuracy: 25.280 validation accuracy: 25.273\n","Per class train accuracy:  tensor([0.2406, 0.3141, 0.1902, 0.0078, 0.6065, 0.3582, 0.1216, 0.1245, 0.0731,\n","        0.1000, 0.3788, 0.2018, 0.6468, 0.1463, 0.2648], device='cuda:0')\n","Per class val accuracy:  tensor([0.2606, 0.3043, 0.1854, 0.0000, 0.5950, 0.3280, 0.0811, 0.1459, 0.0774,\n","        0.2500, 0.3633, 0.2064, 0.6548, 0.1608, 0.2743], device='cuda:0')\n","Epoch 9 with train loss: 1.044 train accuracy: 73.638 validation accuracy: 71.429\n","Per class train accuracy:  tensor([0.5047, 0.6679, 0.7163, 0.5097, 0.8146, 0.6935, 0.5000, 0.7870, 0.5656,\n","        0.6143, 0.8834, 0.7744, 0.8413, 0.7384, 0.9238], device='cuda:0')\n","Per class val accuracy:  tensor([0.5704, 0.5217, 0.7049, 0.3372, 0.7491, 0.6082, 0.4865, 0.7892, 0.4710,\n","        0.4583, 0.8927, 0.7887, 0.8690, 0.7521, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.829\n","Final per class accuracy on test set:  tensor([0.5141, 0.6129, 0.7000, 0.4884, 0.8602, 0.6720, 0.4933, 0.8486, 0.6194,\n","        0.3333, 0.8754, 0.7543, 0.8214, 0.7548, 0.9375], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_89475662\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_89475662\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  361232447\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  361232447\n","Epoch 0 with train loss: 2.803 train accuracy: 25.107 validation accuracy: 24.782\n","Per class train accuracy:  tensor([0.0731, 0.1191, 0.2764, 0.1556, 0.2572, 0.2563, 0.0225, 0.6877, 0.0753,\n","        0.1000, 0.3349, 0.2847, 0.7302, 0.1354, 0.3410], device='cuda:0')\n","Per class val accuracy:  tensor([0.0775, 0.0652, 0.2878, 0.1395, 0.2151, 0.2437, 0.0405, 0.6649, 0.0774,\n","        0.0833, 0.3114, 0.3317, 0.7738, 0.1282, 0.3371], device='cuda:0')\n","Epoch 9 with train loss: 1.059 train accuracy: 72.928 validation accuracy: 72.110\n","Per class train accuracy:  tensor([0.3514, 0.5884, 0.7610, 0.5875, 0.7835, 0.6365, 0.4324, 0.8069, 0.6022,\n","        0.2714, 0.8649, 0.7998, 0.8373, 0.7521, 0.9200], device='cuda:0')\n","Per class val accuracy:  tensor([0.4225, 0.4891, 0.7488, 0.5116, 0.7455, 0.6128, 0.4324, 0.8054, 0.5548,\n","        0.3333, 0.8754, 0.8059, 0.8690, 0.7533, 0.9143], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.257\n","Final per class accuracy on test set:  tensor([0.4155, 0.5376, 0.7341, 0.4884, 0.8315, 0.6287, 0.4400, 0.7892, 0.6581,\n","        0.2917, 0.8651, 0.7912, 0.8810, 0.7645, 0.9261], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_361232447\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_361232447\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3647665043\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3647665043\n","Epoch 0 with train loss: 2.915 train accuracy: 21.186 validation accuracy: 20.965\n","Per class train accuracy:  tensor([0.0755, 0.2166, 0.4846, 0.1012, 0.0215, 0.1163, 0.0721, 0.4639, 0.0753,\n","        0.0571, 0.0704, 0.1731, 0.5873, 0.1463, 0.6648], device='cuda:0')\n","Per class val accuracy:  tensor([0.0775, 0.1957, 0.4341, 0.1279, 0.0323, 0.1503, 0.0946, 0.4811, 0.1097,\n","        0.0833, 0.0588, 0.1720, 0.6310, 0.1342, 0.6286], device='cuda:0')\n","Epoch 9 with train loss: 1.108 train accuracy: 71.891 validation accuracy: 71.183\n","Per class train accuracy:  tensor([0.3231, 0.5776, 0.7528, 0.6148, 0.7560, 0.6327, 0.4414, 0.7798, 0.5849,\n","        0.3429, 0.8984, 0.8039, 0.8532, 0.7166, 0.9162], device='cuda:0')\n","Per class val accuracy:  tensor([0.3944, 0.5109, 0.7488, 0.5000, 0.7276, 0.6036, 0.4459, 0.7838, 0.5290,\n","        0.3750, 0.9100, 0.7862, 0.8810, 0.7376, 0.8800], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.277\n","Final per class accuracy on test set:  tensor([0.3239, 0.5806, 0.7463, 0.5698, 0.7885, 0.6036, 0.4667, 0.7946, 0.6323,\n","        0.4167, 0.8893, 0.8157, 0.8095, 0.7331, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3647665043\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3647665043\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1221215631\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1221215631\n","Epoch 0 with train loss: 2.859 train accuracy: 19.858 validation accuracy: 19.275\n","Per class train accuracy:  tensor([0.0401, 0.3394, 0.1528, 0.2062, 0.3313, 0.1498, 0.0450, 0.3249, 0.0710,\n","        0.0143, 0.4018, 0.2494, 0.2143, 0.1592, 0.0610], device='cuda:0')\n","Per class val accuracy:  tensor([0.0423, 0.3587, 0.1390, 0.1744, 0.3262, 0.1845, 0.0405, 0.3514, 0.0258,\n","        0.0000, 0.3841, 0.2555, 0.2619, 0.1330, 0.0286], device='cuda:0')\n","Epoch 9 with train loss: 1.064 train accuracy: 72.983 validation accuracy: 71.101\n","Per class train accuracy:  tensor([0.3561, 0.6137, 0.7846, 0.5798, 0.8002, 0.6190, 0.4324, 0.7996, 0.5656,\n","        0.4000, 0.8949, 0.7998, 0.8254, 0.7428, 0.9029], device='cuda:0')\n","Per class val accuracy:  tensor([0.4577, 0.5326, 0.7561, 0.5233, 0.7599, 0.5923, 0.3919, 0.8000, 0.5226,\n","        0.2083, 0.9031, 0.8108, 0.8690, 0.7050, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.094\n","Final per class accuracy on test set:  tensor([0.4155, 0.5269, 0.7561, 0.5349, 0.8638, 0.6150, 0.3733, 0.8216, 0.5935,\n","        0.3333, 0.8927, 0.8084, 0.8333, 0.7379, 0.9148], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1221215631\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1221215631\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2036056847\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2036056847\n","Epoch 0 with train loss: 2.934 train accuracy: 15.010 validation accuracy: 15.185\n","Per class train accuracy:  tensor([0.1014, 0.3610, 0.2138, 0.1284, 0.0467, 0.1080, 0.1667, 0.1083, 0.1075,\n","        0.0571, 0.3441, 0.1247, 0.3095, 0.1044, 0.1752], device='cuda:0')\n","Per class val accuracy:  tensor([0.1056, 0.3913, 0.2585, 0.0465, 0.0573, 0.1185, 0.1486, 0.1081, 0.0710,\n","        0.0417, 0.3080, 0.1548, 0.2500, 0.1028, 0.1543], device='cuda:0')\n","Epoch 9 with train loss: 1.094 train accuracy: 72.701 validation accuracy: 70.911\n","Per class train accuracy:  tensor([0.3703, 0.6462, 0.7683, 0.5486, 0.7464, 0.6677, 0.5541, 0.7762, 0.5785,\n","        0.4429, 0.8649, 0.7555, 0.8056, 0.7537, 0.8990], device='cuda:0')\n","Per class val accuracy:  tensor([0.4296, 0.5435, 0.7366, 0.4186, 0.7276, 0.6150, 0.4324, 0.7622, 0.4774,\n","        0.5417, 0.8824, 0.7543, 0.8571, 0.7630, 0.8800], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.658\n","Final per class accuracy on test set:  tensor([0.4577, 0.5806, 0.7341, 0.4651, 0.8280, 0.6538, 0.5333, 0.7730, 0.6387,\n","        0.4167, 0.8685, 0.7150, 0.7619, 0.7633, 0.9091], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2036056847\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2036056847\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  1860537279\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  1860537279\n","Epoch 0 with train loss: 2.811 train accuracy: 23.697 validation accuracy: 22.356\n","Per class train accuracy:  tensor([0.1297, 0.3574, 0.3447, 0.0428, 0.2703, 0.2464, 0.1306, 0.1643, 0.4645,\n","        0.1714, 0.1189, 0.1009, 0.4762, 0.2418, 0.3276], device='cuda:0')\n","Per class val accuracy:  tensor([0.1690, 0.3478, 0.2756, 0.0581, 0.2688, 0.2141, 0.0676, 0.1676, 0.3226,\n","        0.1250, 0.1661, 0.0835, 0.5476, 0.2418, 0.3429], device='cuda:0')\n","Epoch 9 with train loss: 1.041 train accuracy: 74.229 validation accuracy: 72.219\n","Per class train accuracy:  tensor([0.4198, 0.5921, 0.7886, 0.5486, 0.8158, 0.6525, 0.5225, 0.8141, 0.6043,\n","        0.5571, 0.8499, 0.7736, 0.8294, 0.7686, 0.9238], device='cuda:0')\n","Per class val accuracy:  tensor([0.4859, 0.5109, 0.7610, 0.4535, 0.7706, 0.6241, 0.4459, 0.8216, 0.5290,\n","        0.4583, 0.8547, 0.7518, 0.8690, 0.7678, 0.8800], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.529\n","Final per class accuracy on test set:  tensor([0.4437, 0.5269, 0.7634, 0.5000, 0.8387, 0.6333, 0.5200, 0.8000, 0.6258,\n","        0.5417, 0.8581, 0.7199, 0.8095, 0.7874, 0.9205], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_1860537279\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_1860537279\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  516507873\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  516507873\n","Epoch 0 with train loss: 2.759 train accuracy: 24.861 validation accuracy: 24.591\n","Per class train accuracy:  tensor([0.0613, 0.6137, 0.2959, 0.0856, 0.2572, 0.3985, 0.0721, 0.3718, 0.1484,\n","        0.1857, 0.3164, 0.1616, 0.3968, 0.1798, 0.1733], device='cuda:0')\n","Per class val accuracy:  tensor([0.0352, 0.5761, 0.2683, 0.0930, 0.2796, 0.3326, 0.0541, 0.3459, 0.2129,\n","        0.1667, 0.3875, 0.1572, 0.3929, 0.1862, 0.1943], device='cuda:0')\n","Epoch 9 with train loss: 1.053 train accuracy: 72.828 validation accuracy: 71.265\n","Per class train accuracy:  tensor([0.4245, 0.6137, 0.7577, 0.5370, 0.7847, 0.6958, 0.3829, 0.7816, 0.6581,\n","        0.4571, 0.8788, 0.7539, 0.8135, 0.7251, 0.9048], device='cuda:0')\n","Per class val accuracy:  tensor([0.5070, 0.4783, 0.7220, 0.4535, 0.7133, 0.6583, 0.4054, 0.7946, 0.6258,\n","        0.2917, 0.8893, 0.7690, 0.8810, 0.7170, 0.8971], device='cuda:0')\n","Our final test accuracy for the GNN is: 73.856\n","Final per class accuracy on test set:  tensor([0.5352, 0.5806, 0.7171, 0.4884, 0.8495, 0.6743, 0.4133, 0.7946, 0.6387,\n","        0.2917, 0.8720, 0.7838, 0.8571, 0.7512, 0.9318], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_516507873\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_516507873\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3692371949\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3692371949\n","Epoch 0 with train loss: 2.856 train accuracy: 22.960 validation accuracy: 23.146\n","Per class train accuracy:  tensor([0.0802, 0.4007, 0.2488, 0.0973, 0.0574, 0.2236, 0.0450, 0.0271, 0.0753,\n","        0.0143, 0.4122, 0.3224, 0.5476, 0.1697, 0.6400], device='cuda:0')\n","Per class val accuracy:  tensor([0.1056, 0.4022, 0.2463, 0.1163, 0.0681, 0.2460, 0.1081, 0.0324, 0.0645,\n","        0.0000, 0.3737, 0.3391, 0.5357, 0.1644, 0.6171], device='cuda:0')\n","Epoch 9 with train loss: 1.048 train accuracy: 73.465 validation accuracy: 72.056\n","Per class train accuracy:  tensor([0.4410, 0.5668, 0.7480, 0.5409, 0.7799, 0.7065, 0.5045, 0.8087, 0.6172,\n","        0.4429, 0.8764, 0.7186, 0.8333, 0.7642, 0.9010], device='cuda:0')\n","Per class val accuracy:  tensor([0.4789, 0.5652, 0.7171, 0.4767, 0.7419, 0.6629, 0.4324, 0.7838, 0.5419,\n","        0.3750, 0.8858, 0.7248, 0.8690, 0.7775, 0.8743], device='cuda:0')\n","Our final test accuracy for the GNN is: 74.428\n","Final per class accuracy on test set:  tensor([0.5000, 0.5591, 0.7122, 0.4884, 0.8280, 0.6879, 0.4800, 0.8432, 0.6516,\n","        0.4583, 0.8997, 0.7346, 0.8452, 0.7778, 0.9375], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3692371949\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3692371949\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3300171104\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3300171104\n","Epoch 0 with train loss: 2.963 train accuracy: 16.128 validation accuracy: 16.685\n","Per class train accuracy:  tensor([0.1085, 0.1913, 0.0740, 0.2179, 0.2153, 0.0677, 0.1486, 0.3899, 0.1183,\n","        0.0143, 0.1882, 0.1116, 0.2937, 0.1209, 0.5333], device='cuda:0')\n","Per class val accuracy:  tensor([0.1408, 0.2826, 0.1024, 0.2558, 0.2043, 0.0569, 0.1486, 0.3838, 0.1548,\n","        0.1667, 0.2215, 0.0958, 0.3333, 0.1149, 0.4800], device='cuda:0')\n","Epoch 9 with train loss: 1.093 train accuracy: 72.428 validation accuracy: 71.647\n","Per class train accuracy:  tensor([0.4245, 0.6173, 0.7431, 0.6070, 0.7883, 0.6555, 0.5360, 0.7563, 0.6000,\n","        0.4143, 0.8811, 0.7941, 0.8690, 0.7037, 0.9105], device='cuda:0')\n","Per class val accuracy:  tensor([0.4507, 0.5326, 0.7341, 0.4884, 0.7312, 0.6355, 0.4865, 0.7892, 0.6129,\n","        0.2917, 0.8927, 0.8108, 0.8690, 0.7122, 0.8857], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.141\n","Final per class accuracy on test set:  tensor([0.4577, 0.5484, 0.7098, 0.5465, 0.8280, 0.6378, 0.4667, 0.7730, 0.6129,\n","        0.3333, 0.8685, 0.8034, 0.8333, 0.7114, 0.9432], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3300171104\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3300171104\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2794978777\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2794978777\n","Epoch 0 with train loss: 2.775 train accuracy: 26.453 validation accuracy: 26.145\n","Per class train accuracy:  tensor([0.0896, 0.5090, 0.2187, 0.1984, 0.1603, 0.1787, 0.0946, 0.6480, 0.1011,\n","        0.0286, 0.5162, 0.2707, 0.6944, 0.1685, 0.4590], device='cuda:0')\n","Per class val accuracy:  tensor([0.0986, 0.4891, 0.1854, 0.1512, 0.1541, 0.1549, 0.0270, 0.6270, 0.0903,\n","        0.0000, 0.5606, 0.2604, 0.7143, 0.1850, 0.4971], device='cuda:0')\n","Epoch 9 with train loss: 1.095 train accuracy: 71.673 validation accuracy: 70.311\n","Per class train accuracy:  tensor([0.3892, 0.6462, 0.7228, 0.5681, 0.7847, 0.6312, 0.4730, 0.8177, 0.5591,\n","        0.3429, 0.8661, 0.7801, 0.8214, 0.7170, 0.9238], device='cuda:0')\n","Per class val accuracy:  tensor([0.4085, 0.5652, 0.7195, 0.5233, 0.7491, 0.5763, 0.4189, 0.8054, 0.4645,\n","        0.2917, 0.8789, 0.8108, 0.8571, 0.7231, 0.8800], device='cuda:0')\n","Our final test accuracy for the GNN is: 70.752\n","Final per class accuracy on test set:  tensor([0.4225, 0.5806, 0.7073, 0.5349, 0.8065, 0.5854, 0.4667, 0.8270, 0.5742,\n","        0.2500, 0.8754, 0.7617, 0.8452, 0.7065, 0.9318], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2794978777\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2794978777\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  3303475786\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  3303475786\n","Epoch 0 with train loss: 2.883 train accuracy: 21.432 validation accuracy: 20.447\n","Per class train accuracy:  tensor([0.1415, 0.0469, 0.1976, 0.1440, 0.3170, 0.2662, 0.0946, 0.1047, 0.0344,\n","        0.2714, 0.4815, 0.2330, 0.0000, 0.1217, 0.5162], device='cuda:0')\n","Per class val accuracy:  tensor([0.1479, 0.0652, 0.1732, 0.1163, 0.2688, 0.2574, 0.0405, 0.1351, 0.0387,\n","        0.1250, 0.5225, 0.2211, 0.0000, 0.1125, 0.4743], device='cuda:0')\n","Epoch 9 with train loss: 1.063 train accuracy: 73.510 validation accuracy: 71.565\n","Per class train accuracy:  tensor([0.4292, 0.6498, 0.8000, 0.5486, 0.7656, 0.6646, 0.3874, 0.7780, 0.6151,\n","        0.5571, 0.8845, 0.7974, 0.7976, 0.7328, 0.9162], device='cuda:0')\n","Per class val accuracy:  tensor([0.4789, 0.5543, 0.7659, 0.5233, 0.7384, 0.6173, 0.3649, 0.7784, 0.5161,\n","        0.2500, 0.8962, 0.7838, 0.8571, 0.7304, 0.9086], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.958\n","Final per class accuracy on test set:  tensor([0.4859, 0.5914, 0.7659, 0.5698, 0.8315, 0.6105, 0.4000, 0.7784, 0.6129,\n","        0.3750, 0.8893, 0.7690, 0.7738, 0.7452, 0.9205], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_3303475786\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_3303475786\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  2952735006\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRAINING WITH SEED:  2952735006\n","Epoch 0 with train loss: 2.938 train accuracy: 18.130 validation accuracy: 17.121\n","Per class train accuracy:  tensor([0.0731, 0.5415, 0.0634, 0.1751, 0.2667, 0.1970, 0.1622, 0.0686, 0.2624,\n","        0.0286, 0.1224, 0.0861, 0.6667, 0.1024, 0.7162], device='cuda:0')\n","Per class val accuracy:  tensor([0.0845, 0.4239, 0.0659, 0.1744, 0.2760, 0.1526, 0.1622, 0.0865, 0.2194,\n","        0.0000, 0.1176, 0.1007, 0.7381, 0.0859, 0.6914], device='cuda:0')\n","Epoch 9 with train loss: 1.133 train accuracy: 71.546 validation accuracy: 70.256\n","Per class train accuracy:  tensor([0.4080, 0.6282, 0.6976, 0.6187, 0.8134, 0.6829, 0.4144, 0.7834, 0.5871,\n","        0.5571, 0.8695, 0.7646, 0.8333, 0.6888, 0.9162], device='cuda:0')\n","Per class val accuracy:  tensor([0.4718, 0.5217, 0.7073, 0.5116, 0.7563, 0.6446, 0.3649, 0.8054, 0.4903,\n","        0.5000, 0.8685, 0.7715, 0.8690, 0.6941, 0.9029], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.440\n","Final per class accuracy on test set:  tensor([0.4507, 0.5269, 0.7073, 0.5349, 0.8602, 0.6856, 0.4133, 0.8162, 0.5871,\n","        0.3750, 0.8789, 0.7592, 0.8095, 0.7162, 0.9318], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_2952735006\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_2952735006\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n","SETTING SEEDS TO:  572297925\n","TRAINING WITH SEED:  572297925\n","Epoch 0 with train loss: 2.871 train accuracy: 21.687 validation accuracy: 21.701\n","Per class train accuracy:  tensor([0.1203, 0.0108, 0.4764, 0.0195, 0.3098, 0.1300, 0.0360, 0.5162, 0.2043,\n","        0.0571, 0.1778, 0.3831, 0.0952, 0.1016, 0.0362], device='cuda:0')\n","Per class val accuracy:  tensor([0.1549, 0.0435, 0.4902, 0.0116, 0.2760, 0.1367, 0.0676, 0.4811, 0.1742,\n","        0.0417, 0.2249, 0.3857, 0.1310, 0.0859, 0.0286], device='cuda:0')\n","Epoch 9 with train loss: 1.067 train accuracy: 73.429 validation accuracy: 72.683\n","Per class train accuracy:  tensor([0.4976, 0.6137, 0.7935, 0.4708, 0.7895, 0.6259, 0.5045, 0.7852, 0.6323,\n","        0.4714, 0.8915, 0.7621, 0.8492, 0.7388, 0.9314], device='cuda:0')\n","Per class val accuracy:  tensor([0.5845, 0.5217, 0.7707, 0.3372, 0.7527, 0.5786, 0.4324, 0.8108, 0.5935,\n","        0.4167, 0.8927, 0.7961, 0.8929, 0.7570, 0.9086], device='cuda:0')\n","Our final test accuracy for the GNN is: 72.331\n","Final per class accuracy on test set:  tensor([0.5563, 0.5591, 0.7561, 0.4302, 0.8208, 0.5991, 0.4133, 0.8216, 0.6452,\n","        0.4167, 0.8789, 0.7150, 0.8333, 0.7391, 0.9432], device='cuda:0')\n","Training stats saved successfully to file: FastRP-coauthor/FastRP-coauthor_572297925\n","Node embedding saved successfully to file: FastRP-coauthor/FastRP-coauthor_572297925\n","Final results saved successfully to file: FastRP-coauthor/FastRP-coauthor\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:240: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:259: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n","  warnings.warn(\n"]}],"source":["# Use parameters from example in https://github.com/GTmac/FastRP/blob/master/fast-random-projection-blogcatalog.ipynb\n","# Except our input matrix in an adjacency matrix and since we are not tuning alpha we just set this to None\n","input_matrix = 'adj'\n","alpha = -0.67\n","conf = {\n","        'projection_method': 'sparse',\n","        'input_matrix': input_matrix,\n","        'weights': [0.0, 0.0, 1.0, 6.67],\n","        'normalization': True,\n","        'dim': HIDDEN_DIM,\n","        'alpha': alpha,\n","        'C': 0.1\n","    }\n","\n","num_nodes = node_features.shape[0]\n","\n","# Convert adjacency matrix to scipy matrix\n","adj_matrix = to_scipy_sparse_matrix(edge_indices)\n","# Whether we are using the adjacency or transition matrix\n","if input_matrix == 'trans':\n","  # Create the degree matrix for the graph\n","  degrees = degree(edge_indices[0])\n","  diagonal_degree = sp.sparse.spdiags(degrees, 0, degrees.size()[0], degrees.size()[0])\n","  # Create the transition matrix for the graph = D-1(A)\n","  transition_matrix = scipy.sparse.linalg.inv(diagonal_degree).multiply(adj_matrix)\n","  print(\"Using transition matrix\")\n","else:\n","  transition_matrix = adj_matrix\n","  print(\"Using adjacency matrix\")\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","for seed in seeds:\n","  set_seeds(seed)\n","  \n","  embeddings = fastrp_wrapper(transition_matrix, conf, seed)\n","  # convert to tensor \n","  embeddings = torch.from_numpy(embeddings)\n","\n","  # Create the model\n","  model = FastRPEmbeddingWrapper(HIDDEN_DIM, num_classes)\n","  model = model.to(device)\n","\n","  # Run training loop\n","  print(\"TRAINING WITH SEED: \", str(seed))\n","  train_stats_cora = train_eval_loop_embedding_classifier(model, embeddings, train_y, train_mask, \n","                                             valid_y, valid_mask, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, device, is_cora)\n","  # Print out graphs if not using GPU\n","  if device == torch.device('cpu'):\n","    plot_stats(train_stats_cora, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"X5HLu-NNuJ88"},"source":["# Node2Vec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LtiwsyJPxpt"},"outputs":[],"source":["from torch_geometric.nn import Node2Vec\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","data_name = \"Arxiv\"\n","\n","# Get masks and training labels for each split\n","if data_name == \"Cora\":\n","  num_classes = 7\n","  data = cora_data\n","  # Get the edge indices and node features for our model\n","  edge_indices = data.edge_index\n","  node_features = data.x\n","  # CHANGE: To name of model being tested\n","  filename =  \"Node2Vec_Cora\"\n","  train_mask = data.train_mask\n","  train_y = data.y[train_mask]\n","  valid_mask = data.val_mask\n","  valid_y = data.y[valid_mask]\n","  test_mask = data.test_mask\n","  test_y = data.y[test_mask]\n","elif data_name == \"Coauthor\":\n","  data = cs_data\n","  # Get the edge indices and node features for our model\n","  edge_indices = data.edge_index\n","  node_features = data.x\n","  num_classes = 15\n","  filename =  \"Node2Vec_Coauthor_CS\"\n","  train_mask = train_mask_cs\n","  train_y = data.y[train_mask]\n","  valid_mask = val_mask_cs\n","  valid_y = data.y[valid_mask]\n","  test_mask = test_mask_cs\n","  test_y = data.y[test_mask]\n","elif data_name == \"Arxiv\":\n","  data = arxiv_data\n","  edge_indices = arxiv_data.edge_index\n","  node_features = arxiv_data.x\n","  neighbour_dataset = arxiv_data\n","\n","  # Get masks and training labels for each split\n","  train_mask = train_idx\n","  train_y = arxiv_data.y[train_mask]\n","  valid_mask = valid_idx\n","  valid_y = arxiv_data.y[valid_mask]\n","  test_mask = test_idx\n","  test_y = arxiv_data.y[test_mask]\n","\n","  num_classes = 40\n","  is_cora = False\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# use 30 seeds which have been randomly generated using seed_list = [np.random.randint(4294967296 - 1) for i in range(30)]\n","seeds = [4193977854, 1863727779, 170173784, 2342954646, 116846604, 2105922959, 2739899259, 1024258131, 806299656, 880019963, 1818027900, 2135956485, 3710910636, 1517964140, 4083009686, 2455059856, 400225693, 89475662, 361232447, 3647665043, 1221215631, 2036056847, 1860537279, 516507873, 3692371949, 3300171104, 2794978777, 3303475786, 2952735006, 572297925]\n","\n","# create folder for saving all model info into if it does not exist already\n","if not os.path.exists(file_path+filename+\"/\"):\n","  os.mkdir(file_path+filename+\"/\")\n","\n","filename = filename + \"/\" + filename\n","\n","for seed in seeds:\n","  set_seeds(seed)\n","  # Create the model\n","  #model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n","  model = Node2VecWrapper(data.edge_index.to(device), embedding_size=128, walk_length=20,\n","                     context_size=10, walks_per_node=10,\n","                     num_negative_samples=1, p=1, q=1, sparse=True, out_channels=num_classes).to(device)\n","  loader = model.loader(batch_size=128, shuffle=True,\n","                      num_workers=0)\n","  optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n","\n","  def train():\n","    model.train()\n","    total_loss = 0\n","    for pos_rw, neg_rw in loader:\n","      optimizer.zero_grad()\n","      loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n","      loss.backward()\n","      optimizer.step()\n","      total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","  @torch.no_grad()\n","  def find_model_acc(model, train_z, train_y, test_z, test_y, solver: str = 'lbfgs', multi_class: str = 'auto', *args, **kwargs):\n","    pred_y = model.test(train_z, train_y, test_z, test_y, solver=solver, multi_class=multi_class, *args, **kwargs)\n","    acc = accuracy_score(test_y.detach().cpu().numpy(), pred_y)\n","    matrix = confusion_matrix(test_y.detach().cpu().numpy(), pred_y)\n","    per_class_acc = matrix.diagonal()/matrix.sum(axis=1)\n","    #print(m)\n","    #report = classification_report(test_y.detach().cpu().numpy(), pred_y)\n","    #print(report)\n","    return acc, per_class_acc\n","\n","  @torch.no_grad()\n","  def test():\n","    model.eval()\n","    \n","    pred, z = model()\n","    acc_train, per_class_train_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[train_mask], data.y[train_mask])\n","  \n","    acc_val, per_class_val_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[valid_mask], data.y[valid_mask])\n","\n","    acc_test, per_class_test_acc = find_model_acc(model, z[train_mask], data.y[train_mask],\n","                      z[test_mask], data.y[test_mask])\n","\n","    return z, acc_train, per_class_train_acc, acc_val, per_class_val_acc, acc_test, per_class_test_acc\n","\n","  training_stats = None\n","  for epoch in range(0, 10):\n","    loss = train()\n","    node_embeddings, acc_train, per_class_train_acc, acc_val, per_class_val_acc, acc_test, per_class_test_acc = test()\n","    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Acc_train: {acc_train:.4f}, Acc_val: {acc_val:.4f}, Acc_test: {acc_test:.4f}')\n","    print(f'Per class train accuracy: ', per_class_train_acc)\n","    epoch_stats = {'train_acc': acc_train, 'val_acc': acc_val, 'test_acc': acc_test, 'epoch':epoch}\n","    training_stats = update_stats(training_stats, epoch_stats)\n","  \n","  # Save training stats if on final iteration of the run\n","  save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n","  # Save final results\n","  final_results_list = [seed, acc_test, per_class_test_acc, per_class_train_acc, per_class_val_acc]\n","  save_final_results(final_results_list, filename)\n","  # Save final model weights incase we want to do further inference later\n","  torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n","\n","  plot_stats(training_stats, name=filename)"]},{"cell_type":"markdown","metadata":{"id":"NGtX2ycNQa-H"},"source":["# Similarity tests"]},{"cell_type":"markdown","metadata":{"id":"-eesbQaUQfd4"},"source":["https://github.com/SGDE2020/embedding_stability/blob/master/similarity_tests/similarity_tests.py"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["NGtX2ycNQa-H"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}