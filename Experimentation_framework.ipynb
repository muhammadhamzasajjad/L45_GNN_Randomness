{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qU87TNON39IV",
        "NGtX2ycNQa-H"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Preliminaries:** Install and import modules"
      ],
      "metadata": {
        "id": "qU87TNON39IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] install\n",
        "!pip install networkx\n",
        "!pip install mycolorpy\n",
        "!pip install colorama\n",
        "\n",
        "\n",
        "import torch\n",
        "!pip install torch-geometric torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ],
      "metadata": {
        "id": "Mpygj8TTZ-ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8b7a4d-26e3-49a4-c539-1709649edd13"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mycolorpy in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mycolorpy) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mycolorpy) (3.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mycolorpy) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mycolorpy) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mycolorpy) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mycolorpy) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mycolorpy) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mycolorpy) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mycolorpy) (23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->mycolorpy) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (0.4.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.8/dist-packages (2.1.0+pt113cu116)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.8/dist-packages (0.6.16+pt113cu116)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.8/dist-packages (1.6.0+pt113cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.25.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (4.0.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Import modules\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import math\n",
        "import itertools\n",
        "import scipy as sp\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid, ZINC, GNNBenchmarkDataset\n",
        "from torch_scatter import scatter_mean, scatter_max, scatter_sum\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from torch.nn import Embedding\n",
        "\n",
        "import pdb\n",
        "from datetime import datetime\n",
        "\n",
        "#for nice visualisations\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mycolorpy import colorlist as mcp\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "import colorama\n",
        "\n",
        "import scipy.linalg\n",
        "from scipy.linalg import block_diag"
      ],
      "metadata": {
        "id": "ZLrrWpkk6xv-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####### PLOTS #######\n",
        "\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "    \n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))"
      ],
      "metadata": {
        "id": "VLrKgQEuwgtb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cora dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "82mrcZX0A3QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cora_dataset = Planetoid(\"/tmp/cora\", name=\"cora\", split=\"full\")\n",
        "cora_data = cora_dataset[0]"
      ],
      "metadata": {
        "id": "bBTnJEZWA-Iq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training class sizes\")\n",
        "print(torch.bincount(cora_dataset[0].y[cora_dataset[0].train_mask]))\n",
        "print(\"Validation class sizes\")\n",
        "print(torch.bincount(cora_dataset[0].y[cora_dataset[0].val_mask]))\n",
        "print(\"Test class sizes\")\n",
        "print(torch.bincount(cora_dataset[0].y[cora_dataset[0].test_mask]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuZwDeBwJPZg",
        "outputId": "e94ba5d6-461f-40b3-cd6f-782021cfcc4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training class sizes\n",
            "tensor([160,  90, 196, 341, 196, 138,  87])\n",
            "Validation class sizes\n",
            "tensor([ 61,  36,  78, 158,  81,  57,  29])\n",
            "Test class sizes\n",
            "tensor([130,  91, 144, 319, 149, 103,  64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data saving / loading"
      ],
      "metadata": {
        "id": "KL8gKs07J9JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use google drive for saving and loading information\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/L45_project/'\n",
        "# create folder if it does not exist already\n",
        "if not os.path.exists(file_path):\n",
        "  os.mkdir(file_path) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z80lU1V-Isky",
        "outputId": "b8bde187-d6c0-4610-d2ef-cd420556cbb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_training_info(training_stats: dict, node_embedding: torch.Tensor, filename: str):\n",
        "  # write training data info to a file\n",
        "  with open(file_path + filename + \".pkl\", 'wb') as fp:\n",
        "    pickle.dump(training_stats, fp)\n",
        "    print('Training stats saved successfully to file: ' + filename)\n",
        "  # write node embedding to a file\n",
        "  torch.save(node_embedding, file_path + filename + \".pt\")\n",
        "  print('Node embedding saved successfully to file: ' + filename)\n",
        "\n",
        "\n",
        "def load_training_info(filename: str):\n",
        "  # load training stats dictionary \n",
        "  with open(file_path + filename + \".pkl\", 'rb') as fp:\n",
        "    train_stats = pickle.load(fp)\n",
        "    print('Training stats successfully loaded from file: ' + filename)\n",
        "  # load node embedding\n",
        "  node_embedding = torch.load(file_path + filename + \".pt\")\n",
        "  print('Node embedding successfully loaded from file: ' + filename)\n",
        "  return train_stats, node_embedding\n",
        "\n",
        "# Final results is a list [seed, test result, [test per class accuracy], [training per class accuracy], [val per class accuracy]]\n",
        "def save_final_results(final_results: List, filename: str):\n",
        "  # write training data info to a file\n",
        "  with open(file_path + filename + \".pkl\", 'ab') as fp:\n",
        "    pickle.dump(final_results, fp)\n",
        "    print('Final results saved successfully to file: ' + filename)\n",
        "\n",
        "# Returns an iterator which contains all the results from our various runs\n",
        "def load_final_results(filename: str):\n",
        "  with open(file_path + filename + \".pkl\", 'rb') as fp:\n",
        "    print('Final results found in file: ' + filename)\n",
        "    while True:\n",
        "      try:\n",
        "        # This notation creates a generator, which we can then iterate through\n",
        "        yield pickle.load(fp)\n",
        "      except EOFError:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "VhUfVQAZTWHu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dict = {'c':[1,2,3], 'b':[4,5,6]}\n",
        "test_tensor = torch.tensor([[1., -1.], [1., -1.]])\n",
        "save_training_info(test_dict, test_tensor, \"testing\")\n",
        "recovered_val1, recovered_val2 = load_training_info(\"testing\")\n",
        "print(recovered_val1, recovered_val2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZECGPy9JTZrT",
        "outputId": "bbe224e2-0e7a-4155-8669-f343f859ad8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training stats saved successfully to file: testing\n",
            "Node embedding saved successfully to file: testing\n",
            "Training stats successfully loaded from file: testing\n",
            "Node embedding successfully loaded from file: testing\n",
            "{'c': [1, 2, 3], 'b': [4, 5, 6]} tensor([[ 1., -1.],\n",
            "        [ 1., -1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Wrappers"
      ],
      "metadata": {
        "id": "yVyPiw_TBMj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCN\n",
        "from torch_geometric.typing import Adj\n",
        "\n",
        "class GCNModelWrapper(GCN):\n",
        "\n",
        "  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int):\n",
        "    # use one less layer as our final graph layer can downsize for us\n",
        "    # super().__init__(in_channels, hidden_channels, num_layers-1)\n",
        "    super().__init__(in_channels, hidden_channels, num_layers)\n",
        "    self.out_channels = out_channels\n",
        "    # self.final_layer = self.init_conv(in_channels, out_channels)\n",
        "    self.final_layer = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, edge_index: Adj):\n",
        "    x = super().forward(x, edge_index)\n",
        "    # output = self.final_layer(x, edge_index)\n",
        "    output = self.final_layer(x)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "m_yBLcOs6V7v"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GAT\n",
        "\n",
        "class GATModelWrapper(GAT):\n",
        "\n",
        "  def __init__(self, in_channels: int, hidden_channels: int, num_layers: int, out_channels: int, v2: bool):\n",
        "    # Create the model to extract the node embeddings then pass these through a linear layer for classification\n",
        "    super().__init__(in_channels, hidden_channels, num_layers, v2=v2)\n",
        "    self.out_channels = out_channels\n",
        "    self.final_layer = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, edge_index: Adj):\n",
        "    x = super().forward(x, edge_index)\n",
        "    output = self.final_layer(x)\n",
        "    return output, x"
      ],
      "metadata": {
        "id": "M9xNcjhyBRmX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training code\n",
        "\n"
      ],
      "metadata": {
        "id": "5mLwBJNywK-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Hyperparameters GNN\n",
        "\n",
        "NUM_EPOCHS =  10 #@param {type:\"integer\"}\n",
        "LR         = 0.01 #@param {type:\"number\"}\n",
        "\n",
        "#you can add more here if you need"
      ],
      "metadata": {
        "id": "-BLISzysQkdA",
        "cellView": "form"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code taken from L45 practical notebook\n",
        "def train_gnn_cora(X, edge_indices, y, mask, model, optimiser):\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "    #y_out, _ = model(X, edge_indices)\n",
        "    y_out, _ = model(X)\n",
        "    y_hat = y_out[mask]\n",
        "    loss = F.cross_entropy(y_hat, y)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "    return loss.data\n",
        "\n",
        "def evaluate_gnn_cora(X, edge_indices, y, mask, model, num_classes):\n",
        "    model.eval()\n",
        "    y_out, node_embeddings = model(X, edge_indices)\n",
        "    y_hat = y_out[mask]\n",
        "    y_hat = y_hat.data.max(1)[1]\n",
        "    num_correct = y_hat.eq(y.data).sum()\n",
        "    num_total = len(y)\n",
        "    accuracy = 100.0 * (num_correct/num_total)\n",
        "\n",
        "    # calculate per class accuracy\n",
        "    values, counts = torch.unique(y_hat[y_hat == y.data], return_counts=True)\n",
        "    per_class_counts = torch.zeros(num_classes)\n",
        "    # allocate the number of counts per class\n",
        "    for i, x in enumerate(values):\n",
        "      per_class_counts[x] = counts[i]\n",
        "    # find total number of data points per class in the split\n",
        "    total_per_class = torch.bincount(y.data)\n",
        "    per_class_accuracy = torch.div(per_class_counts, total_per_class)\n",
        "\n",
        "    return accuracy, per_class_accuracy, node_embeddings\n",
        "    \n",
        "# Training loop\n",
        "def train_eval_loop_gnn_cora(model, edge_indices, train_x, train_y, train_mask, valid_x, valid_y, valid_mask, \n",
        "                             test_x, test_y, test_mask, num_classes, seed, filename):\n",
        "    optimiser = optim.Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_loss = train_gnn_cora(train_x, edge_indices, train_y, train_mask, model, optimiser)\n",
        "        train_acc, train_class_acc, _ = evaluate_gnn_cora(train_x, edge_indices, train_y, train_mask, model, num_classes)\n",
        "        valid_acc, valid_class_acc, _ = evaluate_gnn_cora(valid_x, edge_indices, valid_y, valid_mask, model, num_classes)\n",
        "        if epoch % 10 == 0 or epoch == (NUM_EPOCHS-1):\n",
        "            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n",
        "            print(\"Per class train accuracy: \", train_class_acc)\n",
        "            print(\"Per class val accuracy: \", valid_class_acc)\n",
        "        # store the loss and the accuracy for the final plot\n",
        "        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "\n",
        "    # Lets look at our final test performance\n",
        "    # Only need to get the node embeddings once, take from the training evaluation call\n",
        "    test_acc, test_class_acc, node_embeddings = evaluate_gnn_cora(test_x, edge_indices, test_y, test_mask, model, num_classes)\n",
        "    print(f\"Our final test accuracy for the GNN is: {test_acc:.3f}\")\n",
        "    print(\"Final per class accuracy on test set: \", test_class_acc)\n",
        "\n",
        "    # Save training stats if on final iteration of the run\n",
        "    save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n",
        "    # Save final results\n",
        "    final_results_list = [seed, test_acc, test_class_acc, train_class_acc, valid_class_acc]\n",
        "    save_final_results(final_results_list, filename)\n",
        "    # Save final model weights incase we want to do further inference later\n",
        "    torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n",
        "    return training_stats"
      ],
      "metadata": {
        "id": "AFTSH-Vuv4gk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed):\n",
        "  print(\"SETTING SEEDS TO: \", str(seed))\n",
        "  # seed the potential sources of randomness\n",
        "  torch.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)"
      ],
      "metadata": {
        "id": "A_O5m_YIaKY-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the edge indices and node features for our model\n",
        "edge_indices = cora_data.edge_index\n",
        "node_features = cora_data.x\n",
        "\n",
        "# Get masks and training labels for each split\n",
        "train_mask = cora_data.train_mask\n",
        "train_y = cora_data.y[train_mask]\n",
        "valid_mask = cora_data.val_mask\n",
        "valid_y = cora_data.y[valid_mask]\n",
        "test_mask = cora_data.test_mask\n",
        "test_y = cora_data.y[test_mask]\n",
        "\n",
        "\n",
        "num_classes = 7\n",
        "# CHANGE: To name of model being tested\n",
        "filename = \"GATV2\"\n",
        "# use 30 seeds which have been randomly generated using seed_list = [np.random.randint(4294967296 - 1) for i in range(30)]\n",
        "seeds = [4193977854, 1863727779, 170173784, 2342954646, 116846604, 2105922959, 2739899259, 1024258131, 806299656, 880019963, 1818027900, 2135956485, 3710910636, 1517964140, 4083009686, 2455059856, 400225693, 89475662, 361232447, 3647665043, 1221215631, 2036056847, 1860537279, 516507873, 3692371949, 3300171104, 2794978777, 3303475786, 2952735006, 572297925]\n",
        "\n",
        "# create folder for saving all model info into if it does not exist already\n",
        "if not os.path.exists(file_path+filename+\"/\"):\n",
        "  os.mkdir(file_path+filename+\"/\")\n",
        "\n",
        "for seed in seeds:\n",
        "  set_seeds(seed)\n",
        "  # Create the model\n",
        "  model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n",
        "\n",
        "  # Run training loop\n",
        "  print(\"TRAINING WITH SEED: \", str(seed))\n",
        "  train_stats_cora = train_eval_loop_gnn_cora(model, edge_indices, node_features, train_y, train_mask, \n",
        "                                            node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename)\n",
        "  plot_stats(train_stats_cora, name=filename+\"_Cora\")"
      ],
      "metadata": {
        "id": "Rl6KVverQy7C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7392ac02-08e5-45ea-8e36-77a2d56793d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SETTING SEEDS TO:  1\n",
            "TRAINING WITH SEED:  1\n",
            "Epoch 0 with train loss: 1.951 train accuracy: 44.536 validation accuracy: 43.200\n",
            "Per class train accuracy:  tensor([0.0812, 0.0000, 0.5714, 1.0000, 0.3265, 0.0580, 0.0000])\n",
            "Per class val accuracy:  tensor([0.0328, 0.0000, 0.4615, 1.0000, 0.2346, 0.0175, 0.0000])\n",
            "Epoch 9 with train loss: 0.024 train accuracy: 99.255 validation accuracy: 82.200\n",
            "Per class train accuracy:  tensor([0.9875, 1.0000, 1.0000, 0.9912, 0.9898, 0.9928, 0.9885])\n",
            "Per class val accuracy:  tensor([0.7213, 0.7500, 0.9103, 0.8291, 0.8642, 0.8246, 0.7241])\n",
            "Our final test accuracy for the GNN is: 83.200\n",
            "Final per class accuracy on test set:  tensor([0.7769, 0.7473, 0.9028, 0.8715, 0.8389, 0.7961, 0.7500])\n",
            "Training stats saved successfully to file: GATV2/GATV2_1\n",
            "Node embedding saved successfully to file: GATV2/GATV2_1\n",
            "Final results saved successfully to file: GATV2/GATV2\n",
            "SETTING SEEDS TO:  2\n",
            "TRAINING WITH SEED:  2\n",
            "Epoch 0 with train loss: 1.950 train accuracy: 45.116 validation accuracy: 41.400\n",
            "Per class train accuracy:  tensor([0.0750, 0.0000, 0.5459, 1.0000, 0.3724, 0.0870, 0.0000])\n",
            "Per class val accuracy:  tensor([0.0000, 0.0000, 0.3846, 1.0000, 0.2346, 0.0000, 0.0000])\n",
            "Epoch 9 with train loss: 0.019 train accuracy: 99.669 validation accuracy: 83.600\n",
            "Per class train accuracy:  tensor([1.0000, 1.0000, 1.0000, 0.9971, 0.9898, 1.0000, 0.9885])\n",
            "Per class val accuracy:  tensor([0.7213, 0.8056, 0.9231, 0.8481, 0.8519, 0.8596, 0.7241])\n",
            "Our final test accuracy for the GNN is: 82.200\n",
            "Final per class accuracy on test set:  tensor([0.7615, 0.6813, 0.9028, 0.8715, 0.8188, 0.7767, 0.7969])\n",
            "Training stats saved successfully to file: GATV2/GATV2_2\n",
            "Node embedding saved successfully to file: GATV2/GATV2_2\n",
            "Final results saved successfully to file: GATV2/GATV2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING LOADING"
      ],
      "metadata": {
        "id": "u4GMM4D5dLoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_results = load_final_results(filename)\n",
        "for r in final_results:\n",
        "  print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35RkMAgK8EHw",
        "outputId": "0ef2d1d1-5e0c-4057-a43f-49d0216cd6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final results found in file: GATV2\n",
            "[1, tensor(83.1000), tensor([0.7615, 0.7473, 0.8750, 0.8809, 0.8389, 0.8058, 0.7656]), tensor([0.9875, 0.9889, 1.0000, 0.9912, 0.9898, 0.9928, 0.9770]), tensor([0.7213, 0.7778, 0.8974, 0.8354, 0.8642, 0.8246, 0.7241])]\n",
            "[2, tensor(82.), tensor([0.7615, 0.6593, 0.9028, 0.8777, 0.8188, 0.7767, 0.7656]), tensor([1.0000, 0.9889, 1.0000, 0.9883, 0.9898, 1.0000, 0.9885]), tensor([0.7213, 0.7778, 0.9231, 0.8608, 0.8519, 0.8421, 0.7586])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_stats_1, embedding = load_training_info(filename+\"_1\")\n",
        "plot_stats(training_stats_1, name=\"Testing\")\n",
        "print(embedding)\n",
        "print(node_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "bZ3GQQld9b97",
        "outputId": "36c49aee-27e6-42ed-81ff-d1d40ec0600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training stats successfully loaded from file: GATV2_1\n",
            "Node embedding successfully loaded from file: GATV2_1\n",
            "tensor([[ 0.3694, -0.3698,  0.2766,  ...,  0.3216,  0.2274,  0.0202],\n",
            "        [ 0.3314, -0.0802, -0.3007,  ...,  0.7356,  0.0207,  0.6433],\n",
            "        [ 0.3232, -0.0492, -0.2139,  ...,  0.7058,  0.0322,  0.6001],\n",
            "        ...,\n",
            "        [ 0.1757, -0.2687,  0.1217,  ...,  0.1831,  0.5841, -0.2099],\n",
            "        [ 0.5839, -0.1735,  0.3632,  ...,  0.1244,  0.3284,  0.0446],\n",
            "        [ 0.5833, -0.1772,  0.3626,  ...,  0.1264,  0.3263,  0.0459]],\n",
            "       requires_grad=True)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading stored model weights\n",
        "model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n",
        "model.load_state_dict(torch.load(file_path+filename+\"/\"+\"GATV2_1_model.pt\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1nR7AjndQJn",
        "outputId": "9eccfaf3-7828-431a-b5c6-79d6bc6847e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GATModelWrapper(1433, 7, num_layers=1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Plot graph with average training stats\n",
        "- Save node embeddings for each run\n",
        "- Save training stats for each run\n",
        "- Save test accuracy for each run\n"
      ],
      "metadata": {
        "id": "GubPzc9IQyP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code taken from L45 practical notebook\n",
        "def train_gnn_cora(X, edge_indices, y, mask, model, optimiser, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for pos_rw, neg_rw in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def evaluate_gnn_cora(X, edge_indices, y, mask, model, num_classes, loader):\n",
        "    model.eval()\n",
        "    z = model()\n",
        "    acc = model.test(z[cora_data.train_mask], cora_data.y[cora_data.train_mask],\n",
        "                      z[cora_data.val_mask], cora_data.y[cora_data.val_mask],\n",
        "                      max_iter=150)\n",
        "    #y_out = z[cora_data.train_mask]\n",
        "    y_hat = z[cora_data.val_mask].to(device)\n",
        "    y = cora_data.y[cora_data.val_mask].to(device)\n",
        "    \n",
        "    #model.eval()\n",
        "    #y_out, node_embeddings = model(X, edge_indices)\n",
        "    #y_hat = y_out[mask]\n",
        "    y_hat = y_hat.data.max(1)[1]\n",
        "    num_correct = y_hat.eq(y.data).sum()\n",
        "    num_total = len(y)\n",
        "    accuracy = 100.0 * (num_correct/num_total)\n",
        "\n",
        "    # calculate per class accuracy\n",
        "    values, counts = torch.unique(y_hat[y_hat == y.data], return_counts=True)\n",
        "    per_class_counts = torch.zeros(num_classes)\n",
        "    # allocate the number of counts per class\n",
        "    for i, x in enumerate(values):\n",
        "      per_class_counts[x] = counts[i]\n",
        "    per_class_counts = per_class_counts.to(device)\n",
        "    # find total number of data points per class in the split\n",
        "    total_per_class = torch.bincount(y.data).to(device)\n",
        "    per_class_accuracy = torch.div(per_class_counts, total_per_class)\n",
        "\n",
        "    return accuracy, per_class_accuracy\n",
        "    \n",
        "# Training loop\n",
        "def train_eval_loop_gnn_cora(model, edge_indices, train_x, train_y, train_mask, valid_x, valid_y, valid_mask, \n",
        "                             test_x, test_y, test_mask, num_classes, seed, filename, loader):\n",
        "    optimiser = optim.Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_loss = train_gnn_cora(train_x, edge_indices, train_y, train_mask, model, optimiser, loader)\n",
        "        train_acc, train_class_acc = evaluate_gnn_cora(train_x, edge_indices, train_y, train_mask, model, num_classes, loader)\n",
        "        valid_acc, valid_class_acc = evaluate_gnn_cora(valid_x, edge_indices, valid_y, valid_mask, model, num_classes, loader)\n",
        "        if epoch % 10 == 0 or epoch == (NUM_EPOCHS-1):\n",
        "            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n",
        "            #print(\"Per class train accuracy: \", train_class_acc)\n",
        "            #print(\"Per class val accuracy: \", valid_class_acc)\n",
        "        # store the loss and the accuracy for the final plot\n",
        "        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "\n",
        "    # Lets look at our final test performance\n",
        "    # Only need to get the node embeddings once, take from the training evaluation call\n",
        "    test_acc, test_class_acc = evaluate_gnn_cora(test_x, edge_indices, test_y, test_mask, model, num_classes, loader)\n",
        "    print(f\"Our final test accuracy for the GNN is: {test_acc:.3f}\")\n",
        "    print(\"Final per class accuracy on test set: \", test_class_acc)\n",
        "\n",
        "    # Save training stats if on final iteration of the run\n",
        "    #save_training_info(training_stats, node_embeddings, filename+\"_\"+str(seed))\n",
        "    # Save final results\n",
        "    final_results_list = [seed, test_acc, test_class_acc, train_class_acc, valid_class_acc]\n",
        "    save_final_results(final_results_list, filename)\n",
        "    # Save final model weights incase we want to do further inference later\n",
        "    torch.save(model.state_dict(), file_path+filename+\"_\" + str(seed) + \"_model.pt\")\n",
        "    return training_stats"
      ],
      "metadata": {
        "id": "lp0VtUUmCtco"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import Node2Vec\n",
        "\n",
        "# Get the edge indices and node features for our model\n",
        "edge_indices = cora_data.edge_index\n",
        "node_features = cora_data.x\n",
        "\n",
        "# Get masks and training labels for each split\n",
        "train_mask = cora_data.train_mask\n",
        "train_y = cora_data.y[train_mask]\n",
        "valid_mask = cora_data.val_mask\n",
        "valid_y = cora_data.y[valid_mask]\n",
        "test_mask = cora_data.test_mask\n",
        "test_y = cora_data.y[test_mask]\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "num_classes = 7\n",
        "# CHANGE: To name of model being tested\n",
        "filename = \"Node2Vec\"\n",
        "# use 30 seeds which have been randomly generated using seed_list = [np.random.randint(4294967296 - 1) for i in range(30)]\n",
        "seeds = [4193977854, 1863727779, 170173784, 2342954646, 116846604, 2105922959, 2739899259, 1024258131, 806299656, 880019963, 1818027900, 2135956485, 3710910636, 1517964140, 4083009686, 2455059856, 400225693, 89475662, 361232447, 3647665043, 1221215631, 2036056847, 1860537279, 516507873, 3692371949, 3300171104, 2794978777, 3303475786, 2952735006, 572297925]\n",
        "\n",
        "# create folder for saving all model info into if it does not exist already\n",
        "if not os.path.exists(file_path+filename+\"/\"):\n",
        "  os.mkdir(file_path+filename+\"/\")\n",
        "\n",
        "for seed in seeds:\n",
        "  set_seeds(seed)\n",
        "  # Create the model\n",
        "  #model = GATModelWrapper(in_channels = node_features.shape[-1], hidden_channels = node_features.shape[-1], num_layers=1, out_channels=num_classes, v2=True)\n",
        "  model = Node2Vec(cora_data.edge_index.to(device), embedding_dim=128, walk_length=20,\n",
        "                     context_size=10, walks_per_node=10,\n",
        "                     num_negative_samples=1, p=1, q=1, sparse=True).to(device)\n",
        "  loader = model.loader(batch_size=128, shuffle=True,\n",
        "                          num_workers=0)\n",
        "  optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
        "\n",
        "  #train_stats_cora = train_eval_loop_gnn_cora(model, edge_indices, node_features, train_y, train_mask, \n",
        "                                            #node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename, loader)\n",
        "\n",
        "  def train():\n",
        "      model.train()\n",
        "      total_loss = 0\n",
        "      for pos_rw, neg_rw in loader:\n",
        "          optimizer.zero_grad()\n",
        "          loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "          #print(loss.data)\n",
        "      #epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "      return total_loss / len(loader)\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def test():\n",
        "    model.eval()\n",
        "    z = model()\n",
        "    acc_train = model.test(z[cora_data.train_mask], cora_data.y[cora_data.train_mask],\n",
        "                      z[cora_data.train_mask], cora_data.y[cora_data.train_mask],\n",
        "                      max_iter=150)\n",
        "    acc_val = model.test(z[cora_data.train_mask], cora_data.y[cora_data.train_mask],\n",
        "                      z[cora_data.val_mask], cora_data.y[cora_data.val_mask],\n",
        "                      max_iter=150)\n",
        "    acc_test = model.test(z[cora_data.train_mask], cora_data.y[cora_data.train_mask],\n",
        "                      z[cora_data.test_mask], cora_data.y[cora_data.test_mask],\n",
        "                      max_iter=150)\n",
        "    y_train = cora_data.y[cora_data.train_mask].to(device)\n",
        "    y_hat_train = z[cora_data.train_mask].to(device)\n",
        "    y_val = cora_data.y[cora_data.val_mask].to(device)\n",
        "    y_hat_val = z[cora_data.val_mask].to(device)\n",
        "    y_test = cora_data.y[cora_data.test_mask].to(device)\n",
        "    y_hat_test = z[cora_data.test_mask].to(device)\n",
        "\n",
        "    loss_train = F.cross_entropy(y_hat_train, y_train)\n",
        "    loss_val = F.cross_entropy(y_hat_val, y_val)\n",
        "    loss_test = F.cross_entropy(y_hat_test, y_test)\n",
        "\n",
        "    return acc_train, acc_val, acc_test, loss_train, loss_val, loss_test\n",
        "\n",
        "  for epoch in range(1, 40):\n",
        "    loss = train()\n",
        "    acc_train, acc_val, acc_test, loss_train, loss_val, loss_test = test()\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Acc_train: {acc_train:.4f}, Acc_val: {acc_val:.4f}, Acc_test: {acc_test:.4f}')\n",
        "\n",
        "  # Run training loop\n",
        "  #print(\"TRAINING WITH SEED: \", str(seed))\n",
        "  #train_stats_cora = train_eval_loop_gnn_cora(model, edge_indices, node_features, train_y, train_mask, \n",
        "  #                                          node_features, valid_y, valid_mask, node_features, test_y, test_mask, num_classes, seed, filename+\"/\"+filename)\n",
        "  #plot_stats(train_stats_cora, name=filename+\"_Cora\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DAdzhL_4AB9j",
        "outputId": "c3d40df2-2e97-48c7-dbed-53d80a975bbf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SETTING SEEDS TO:  4193977854\n",
            "Epoch: 01, Loss: 8.1413, Acc_train: 0.4462, Acc_val: 0.2460, Acc_test: 0.2290\n",
            "Epoch: 02, Loss: 6.0991, Acc_train: 0.5000, Acc_val: 0.2900, Acc_test: 0.2680\n",
            "Epoch: 03, Loss: 4.9834, Acc_train: 0.5472, Acc_val: 0.3300, Acc_test: 0.3110\n",
            "Epoch: 04, Loss: 4.1355, Acc_train: 0.6051, Acc_val: 0.3860, Acc_test: 0.3730\n",
            "Epoch: 05, Loss: 3.4939, Acc_train: 0.6416, Acc_val: 0.4120, Acc_test: 0.4220\n",
            "Epoch: 06, Loss: 2.9725, Acc_train: 0.6796, Acc_val: 0.4760, Acc_test: 0.4520\n",
            "Epoch: 07, Loss: 2.5564, Acc_train: 0.7219, Acc_val: 0.5080, Acc_test: 0.4960\n",
            "Epoch: 08, Loss: 2.2324, Acc_train: 0.7575, Acc_val: 0.5200, Acc_test: 0.5180\n",
            "Epoch: 09, Loss: 1.9625, Acc_train: 0.7765, Acc_val: 0.5300, Acc_test: 0.5390\n",
            "Epoch: 10, Loss: 1.7468, Acc_train: 0.7997, Acc_val: 0.5480, Acc_test: 0.5650\n",
            "Epoch: 11, Loss: 1.5779, Acc_train: 0.8146, Acc_val: 0.5700, Acc_test: 0.5790\n",
            "Epoch: 12, Loss: 1.4357, Acc_train: 0.8237, Acc_val: 0.5820, Acc_test: 0.6120\n",
            "Epoch: 13, Loss: 1.3248, Acc_train: 0.8369, Acc_val: 0.6080, Acc_test: 0.6160\n",
            "Epoch: 14, Loss: 1.2381, Acc_train: 0.8427, Acc_val: 0.6100, Acc_test: 0.6410\n",
            "Epoch: 15, Loss: 1.1650, Acc_train: 0.8469, Acc_val: 0.6220, Acc_test: 0.6520\n",
            "Epoch: 16, Loss: 1.1079, Acc_train: 0.8576, Acc_val: 0.6420, Acc_test: 0.6650\n",
            "Epoch: 17, Loss: 1.0602, Acc_train: 0.8642, Acc_val: 0.6640, Acc_test: 0.6760\n",
            "Epoch: 18, Loss: 1.0276, Acc_train: 0.8709, Acc_val: 0.6660, Acc_test: 0.6920\n",
            "Epoch: 19, Loss: 0.9992, Acc_train: 0.8725, Acc_val: 0.6740, Acc_test: 0.7010\n",
            "Epoch: 20, Loss: 0.9719, Acc_train: 0.8742, Acc_val: 0.7020, Acc_test: 0.7060\n",
            "Epoch: 21, Loss: 0.9533, Acc_train: 0.8767, Acc_val: 0.7060, Acc_test: 0.7170\n",
            "Epoch: 22, Loss: 0.9365, Acc_train: 0.8800, Acc_val: 0.7160, Acc_test: 0.7200\n",
            "Epoch: 23, Loss: 0.9217, Acc_train: 0.8816, Acc_val: 0.7280, Acc_test: 0.7260\n",
            "Epoch: 24, Loss: 0.9108, Acc_train: 0.8833, Acc_val: 0.7340, Acc_test: 0.7300\n",
            "Epoch: 25, Loss: 0.9040, Acc_train: 0.8849, Acc_val: 0.7360, Acc_test: 0.7320\n",
            "Epoch: 26, Loss: 0.8943, Acc_train: 0.8891, Acc_val: 0.7380, Acc_test: 0.7370\n",
            "Epoch: 27, Loss: 0.8877, Acc_train: 0.8940, Acc_val: 0.7480, Acc_test: 0.7380\n",
            "Epoch: 28, Loss: 0.8821, Acc_train: 0.8957, Acc_val: 0.7540, Acc_test: 0.7440\n",
            "Epoch: 29, Loss: 0.8748, Acc_train: 0.8949, Acc_val: 0.7640, Acc_test: 0.7470\n",
            "Epoch: 30, Loss: 0.8710, Acc_train: 0.8990, Acc_val: 0.7820, Acc_test: 0.7540\n",
            "Epoch: 31, Loss: 0.8670, Acc_train: 0.8957, Acc_val: 0.7780, Acc_test: 0.7550\n",
            "Epoch: 32, Loss: 0.8633, Acc_train: 0.8974, Acc_val: 0.7700, Acc_test: 0.7580\n",
            "Epoch: 33, Loss: 0.8612, Acc_train: 0.8998, Acc_val: 0.7800, Acc_test: 0.7640\n",
            "Epoch: 34, Loss: 0.8558, Acc_train: 0.8982, Acc_val: 0.7800, Acc_test: 0.7610\n",
            "Epoch: 35, Loss: 0.8535, Acc_train: 0.9065, Acc_val: 0.7900, Acc_test: 0.7660\n",
            "Epoch: 36, Loss: 0.8509, Acc_train: 0.9073, Acc_val: 0.7820, Acc_test: 0.7680\n",
            "Epoch: 37, Loss: 0.8497, Acc_train: 0.9040, Acc_val: 0.7960, Acc_test: 0.7800\n",
            "Epoch: 38, Loss: 0.8499, Acc_train: 0.9007, Acc_val: 0.7980, Acc_test: 0.7790\n",
            "Epoch: 39, Loss: 0.8475, Acc_train: 0.8965, Acc_val: 0.8060, Acc_test: 0.7740\n",
            "SETTING SEEDS TO:  1863727779\n",
            "Epoch: 01, Loss: 8.1438, Acc_train: 0.4478, Acc_val: 0.1940, Acc_test: 0.2180\n",
            "Epoch: 02, Loss: 6.0828, Acc_train: 0.5099, Acc_val: 0.2480, Acc_test: 0.2600\n",
            "Epoch: 03, Loss: 4.9656, Acc_train: 0.5671, Acc_val: 0.2960, Acc_test: 0.3210\n",
            "Epoch: 04, Loss: 4.1416, Acc_train: 0.6126, Acc_val: 0.3600, Acc_test: 0.3530\n",
            "Epoch: 05, Loss: 3.4788, Acc_train: 0.6680, Acc_val: 0.4080, Acc_test: 0.3880\n",
            "Epoch: 06, Loss: 2.9635, Acc_train: 0.6970, Acc_val: 0.4320, Acc_test: 0.4250\n",
            "Epoch: 07, Loss: 2.5462, Acc_train: 0.7136, Acc_val: 0.4780, Acc_test: 0.4690\n",
            "Epoch: 08, Loss: 2.2187, Acc_train: 0.7368, Acc_val: 0.5200, Acc_test: 0.5050\n",
            "Epoch: 09, Loss: 1.9494, Acc_train: 0.7757, Acc_val: 0.5540, Acc_test: 0.5350\n",
            "Epoch: 10, Loss: 1.7360, Acc_train: 0.7906, Acc_val: 0.5960, Acc_test: 0.5590\n",
            "Epoch: 11, Loss: 1.5637, Acc_train: 0.8071, Acc_val: 0.6240, Acc_test: 0.5820\n",
            "Epoch: 12, Loss: 1.4242, Acc_train: 0.8278, Acc_val: 0.6420, Acc_test: 0.6030\n",
            "Epoch: 13, Loss: 1.3147, Acc_train: 0.8419, Acc_val: 0.6680, Acc_test: 0.6180\n",
            "Epoch: 14, Loss: 1.2291, Acc_train: 0.8493, Acc_val: 0.6840, Acc_test: 0.6290\n",
            "Epoch: 15, Loss: 1.1574, Acc_train: 0.8642, Acc_val: 0.7000, Acc_test: 0.6500\n",
            "Epoch: 16, Loss: 1.1019, Acc_train: 0.8709, Acc_val: 0.7160, Acc_test: 0.6670\n",
            "Epoch: 17, Loss: 1.0587, Acc_train: 0.8750, Acc_val: 0.7200, Acc_test: 0.6810\n",
            "Epoch: 18, Loss: 1.0213, Acc_train: 0.8825, Acc_val: 0.7240, Acc_test: 0.6890\n",
            "Epoch: 19, Loss: 0.9919, Acc_train: 0.8874, Acc_val: 0.7280, Acc_test: 0.6980\n",
            "Epoch: 20, Loss: 0.9705, Acc_train: 0.8924, Acc_val: 0.7320, Acc_test: 0.7100\n",
            "Epoch: 21, Loss: 0.9507, Acc_train: 0.8965, Acc_val: 0.7380, Acc_test: 0.7200\n",
            "Epoch: 22, Loss: 0.9332, Acc_train: 0.8957, Acc_val: 0.7460, Acc_test: 0.7230\n",
            "Epoch: 23, Loss: 0.9210, Acc_train: 0.8982, Acc_val: 0.7560, Acc_test: 0.7330\n",
            "Epoch: 24, Loss: 0.9104, Acc_train: 0.8957, Acc_val: 0.7540, Acc_test: 0.7380\n",
            "Epoch: 25, Loss: 0.8991, Acc_train: 0.9007, Acc_val: 0.7700, Acc_test: 0.7430\n",
            "Epoch: 26, Loss: 0.8931, Acc_train: 0.8965, Acc_val: 0.7740, Acc_test: 0.7430\n",
            "Epoch: 27, Loss: 0.8848, Acc_train: 0.9007, Acc_val: 0.7800, Acc_test: 0.7520\n",
            "Epoch: 28, Loss: 0.8792, Acc_train: 0.9015, Acc_val: 0.7860, Acc_test: 0.7550\n",
            "Epoch: 29, Loss: 0.8755, Acc_train: 0.9007, Acc_val: 0.7860, Acc_test: 0.7630\n",
            "Epoch: 30, Loss: 0.8694, Acc_train: 0.9023, Acc_val: 0.7900, Acc_test: 0.7610\n",
            "Epoch: 31, Loss: 0.8664, Acc_train: 0.9023, Acc_val: 0.7860, Acc_test: 0.7740\n",
            "Epoch: 32, Loss: 0.8608, Acc_train: 0.8982, Acc_val: 0.7900, Acc_test: 0.7760\n",
            "Epoch: 33, Loss: 0.8600, Acc_train: 0.9031, Acc_val: 0.7880, Acc_test: 0.7810\n",
            "Epoch: 34, Loss: 0.8557, Acc_train: 0.8998, Acc_val: 0.7980, Acc_test: 0.7820\n",
            "Epoch: 35, Loss: 0.8537, Acc_train: 0.9048, Acc_val: 0.8060, Acc_test: 0.7820\n",
            "Epoch: 36, Loss: 0.8529, Acc_train: 0.9007, Acc_val: 0.8060, Acc_test: 0.7840\n",
            "Epoch: 37, Loss: 0.8494, Acc_train: 0.9040, Acc_val: 0.8040, Acc_test: 0.7900\n",
            "Epoch: 38, Loss: 0.8465, Acc_train: 0.9031, Acc_val: 0.8100, Acc_test: 0.7920\n",
            "Epoch: 39, Loss: 0.8450, Acc_train: 0.9023, Acc_val: 0.8060, Acc_test: 0.7920\n",
            "SETTING SEEDS TO:  170173784\n",
            "Epoch: 01, Loss: 8.1242, Acc_train: 0.4719, Acc_val: 0.2760, Acc_test: 0.2410\n",
            "Epoch: 02, Loss: 6.0816, Acc_train: 0.5306, Acc_val: 0.3040, Acc_test: 0.2830\n",
            "Epoch: 03, Loss: 4.9617, Acc_train: 0.5869, Acc_val: 0.3440, Acc_test: 0.3280\n",
            "Epoch: 04, Loss: 4.1331, Acc_train: 0.6308, Acc_val: 0.3760, Acc_test: 0.3790\n",
            "Epoch: 05, Loss: 3.4814, Acc_train: 0.6796, Acc_val: 0.4160, Acc_test: 0.4290\n",
            "Epoch: 06, Loss: 2.9687, Acc_train: 0.7152, Acc_val: 0.4660, Acc_test: 0.4550\n",
            "Epoch: 07, Loss: 2.5487, Acc_train: 0.7508, Acc_val: 0.5200, Acc_test: 0.4920\n",
            "Epoch: 08, Loss: 2.2225, Acc_train: 0.7740, Acc_val: 0.5440, Acc_test: 0.5230\n",
            "Epoch: 09, Loss: 1.9552, Acc_train: 0.7914, Acc_val: 0.5760, Acc_test: 0.5410\n",
            "Epoch: 10, Loss: 1.7424, Acc_train: 0.8137, Acc_val: 0.5860, Acc_test: 0.5670\n",
            "Epoch: 11, Loss: 1.5695, Acc_train: 0.8262, Acc_val: 0.6040, Acc_test: 0.5810\n",
            "Epoch: 12, Loss: 1.4311, Acc_train: 0.8411, Acc_val: 0.6400, Acc_test: 0.5980\n",
            "Epoch: 13, Loss: 1.3198, Acc_train: 0.8518, Acc_val: 0.6680, Acc_test: 0.6180\n",
            "Epoch: 14, Loss: 1.2301, Acc_train: 0.8626, Acc_val: 0.6820, Acc_test: 0.6440\n",
            "Epoch: 15, Loss: 1.1603, Acc_train: 0.8667, Acc_val: 0.6900, Acc_test: 0.6590\n",
            "Epoch: 16, Loss: 1.1039, Acc_train: 0.8758, Acc_val: 0.6920, Acc_test: 0.6740\n",
            "Epoch: 17, Loss: 1.0605, Acc_train: 0.8825, Acc_val: 0.7080, Acc_test: 0.6820\n",
            "Epoch: 18, Loss: 1.0246, Acc_train: 0.8891, Acc_val: 0.7200, Acc_test: 0.6890\n",
            "Epoch: 19, Loss: 0.9953, Acc_train: 0.8932, Acc_val: 0.7360, Acc_test: 0.7060\n",
            "Epoch: 20, Loss: 0.9712, Acc_train: 0.8949, Acc_val: 0.7420, Acc_test: 0.7040\n",
            "Epoch: 21, Loss: 0.9497, Acc_train: 0.8965, Acc_val: 0.7460, Acc_test: 0.7060\n",
            "Epoch: 22, Loss: 0.9358, Acc_train: 0.9040, Acc_val: 0.7620, Acc_test: 0.7220\n",
            "Epoch: 23, Loss: 0.9226, Acc_train: 0.9089, Acc_val: 0.7580, Acc_test: 0.7260\n",
            "Epoch: 24, Loss: 0.9128, Acc_train: 0.9123, Acc_val: 0.7640, Acc_test: 0.7360\n",
            "Epoch: 25, Loss: 0.9032, Acc_train: 0.9164, Acc_val: 0.7620, Acc_test: 0.7360\n",
            "Epoch: 26, Loss: 0.8936, Acc_train: 0.9205, Acc_val: 0.7780, Acc_test: 0.7410\n",
            "Epoch: 27, Loss: 0.8863, Acc_train: 0.9180, Acc_val: 0.7820, Acc_test: 0.7430\n",
            "Epoch: 28, Loss: 0.8819, Acc_train: 0.9172, Acc_val: 0.7760, Acc_test: 0.7450\n",
            "Epoch: 29, Loss: 0.8746, Acc_train: 0.9139, Acc_val: 0.7760, Acc_test: 0.7520\n",
            "Epoch: 30, Loss: 0.8700, Acc_train: 0.9131, Acc_val: 0.7740, Acc_test: 0.7590\n",
            "Epoch: 31, Loss: 0.8671, Acc_train: 0.9081, Acc_val: 0.7840, Acc_test: 0.7620\n",
            "Epoch: 32, Loss: 0.8624, Acc_train: 0.9089, Acc_val: 0.7860, Acc_test: 0.7630\n",
            "Epoch: 33, Loss: 0.8602, Acc_train: 0.9065, Acc_val: 0.7840, Acc_test: 0.7640\n",
            "Epoch: 34, Loss: 0.8555, Acc_train: 0.9106, Acc_val: 0.7940, Acc_test: 0.7670\n",
            "Epoch: 35, Loss: 0.8537, Acc_train: 0.9098, Acc_val: 0.7880, Acc_test: 0.7680\n",
            "Epoch: 36, Loss: 0.8517, Acc_train: 0.9098, Acc_val: 0.7900, Acc_test: 0.7670\n",
            "Epoch: 37, Loss: 0.8498, Acc_train: 0.9098, Acc_val: 0.7900, Acc_test: 0.7710\n",
            "Epoch: 38, Loss: 0.8481, Acc_train: 0.9023, Acc_val: 0.7820, Acc_test: 0.7790\n",
            "Epoch: 39, Loss: 0.8456, Acc_train: 0.9048, Acc_val: 0.7860, Acc_test: 0.7810\n",
            "SETTING SEEDS TO:  2342954646\n",
            "Epoch: 01, Loss: 8.1270, Acc_train: 0.4694, Acc_val: 0.2460, Acc_test: 0.2320\n",
            "Epoch: 02, Loss: 6.0755, Acc_train: 0.5166, Acc_val: 0.2900, Acc_test: 0.2790\n",
            "Epoch: 03, Loss: 4.9570, Acc_train: 0.5786, Acc_val: 0.3260, Acc_test: 0.3260\n",
            "Epoch: 04, Loss: 4.1335, Acc_train: 0.6341, Acc_val: 0.3820, Acc_test: 0.3840\n",
            "Epoch: 05, Loss: 3.4834, Acc_train: 0.6796, Acc_val: 0.4360, Acc_test: 0.4390\n",
            "Epoch: 06, Loss: 2.9684, Acc_train: 0.7276, Acc_val: 0.4800, Acc_test: 0.4730\n",
            "Epoch: 07, Loss: 2.5511, Acc_train: 0.7599, Acc_val: 0.4980, Acc_test: 0.4980\n",
            "Epoch: 08, Loss: 2.2260, Acc_train: 0.7856, Acc_val: 0.5220, Acc_test: 0.5100\n",
            "Epoch: 09, Loss: 1.9588, Acc_train: 0.8129, Acc_val: 0.5300, Acc_test: 0.5450\n",
            "Epoch: 10, Loss: 1.7466, Acc_train: 0.8195, Acc_val: 0.5600, Acc_test: 0.5620\n",
            "Epoch: 11, Loss: 1.5737, Acc_train: 0.8386, Acc_val: 0.5720, Acc_test: 0.5880\n",
            "Epoch: 12, Loss: 1.4368, Acc_train: 0.8444, Acc_val: 0.5960, Acc_test: 0.6140\n",
            "Epoch: 13, Loss: 1.3245, Acc_train: 0.8560, Acc_val: 0.6060, Acc_test: 0.6370\n",
            "Epoch: 14, Loss: 1.2371, Acc_train: 0.8684, Acc_val: 0.6280, Acc_test: 0.6480\n",
            "Epoch: 15, Loss: 1.1631, Acc_train: 0.8733, Acc_val: 0.6660, Acc_test: 0.6590\n",
            "Epoch: 16, Loss: 1.1079, Acc_train: 0.8783, Acc_val: 0.6680, Acc_test: 0.6760\n",
            "Epoch: 17, Loss: 1.0645, Acc_train: 0.8841, Acc_val: 0.6740, Acc_test: 0.6850\n",
            "Epoch: 18, Loss: 1.0256, Acc_train: 0.8866, Acc_val: 0.6860, Acc_test: 0.6940\n",
            "Epoch: 19, Loss: 0.9992, Acc_train: 0.8949, Acc_val: 0.6980, Acc_test: 0.7090\n",
            "Epoch: 20, Loss: 0.9731, Acc_train: 0.8940, Acc_val: 0.7140, Acc_test: 0.7180\n",
            "Epoch: 21, Loss: 0.9546, Acc_train: 0.8982, Acc_val: 0.7160, Acc_test: 0.7270\n",
            "Epoch: 22, Loss: 0.9383, Acc_train: 0.9023, Acc_val: 0.7280, Acc_test: 0.7370\n",
            "Epoch: 23, Loss: 0.9226, Acc_train: 0.9040, Acc_val: 0.7380, Acc_test: 0.7340\n",
            "Epoch: 24, Loss: 0.9121, Acc_train: 0.9089, Acc_val: 0.7360, Acc_test: 0.7400\n",
            "Epoch: 25, Loss: 0.9029, Acc_train: 0.9065, Acc_val: 0.7360, Acc_test: 0.7490\n",
            "Epoch: 26, Loss: 0.8951, Acc_train: 0.9131, Acc_val: 0.7420, Acc_test: 0.7490\n",
            "Epoch: 27, Loss: 0.8883, Acc_train: 0.9139, Acc_val: 0.7500, Acc_test: 0.7570\n",
            "Epoch: 28, Loss: 0.8820, Acc_train: 0.9147, Acc_val: 0.7520, Acc_test: 0.7570\n",
            "Epoch: 29, Loss: 0.8754, Acc_train: 0.9123, Acc_val: 0.7580, Acc_test: 0.7570\n",
            "Epoch: 30, Loss: 0.8710, Acc_train: 0.9131, Acc_val: 0.7680, Acc_test: 0.7640\n",
            "Epoch: 31, Loss: 0.8674, Acc_train: 0.9156, Acc_val: 0.7800, Acc_test: 0.7690\n",
            "Epoch: 32, Loss: 0.8620, Acc_train: 0.9156, Acc_val: 0.7680, Acc_test: 0.7690\n",
            "Epoch: 33, Loss: 0.8603, Acc_train: 0.9139, Acc_val: 0.7640, Acc_test: 0.7650\n",
            "Epoch: 34, Loss: 0.8580, Acc_train: 0.9081, Acc_val: 0.7740, Acc_test: 0.7680\n",
            "Epoch: 35, Loss: 0.8558, Acc_train: 0.9089, Acc_val: 0.7700, Acc_test: 0.7680\n",
            "Epoch: 36, Loss: 0.8527, Acc_train: 0.9056, Acc_val: 0.7740, Acc_test: 0.7760\n",
            "Epoch: 37, Loss: 0.8509, Acc_train: 0.9073, Acc_val: 0.7780, Acc_test: 0.7750\n",
            "Epoch: 38, Loss: 0.8482, Acc_train: 0.9081, Acc_val: 0.7860, Acc_test: 0.7790\n",
            "Epoch: 39, Loss: 0.8454, Acc_train: 0.9089, Acc_val: 0.7960, Acc_test: 0.7820\n",
            "SETTING SEEDS TO:  116846604\n",
            "Epoch: 01, Loss: 8.0410, Acc_train: 0.4578, Acc_val: 0.2340, Acc_test: 0.2260\n",
            "Epoch: 02, Loss: 6.0012, Acc_train: 0.5008, Acc_val: 0.2660, Acc_test: 0.2920\n",
            "Epoch: 03, Loss: 4.9006, Acc_train: 0.5621, Acc_val: 0.3180, Acc_test: 0.3440\n",
            "Epoch: 04, Loss: 4.0851, Acc_train: 0.6068, Acc_val: 0.3800, Acc_test: 0.3970\n",
            "Epoch: 05, Loss: 3.4457, Acc_train: 0.6490, Acc_val: 0.4140, Acc_test: 0.4460\n",
            "Epoch: 06, Loss: 2.9260, Acc_train: 0.6929, Acc_val: 0.4760, Acc_test: 0.4690\n",
            "Epoch: 07, Loss: 2.5122, Acc_train: 0.7326, Acc_val: 0.5060, Acc_test: 0.4940\n",
            "Epoch: 08, Loss: 2.1925, Acc_train: 0.7483, Acc_val: 0.5240, Acc_test: 0.5270\n",
            "Epoch: 09, Loss: 1.9326, Acc_train: 0.7682, Acc_val: 0.5740, Acc_test: 0.5520\n",
            "Epoch: 10, Loss: 1.7218, Acc_train: 0.7864, Acc_val: 0.5980, Acc_test: 0.5630\n",
            "Epoch: 11, Loss: 1.5512, Acc_train: 0.7972, Acc_val: 0.6160, Acc_test: 0.5830\n",
            "Epoch: 12, Loss: 1.4191, Acc_train: 0.8079, Acc_val: 0.6160, Acc_test: 0.6100\n",
            "Epoch: 13, Loss: 1.3095, Acc_train: 0.8237, Acc_val: 0.6280, Acc_test: 0.6230\n",
            "Epoch: 14, Loss: 1.2257, Acc_train: 0.8295, Acc_val: 0.6360, Acc_test: 0.6420\n",
            "Epoch: 15, Loss: 1.1550, Acc_train: 0.8411, Acc_val: 0.6480, Acc_test: 0.6470\n",
            "Epoch: 16, Loss: 1.0979, Acc_train: 0.8477, Acc_val: 0.6600, Acc_test: 0.6700\n",
            "Epoch: 17, Loss: 1.0552, Acc_train: 0.8593, Acc_val: 0.6780, Acc_test: 0.6820\n",
            "Epoch: 18, Loss: 1.0207, Acc_train: 0.8717, Acc_val: 0.6780, Acc_test: 0.6980\n",
            "Epoch: 19, Loss: 0.9916, Acc_train: 0.8808, Acc_val: 0.6940, Acc_test: 0.7050\n",
            "Epoch: 20, Loss: 0.9680, Acc_train: 0.8800, Acc_val: 0.6980, Acc_test: 0.7190\n",
            "Epoch: 21, Loss: 0.9483, Acc_train: 0.8891, Acc_val: 0.7020, Acc_test: 0.7220\n",
            "Epoch: 22, Loss: 0.9343, Acc_train: 0.8891, Acc_val: 0.7000, Acc_test: 0.7250\n",
            "Epoch: 23, Loss: 0.9200, Acc_train: 0.8924, Acc_val: 0.7040, Acc_test: 0.7340\n",
            "Epoch: 24, Loss: 0.9097, Acc_train: 0.8940, Acc_val: 0.7120, Acc_test: 0.7400\n",
            "Epoch: 25, Loss: 0.9003, Acc_train: 0.8949, Acc_val: 0.7320, Acc_test: 0.7510\n",
            "Epoch: 26, Loss: 0.8925, Acc_train: 0.8957, Acc_val: 0.7480, Acc_test: 0.7510\n",
            "Epoch: 27, Loss: 0.8848, Acc_train: 0.8965, Acc_val: 0.7480, Acc_test: 0.7550\n",
            "Epoch: 28, Loss: 0.8787, Acc_train: 0.8982, Acc_val: 0.7480, Acc_test: 0.7620\n",
            "Epoch: 29, Loss: 0.8733, Acc_train: 0.8957, Acc_val: 0.7460, Acc_test: 0.7620\n",
            "Epoch: 30, Loss: 0.8703, Acc_train: 0.8965, Acc_val: 0.7440, Acc_test: 0.7600\n",
            "Epoch: 31, Loss: 0.8647, Acc_train: 0.8990, Acc_val: 0.7500, Acc_test: 0.7630\n",
            "Epoch: 32, Loss: 0.8615, Acc_train: 0.9007, Acc_val: 0.7560, Acc_test: 0.7620\n",
            "Epoch: 33, Loss: 0.8581, Acc_train: 0.9023, Acc_val: 0.7740, Acc_test: 0.7630\n",
            "Epoch: 34, Loss: 0.8574, Acc_train: 0.9031, Acc_val: 0.7740, Acc_test: 0.7690\n",
            "Epoch: 35, Loss: 0.8544, Acc_train: 0.9023, Acc_val: 0.7680, Acc_test: 0.7680\n",
            "Epoch: 36, Loss: 0.8520, Acc_train: 0.9031, Acc_val: 0.7720, Acc_test: 0.7700\n",
            "Epoch: 37, Loss: 0.8497, Acc_train: 0.9031, Acc_val: 0.7820, Acc_test: 0.7690\n",
            "Epoch: 38, Loss: 0.8467, Acc_train: 0.8990, Acc_val: 0.7740, Acc_test: 0.7680\n",
            "Epoch: 39, Loss: 0.8460, Acc_train: 0.9015, Acc_val: 0.7820, Acc_test: 0.7730\n",
            "SETTING SEEDS TO:  2105922959\n",
            "Epoch: 01, Loss: 8.1132, Acc_train: 0.4801, Acc_val: 0.2600, Acc_test: 0.2280\n",
            "Epoch: 02, Loss: 6.0764, Acc_train: 0.5381, Acc_val: 0.3100, Acc_test: 0.2850\n",
            "Epoch: 03, Loss: 4.9590, Acc_train: 0.5919, Acc_val: 0.3520, Acc_test: 0.3390\n",
            "Epoch: 04, Loss: 4.1338, Acc_train: 0.6432, Acc_val: 0.3920, Acc_test: 0.3950\n",
            "Epoch: 05, Loss: 3.4768, Acc_train: 0.6879, Acc_val: 0.4380, Acc_test: 0.4340\n",
            "Epoch: 06, Loss: 2.9542, Acc_train: 0.7351, Acc_val: 0.4880, Acc_test: 0.4720\n",
            "Epoch: 07, Loss: 2.5350, Acc_train: 0.7715, Acc_val: 0.5520, Acc_test: 0.4900\n",
            "Epoch: 08, Loss: 2.2072, Acc_train: 0.7980, Acc_val: 0.5820, Acc_test: 0.5160\n",
            "Epoch: 09, Loss: 1.9468, Acc_train: 0.8204, Acc_val: 0.6020, Acc_test: 0.5470\n",
            "Epoch: 10, Loss: 1.7350, Acc_train: 0.8320, Acc_val: 0.6340, Acc_test: 0.5660\n",
            "Epoch: 11, Loss: 1.5653, Acc_train: 0.8560, Acc_val: 0.6520, Acc_test: 0.5940\n",
            "Epoch: 12, Loss: 1.4256, Acc_train: 0.8659, Acc_val: 0.6740, Acc_test: 0.6230\n",
            "Epoch: 13, Loss: 1.3140, Acc_train: 0.8733, Acc_val: 0.6800, Acc_test: 0.6400\n",
            "Epoch: 14, Loss: 1.2275, Acc_train: 0.8742, Acc_val: 0.6900, Acc_test: 0.6540\n",
            "Epoch: 15, Loss: 1.1565, Acc_train: 0.8816, Acc_val: 0.7060, Acc_test: 0.6570\n",
            "Epoch: 16, Loss: 1.1011, Acc_train: 0.8849, Acc_val: 0.7100, Acc_test: 0.6740\n",
            "Epoch: 17, Loss: 1.0587, Acc_train: 0.8949, Acc_val: 0.7160, Acc_test: 0.6890\n",
            "Epoch: 18, Loss: 1.0226, Acc_train: 0.8982, Acc_val: 0.7220, Acc_test: 0.7080\n",
            "Epoch: 19, Loss: 0.9930, Acc_train: 0.8949, Acc_val: 0.7280, Acc_test: 0.7100\n",
            "Epoch: 20, Loss: 0.9695, Acc_train: 0.8982, Acc_val: 0.7380, Acc_test: 0.7190\n",
            "Epoch: 21, Loss: 0.9507, Acc_train: 0.8990, Acc_val: 0.7520, Acc_test: 0.7280\n",
            "Epoch: 22, Loss: 0.9337, Acc_train: 0.9048, Acc_val: 0.7620, Acc_test: 0.7430\n",
            "Epoch: 23, Loss: 0.9207, Acc_train: 0.9073, Acc_val: 0.7660, Acc_test: 0.7460\n",
            "Epoch: 24, Loss: 0.9080, Acc_train: 0.9081, Acc_val: 0.7600, Acc_test: 0.7570\n",
            "Epoch: 25, Loss: 0.8998, Acc_train: 0.9081, Acc_val: 0.7680, Acc_test: 0.7630\n",
            "Epoch: 26, Loss: 0.8917, Acc_train: 0.9048, Acc_val: 0.7680, Acc_test: 0.7660\n",
            "Epoch: 27, Loss: 0.8836, Acc_train: 0.9081, Acc_val: 0.7760, Acc_test: 0.7650\n",
            "Epoch: 28, Loss: 0.8781, Acc_train: 0.9106, Acc_val: 0.7780, Acc_test: 0.7700\n",
            "Epoch: 29, Loss: 0.8726, Acc_train: 0.9081, Acc_val: 0.7880, Acc_test: 0.7730\n",
            "Epoch: 30, Loss: 0.8681, Acc_train: 0.9056, Acc_val: 0.7880, Acc_test: 0.7750\n",
            "Epoch: 31, Loss: 0.8644, Acc_train: 0.9065, Acc_val: 0.7820, Acc_test: 0.7820\n",
            "Epoch: 32, Loss: 0.8608, Acc_train: 0.9015, Acc_val: 0.7940, Acc_test: 0.7790\n",
            "Epoch: 33, Loss: 0.8574, Acc_train: 0.9065, Acc_val: 0.7960, Acc_test: 0.7790\n",
            "Epoch: 34, Loss: 0.8538, Acc_train: 0.9081, Acc_val: 0.8060, Acc_test: 0.7830\n",
            "Epoch: 35, Loss: 0.8524, Acc_train: 0.9089, Acc_val: 0.8020, Acc_test: 0.7880\n",
            "Epoch: 36, Loss: 0.8513, Acc_train: 0.9114, Acc_val: 0.8040, Acc_test: 0.7870\n",
            "Epoch: 37, Loss: 0.8483, Acc_train: 0.9139, Acc_val: 0.8100, Acc_test: 0.7840\n",
            "Epoch: 38, Loss: 0.8461, Acc_train: 0.9089, Acc_val: 0.8200, Acc_test: 0.7850\n",
            "Epoch: 39, Loss: 0.8453, Acc_train: 0.9040, Acc_val: 0.8220, Acc_test: 0.7950\n",
            "SETTING SEEDS TO:  2739899259\n",
            "Epoch: 01, Loss: 8.1020, Acc_train: 0.4528, Acc_val: 0.2360, Acc_test: 0.2330\n",
            "Epoch: 02, Loss: 6.0760, Acc_train: 0.5008, Acc_val: 0.2760, Acc_test: 0.2900\n",
            "Epoch: 03, Loss: 4.9702, Acc_train: 0.5613, Acc_val: 0.3440, Acc_test: 0.3370\n",
            "Epoch: 04, Loss: 4.1463, Acc_train: 0.6084, Acc_val: 0.3960, Acc_test: 0.3760\n",
            "Epoch: 05, Loss: 3.4922, Acc_train: 0.6531, Acc_val: 0.4280, Acc_test: 0.4190\n",
            "Epoch: 06, Loss: 2.9709, Acc_train: 0.7020, Acc_val: 0.4660, Acc_test: 0.4510\n",
            "Epoch: 07, Loss: 2.5535, Acc_train: 0.7343, Acc_val: 0.5080, Acc_test: 0.4930\n",
            "Epoch: 08, Loss: 2.2209, Acc_train: 0.7624, Acc_val: 0.5260, Acc_test: 0.5200\n",
            "Epoch: 09, Loss: 1.9564, Acc_train: 0.7906, Acc_val: 0.5400, Acc_test: 0.5400\n",
            "Epoch: 10, Loss: 1.7441, Acc_train: 0.8030, Acc_val: 0.5640, Acc_test: 0.5620\n",
            "Epoch: 11, Loss: 1.5715, Acc_train: 0.8171, Acc_val: 0.5840, Acc_test: 0.5890\n",
            "Epoch: 12, Loss: 1.4316, Acc_train: 0.8361, Acc_val: 0.6100, Acc_test: 0.6090\n",
            "Epoch: 13, Loss: 1.3197, Acc_train: 0.8485, Acc_val: 0.6460, Acc_test: 0.6290\n",
            "Epoch: 14, Loss: 1.2325, Acc_train: 0.8568, Acc_val: 0.6600, Acc_test: 0.6510\n",
            "Epoch: 15, Loss: 1.1624, Acc_train: 0.8642, Acc_val: 0.6820, Acc_test: 0.6570\n",
            "Epoch: 16, Loss: 1.1037, Acc_train: 0.8692, Acc_val: 0.6940, Acc_test: 0.6830\n",
            "Epoch: 17, Loss: 1.0616, Acc_train: 0.8808, Acc_val: 0.7040, Acc_test: 0.7020\n",
            "Epoch: 18, Loss: 1.0246, Acc_train: 0.8816, Acc_val: 0.7180, Acc_test: 0.7070\n",
            "Epoch: 19, Loss: 0.9959, Acc_train: 0.8874, Acc_val: 0.7320, Acc_test: 0.7110\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6000005b2698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0macc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch:02d}, Loss: {loss:.4f}, Acc_train: {acc_train:.4f}, Acc_val: {acc_val:.4f}, Acc_test: {acc_test:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-6000005b2698>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m                       \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcora_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcora_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcora_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                       max_iter=150)\n\u001b[0;32m---> 61\u001b[0;31m     acc_val = model.test(z[cora_data.train_mask], cora_data.y[cora_data.train_mask],\n\u001b[0m\u001b[1;32m     62\u001b[0m                       \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcora_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcora_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcora_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                       max_iter=150)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/nn/models/node2vec.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, train_z, train_y, test_z, test_y, solver, multi_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n\u001b[0m\u001b[1;32m    176\u001b[0m                                  \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                                                train_y.detach().cpu().numpy())\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1292\u001b[0m             path_func(\n\u001b[1;32m   1293\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             ]\n\u001b[0;32m--> 450\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    694\u001b[0m                                  **options)\n\u001b[1;32m    695\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    697\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    698\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_prediction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_intercept_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mweight_intercept_raw\u001b[0;34m(self, coef, X)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m# weights has shape (n_classes, n_dof)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mraw_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mintercept\u001b[0m  \u001b[0;31m# ndarray, likely C-contiguous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similarity tests"
      ],
      "metadata": {
        "id": "NGtX2ycNQa-H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/SGDE2020/embedding_stability/blob/master/similarity_tests/similarity_tests.py"
      ],
      "metadata": {
        "id": "-eesbQaUQfd4"
      }
    }
  ]
}